#!/usr/bin/env python3
"""
æœç´¢å‘½ä»¤è¡Œå·¥å…·
æä¾›ä¾¿æ·çš„æœç´¢ç•Œé¢
"""
import argparse
import json
from typing import List
from tabulate import tabulate

from db import SearchRepository
from db.search import SearchField, SortBy


def format_duration(seconds: float) -> str:
    """æ ¼å¼åŒ–æ—¶é•¿"""
    if not seconds:
        return 'N/A'
    minutes = int(seconds // 60)
    secs = int(seconds % 60)
    return f"{minutes}:{secs:02d}"


def format_timestamp(seconds: float) -> str:
    """æ ¼å¼åŒ–æ—¶é—´æˆ³"""
    if not seconds:
        return 'N/A'
    minutes = int(seconds // 60)
    secs = int(seconds % 60)
    return f"{minutes:02d}:{secs:02d}"


def truncate_text(text: str, max_length: int = 80) -> str:
    """æˆªæ–­æ–‡æœ¬"""
    if len(text) <= max_length:
        return text
    return text[:max_length-3] + '...'


def search_command(args):
    """å…¨æ–‡æœç´¢å‘½ä»¤"""
    repo = SearchRepository()
    
    # è§£æžæœç´¢å­—æ®µ
    field = SearchField(args.field) if args.field else SearchField.ALL
    
    # è§£æžæŽ’åºæ–¹å¼
    sort_by = SortBy(args.sort) if args.sort else SortBy.RELEVANCE
    
    # æ‰§è¡Œæœç´¢
    results = repo.search(
        query=args.query,
        tags=args.tags,
        fields=field,
        limit=args.limit,
        offset=args.offset,
        sort_by=sort_by,
        min_relevance=args.min_relevance
    )
    
    if not results:
        print("âŒ æœªæ‰¾åˆ°åŒ¹é…ç»“æžœ")
        return
    
    # è¾“å‡ºç»“æžœ
    if args.json:
        # JSON æ ¼å¼è¾“å‡º
        print(json.dumps(
            [r.to_dict() for r in results],
            ensure_ascii=False,
            indent=2
        ))
    else:
        # è¡¨æ ¼æ ¼å¼è¾“å‡º
        print(f"\nðŸ” æ‰¾åˆ° {len(results)} ä¸ªç»“æžœ:\n")
        
        table_data = []
        for i, result in enumerate(results, 1):
            table_data.append([
                i,
                truncate_text(result.video_title, 30),
                result.source_field,
                truncate_text(result.matched_snippet, 50),
                format_timestamp(result.timestamp_seconds),
                f"{result.relevance_score:.2f}",
                ', '.join(result.tags[:3]) if result.tags else '-'
            ])
        
        headers = ['#', 'è§†é¢‘æ ‡é¢˜', 'æ¥æº', 'åŒ¹é…ç‰‡æ®µ', 'æ—¶é—´ç‚¹', 'ç›¸å…³æ€§', 'æ ‡ç­¾']
        print(tabulate(table_data, headers=headers, tablefmt='grid'))
        
        # è¯¦ç»†ä¿¡æ¯
        if args.verbose:
            print("\nðŸ“ è¯¦ç»†ä¿¡æ¯:\n")
            for i, result in enumerate(results, 1):
                print(f"[{i}] {result.video_title}")
                print(f"  ID: {result.video_id}")
                print(f"  æ¥æº: {result.source_field}")
                print(f"  æ ‡ç­¾: {', '.join(result.tags)}")
                print(f"  æ—¶é—´: {format_timestamp(result.timestamp_seconds)}")
                print(f"  ç›¸å…³æ€§: {result.relevance_score:.3f}")
                print(f"  ç‰‡æ®µ: {result.matched_snippet}")
                print(f"  æ–‡ä»¶: {result.file_path}")
                print()


def tag_search_command(args):
    """æ ‡ç­¾æœç´¢å‘½ä»¤"""
    repo = SearchRepository()
    
    results = repo.search_by_tags(
        tags=args.tags,
        match_all=args.match_all,
        limit=args.limit,
        offset=args.offset
    )
    
    if not results:
        print("âŒ æœªæ‰¾åˆ°åŒ¹é…ç»“æžœ")
        return
    
    print(f"\nðŸ·ï¸  æ‰¾åˆ° {len(results)} ä¸ªè§†é¢‘:\n")
    
    if args.json:
        print(json.dumps(results, ensure_ascii=False, indent=2, default=str))
    else:
        table_data = []
        for i, video in enumerate(results, 1):
            table_data.append([
                i,
                video['id'],
                truncate_text(video['title'], 40),
                video['source_type'],
                format_duration(video.get('duration_seconds')),
                video.get('tags', '-')
            ])
        
        headers = ['#', 'ID', 'æ ‡é¢˜', 'æ¥æº', 'æ—¶é•¿', 'æ ‡ç­¾']
        print(tabulate(table_data, headers=headers, tablefmt='grid'))


def topic_search_command(args):
    """ä¸»é¢˜æœç´¢å‘½ä»¤"""
    repo = SearchRepository()
    
    results = repo.search_topics(
        query=args.query,
        limit=args.limit,
        offset=args.offset
    )
    
    if not results:
        print("âŒ æœªæ‰¾åˆ°åŒ¹é…ç»“æžœ")
        return
    
    print(f"\nðŸ“š æ‰¾åˆ° {len(results)} ä¸ªä¸»é¢˜:\n")
    
    if args.json:
        print(json.dumps(results, ensure_ascii=False, indent=2, default=str))
    else:
        for i, topic in enumerate(results, 1):
            print(f"[{i}] {topic['title']}")
            print(f"  è§†é¢‘: {topic['video_title']}")
            print(f"  æ—¶é—´: {format_timestamp(topic.get('start_time'))} - {format_timestamp(topic.get('end_time'))}")
            if topic.get('summary'):
                print(f"  æ‘˜è¦: {truncate_text(topic['summary'], 100)}")
            if topic.get('video_tags'):
                print(f"  æ ‡ç­¾: {topic['video_tags']}")
            print()


def list_tags_command(args):
    """åˆ—å‡ºçƒ­é—¨æ ‡ç­¾"""
    repo = SearchRepository()
    
    tags = repo.get_popular_tags(limit=args.limit)
    
    if not tags:
        print("âŒ æš‚æ— æ ‡ç­¾")
        return
    
    print(f"\nðŸ·ï¸  çƒ­é—¨æ ‡ç­¾ (Top {len(tags)}):\n")
    
    if args.json:
        print(json.dumps(tags, ensure_ascii=False, indent=2, default=str))
    else:
        table_data = []
        for i, tag in enumerate(tags, 1):
            table_data.append([
                i,
                tag['name'],
                tag.get('category', '-'),
                tag['video_count'],
                tag['count']
            ])
        
        headers = ['#', 'æ ‡ç­¾å', 'åˆ†ç±»', 'è§†é¢‘æ•°', 'ä½¿ç”¨æ¬¡æ•°']
        print(tabulate(table_data, headers=headers, tablefmt='grid'))


def suggest_tags_command(args):
    """æ ‡ç­¾è‡ªåŠ¨è¡¥å…¨"""
    repo = SearchRepository()
    
    suggestions = repo.suggest_tags(args.prefix, limit=args.limit)
    
    if not suggestions:
        print(f"âŒ æ— åŒ¹é…çš„æ ‡ç­¾: {args.prefix}")
        return
    
    print(f"\nðŸ’¡ æ ‡ç­¾å»ºè®® (å‰ç¼€: '{args.prefix}'):\n")
    for tag in suggestions:
        print(f"  â€¢ {tag}")


def main():
    parser = argparse.ArgumentParser(
        description='çŸ¥è¯†åº“æœç´¢å·¥å…·',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # å…¨æ–‡æœç´¢
  python search_cli.py search "æœºå™¨å­¦ä¹ "
  
  # åœ¨è½¬å†™ä¸­æœç´¢
  python search_cli.py search "äººå·¥æ™ºèƒ½" --field transcript
  
  # æŒ‰æ ‡ç­¾æœç´¢
  python search_cli.py tags --tags æ•™è‚² ç§‘æŠ€ --match-all
  
  # æœç´¢ä¸»é¢˜
  python search_cli.py topics "ç¥žç»ç½‘ç»œ"
  
  # åˆ—å‡ºçƒ­é—¨æ ‡ç­¾
  python search_cli.py list-tags --limit 20
  
  # æ ‡ç­¾è‡ªåŠ¨è¡¥å…¨
  python search_cli.py suggest "æœºå™¨"
        """
    )
    
    subparsers = parser.add_subparsers(dest='command', help='å­å‘½ä»¤')
    
    # å…¨æ–‡æœç´¢
    search_parser = subparsers.add_parser('search', help='å…¨æ–‡æœç´¢')
    search_parser.add_argument('query', help='æœç´¢æŸ¥è¯¢')
    search_parser.add_argument('--tags', nargs='+', help='æ ‡ç­¾è¿‡æ»¤')
    search_parser.add_argument('--field', choices=['all', 'report', 'transcript', 'ocr', 'topic'],
                              default='all', help='æœç´¢å­—æ®µ')
    search_parser.add_argument('--sort', choices=['relevance', 'date', 'duration', 'title'],
                              default='relevance', help='æŽ’åºæ–¹å¼')
    search_parser.add_argument('--limit', type=int, default=20, help='è¿”å›žç»“æžœæ•°')
    search_parser.add_argument('--offset', type=int, default=0, help='åˆ†é¡µåç§»')
    search_parser.add_argument('--min-relevance', type=float, default=0.0, help='æœ€å°ç›¸å…³æ€§')
    search_parser.add_argument('--json', action='store_true', help='JSONæ ¼å¼è¾“å‡º')
    search_parser.add_argument('-v', '--verbose', action='store_true', help='è¯¦ç»†è¾“å‡º')
    search_parser.set_defaults(func=search_command)
    
    # æ ‡ç­¾æœç´¢
    tags_parser = subparsers.add_parser('tags', help='æŒ‰æ ‡ç­¾æœç´¢')
    tags_parser.add_argument('--tags', nargs='+', required=True, help='æ ‡ç­¾åˆ—è¡¨')
    tags_parser.add_argument('--match-all', action='store_true', help='åŒ¹é…æ‰€æœ‰æ ‡ç­¾ï¼ˆANDé€»è¾‘ï¼‰')
    tags_parser.add_argument('--limit', type=int, default=20, help='è¿”å›žç»“æžœæ•°')
    tags_parser.add_argument('--offset', type=int, default=0, help='åˆ†é¡µåç§»')
    tags_parser.add_argument('--json', action='store_true', help='JSONæ ¼å¼è¾“å‡º')
    tags_parser.set_defaults(func=tag_search_command)
    
    # ä¸»é¢˜æœç´¢
    topics_parser = subparsers.add_parser('topics', help='æœç´¢ä¸»é¢˜')
    topics_parser.add_argument('query', help='æœç´¢æŸ¥è¯¢')
    topics_parser.add_argument('--limit', type=int, default=20, help='è¿”å›žç»“æžœæ•°')
    topics_parser.add_argument('--offset', type=int, default=0, help='åˆ†é¡µåç§»')
    topics_parser.add_argument('--json', action='store_true', help='JSONæ ¼å¼è¾“å‡º')
    topics_parser.set_defaults(func=topic_search_command)
    
    # åˆ—å‡ºæ ‡ç­¾
    list_tags_parser = subparsers.add_parser('list-tags', help='åˆ—å‡ºçƒ­é—¨æ ‡ç­¾')
    list_tags_parser.add_argument('--limit', type=int, default=50, help='è¿”å›žç»“æžœæ•°')
    list_tags_parser.add_argument('--json', action='store_true', help='JSONæ ¼å¼è¾“å‡º')
    list_tags_parser.set_defaults(func=list_tags_command)
    
    # æ ‡ç­¾å»ºè®®
    suggest_parser = subparsers.add_parser('suggest', help='æ ‡ç­¾è‡ªåŠ¨è¡¥å…¨')
    suggest_parser.add_argument('prefix', help='æ ‡ç­¾å‰ç¼€')
    suggest_parser.add_argument('--limit', type=int, default=10, help='è¿”å›žç»“æžœæ•°')
    suggest_parser.set_defaults(func=suggest_tags_command)
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return
    
    # æ‰§è¡Œå‘½ä»¤
    args.func(args)


if __name__ == '__main__':
    main()
