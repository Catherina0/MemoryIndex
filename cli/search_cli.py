#!/usr/bin/env python3
"""
æœç´¢å‘½ä»¤è¡Œå·¥å…·
æä¾›ä¾¿æ·çš„æœç´¢ç•Œé¢
"""
import sys
import argparse
import json
from pathlib import Path
from typing import List
from tabulate import tabulate

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from db import SearchRepository
from db.search import SearchField, SortBy


def format_duration(seconds: float) -> str:
    """æ ¼å¼åŒ–æ—¶é•¿"""
    if not seconds:
        return 'N/A'
    minutes = int(seconds // 60)
    secs = int(seconds % 60)
    return f"{minutes}:{secs:02d}"


def format_timestamp(seconds: float) -> str:
    """æ ¼å¼åŒ–æ—¶é—´æˆ³"""
    if not seconds:
        return 'N/A'
    minutes = int(seconds // 60)
    secs = int(seconds % 60)
    return f"{minutes:02d}:{secs:02d}"


def truncate_text(text: str, max_length: int = 80) -> str:
    """æˆªæ–­æ–‡æœ¬"""
    if len(text) <= max_length:
        return text
    return text[:max_length-3] + '...'


def search_command(args):
    """å…¨æ–‡æœç´¢å‘½ä»¤"""
    repo = SearchRepository()
    
    # è§£ææœç´¢å­—æ®µ
    field = SearchField(args.field) if args.field else SearchField.ALL
    
    # è§£ææ’åºæ–¹å¼
    sort_by = SortBy(args.sort) if args.sort else SortBy.RELEVANCE
    
    # æ‰§è¡Œæœç´¢
    results = repo.search(
        query=args.query,
        tags=args.tags,
        fields=field,
        limit=args.limit,
        offset=args.offset,
        sort_by=sort_by,
        min_relevance=args.min_relevance,
        group_by_video=not args.show_all_matches,  # é»˜è®¤èšåˆï¼Œé™¤éæŒ‡å®šæ˜¾ç¤ºæ‰€æœ‰
        match_all_keywords=getattr(args, 'match_all', False),  # å¤šå…³é”®è¯åŒ¹é…é€»è¾‘
        fuzzy=not getattr(args, 'exact', False)  # é»˜è®¤æ¨¡ç³Šæœç´¢ï¼Œé™¤éæŒ‡å®šç²¾ç¡®
    )
    
    if not results:
        print("âŒ æœªæ‰¾åˆ°åŒ¹é…ç»“æœ")
        return
    
    # è¾“å‡ºç»“æœ
    if args.json:
        # JSON æ ¼å¼è¾“å‡º
        print(json.dumps(
            [r.to_dict() for r in results],
            ensure_ascii=False,
            indent=2
        ))
    else:
        # è¡¨æ ¼æ ¼å¼è¾“å‡º
        print(f"\nğŸ” æ‰¾åˆ° {len(results)} ä¸ªç»“æœ:\n")
        
        table_data = []
        for i, result in enumerate(results, 1):
            table_data.append([
                i,
                result.video_id,
                truncate_text(result.video_title, 30),
                result.source_field,
                truncate_text(result.matched_snippet, 50),
                format_timestamp(result.timestamp_seconds),
                f"{result.relevance_score:.2f}",
                ', '.join(result.tags[:3]) if result.tags else '-'
            ])
        
        headers = ['#', 'ID', 'è§†é¢‘æ ‡é¢˜', 'æ¥æº', 'åŒ¹é…ç‰‡æ®µ', 'æ—¶é—´ç‚¹', 'ç›¸å…³æ€§', 'æ ‡ç­¾']
        print(tabulate(table_data, headers=headers, tablefmt='grid'))
        
        # è¯¦ç»†ä¿¡æ¯
        if args.verbose:
            print("\nğŸ“ è¯¦ç»†ä¿¡æ¯:\n")
            for i, result in enumerate(results, 1):
                print(f"[{i}] {result.video_title}")
                print(f"  ID: {result.video_id}")
                print(f"  æ¥æº: {result.source_field}")
                print(f"  æ ‡ç­¾: {', '.join(result.tags)}")
                print(f"  æ—¶é—´: {format_timestamp(result.timestamp_seconds)}")
                print(f"  ç›¸å…³æ€§: {result.relevance_score:.3f}")
                print(f"  ç‰‡æ®µ: {result.matched_snippet}")
                print(f"  æ–‡ä»¶: {result.file_path}")
                print()


def tag_search_command(args):
    """æ ‡ç­¾æœç´¢å‘½ä»¤"""
    repo = SearchRepository()
    
    results = repo.search_by_tags(
        tags=args.tags,
        match_all=args.match_all,
        limit=args.limit,
        offset=args.offset
    )
    
    if not results:
        print("âŒ æœªæ‰¾åˆ°åŒ¹é…ç»“æœ")
        return
    
    print(f"\nğŸ·ï¸  æ‰¾åˆ° {len(results)} ä¸ªè§†é¢‘:\n")
    
    if args.json:
        print(json.dumps(results, ensure_ascii=False, indent=2, default=str))
    else:
        table_data = []
        for i, video in enumerate(results, 1):
            table_data.append([
                i,
                video['id'],
                truncate_text(video['title'], 40),
                video['source_type'],
                format_duration(video.get('duration_seconds')),
                video.get('tags', '-')
            ])
        
        headers = ['#', 'ID', 'æ ‡é¢˜', 'æ¥æº', 'æ—¶é•¿', 'æ ‡ç­¾']
        print(tabulate(table_data, headers=headers, tablefmt='grid'))


def topic_search_command(args):
    """ä¸»é¢˜æœç´¢å‘½ä»¤"""
    repo = SearchRepository()
    
    results = repo.search_topics(
        query=args.query,
        limit=args.limit,
        offset=args.offset
    )
    
    if not results:
        print("âŒ æœªæ‰¾åˆ°åŒ¹é…ç»“æœ")
        return
    
    print(f"\nğŸ“š æ‰¾åˆ° {len(results)} ä¸ªä¸»é¢˜:\n")
    
    if args.json:
        print(json.dumps(results, ensure_ascii=False, indent=2, default=str))
    else:
        for i, topic in enumerate(results, 1):
            print(f"[{i}] {topic['title']}")
            print(f"  è§†é¢‘: {topic['video_title']}")
            print(f"  æ—¶é—´: {format_timestamp(topic.get('start_time'))} - {format_timestamp(topic.get('end_time'))}")
            if topic.get('summary'):
                print(f"  æ‘˜è¦: {truncate_text(topic['summary'], 100)}")
            if topic.get('video_tags'):
                print(f"  æ ‡ç­¾: {topic['video_tags']}")
            print()


def list_tags_command(args):
    """åˆ—å‡ºçƒ­é—¨æ ‡ç­¾"""
    repo = SearchRepository()
    
    tags = repo.get_popular_tags(limit=args.limit)
    
    if not tags:
        print("âŒ æš‚æ— æ ‡ç­¾")
        return
    
    print(f"\nğŸ·ï¸  çƒ­é—¨æ ‡ç­¾ (Top {len(tags)}):\n")
    
    if args.json:
        print(json.dumps(tags, ensure_ascii=False, indent=2, default=str))
    else:
        table_data = []
        for i, tag in enumerate(tags, 1):
            table_data.append([
                i,
                tag['name'],
                tag.get('category', '-'),
                tag['video_count'],
                tag['count']
            ])
        
        headers = ['#', 'æ ‡ç­¾å', 'åˆ†ç±»', 'è§†é¢‘æ•°', 'ä½¿ç”¨æ¬¡æ•°']
        print(tabulate(table_data, headers=headers, tablefmt='grid'))


def suggest_tags_command(args):
    """æ ‡ç­¾è‡ªåŠ¨è¡¥å…¨"""
    repo = SearchRepository()
    
    suggestions = repo.suggest_tags(args.prefix, limit=args.limit)
    
    if not suggestions:
        print(f"âŒ æ— åŒ¹é…çš„æ ‡ç­¾: {args.prefix}")
        return
    
    print(f"\nğŸ’¡ æ ‡ç­¾å»ºè®® (å‰ç¼€: '{args.prefix}'):\n")
    for tag in suggestions:
        print(f"  â€¢ {tag}")


def show_command(args):
    """å±•ç¤ºç‰¹å®šIDçš„è§†é¢‘è¯¦æƒ…"""
    from db import VideoRepository
    repo = VideoRepository()
    
    video = repo.get_video_by_id(args.id)
    
    if not video:
        print(f"\nâŒ æœªæ‰¾åˆ° ID ä¸º {args.id} çš„è§†é¢‘")
        return
    
    # è·å–æ ‡ç­¾
    tags = repo.get_video_tags(args.id)
    
    # è·å–ä¸»é¢˜
    topics = repo.get_topics(args.id)
    
    # è·å–æ–‡ä»¶ï¼ˆæŠ¥å‘Šã€è½¬å†™ã€OCRï¼‰
    artifacts = repo.get_artifacts(args.id)
    
    # JSON è¾“å‡º
    if args.json:
        result = {
            'id': video.id,
            'title': video.title,
            'source_type': video.source_type.value if video.source_type else None,
            'source_url': video.source_url,
            'file_path': video.file_path,
            'duration_seconds': video.duration_seconds,
            'status': video.status.value if video.status else None,
            'created_at': str(video.created_at) if video.created_at else None,
            'processed_at': str(video.processed_at) if video.processed_at else None,
            'tags': tags,
            'topics': [
                {
                    'title': t.title,
                    'start_time': t.start_time,
                    'end_time': t.end_time,
                    'summary': t.summary
                } for t in topics
            ],
            'artifacts': [
                {
                    'type': a.artifact_type.value if a.artifact_type else None,
                    'file_path': a.file_path,
                    'content_preview': a.content_text[:500] + '...' if a.content_text and len(a.content_text) > 500 else a.content_text
                } for a in artifacts
            ] if not args.full else [
                {
                    'type': a.artifact_type.value if a.artifact_type else None,
                    'file_path': a.file_path,
                    'content': a.content_text
                } for a in artifacts
            ]
        }
        print(json.dumps(result, ensure_ascii=False, indent=2))
        return
    
    # æ ¼å¼åŒ–è¾“å‡º
    print(f"\n{'='*60}")
    print(f"ğŸ“¹ è§†é¢‘è¯¦æƒ… (ID: {video.id})")
    print(f"{'='*60}")
    
    print(f"\nğŸ“Œ åŸºæœ¬ä¿¡æ¯")
    print(f"  æ ‡é¢˜: {video.title}")
    print(f"  æ¥æº: {video.source_type.value if video.source_type else 'N/A'}")
    if video.source_url:
        print(f"  URL: {video.source_url}")
    print(f"  æ–‡ä»¶: {video.file_path}")
    print(f"  æ—¶é•¿: {format_duration(video.duration_seconds)}")
    print(f"  çŠ¶æ€: {video.status.value if video.status else 'N/A'}")
    print(f"  åˆ›å»º: {video.created_at}")
    if video.processed_at:
        print(f"  å¤„ç†: {video.processed_at}")
    
    if tags:
        print(f"\nğŸ·ï¸  æ ‡ç­¾")
        print(f"  {', '.join(tags)}")
    
    # ä» artifacts ä¸­è·å–æŠ¥å‘Šå†…å®¹ï¼Œæå–æ‘˜è¦å’Œä¸»è¦å†…å®¹æ¦‚æ‹¬
    report_artifact = next((a for a in artifacts if a.artifact_type and a.artifact_type.value == 'report'), None)
    if report_artifact and report_artifact.content_text:
        content = report_artifact.content_text
        lines = content.split('\n')
        
        # æå–æ‘˜è¦éƒ¨åˆ†
        summary_lines = []
        in_summary = False
        for line in lines:
            # æ£€æµ‹æ‘˜è¦æ ‡é¢˜
            if 'æ‘˜è¦' in line and ('#' in line or line.strip().startswith('æ‘˜è¦')):
                in_summary = True
                continue
            # æ£€æµ‹ä¸‹ä¸€ä¸ªç« èŠ‚æ ‡é¢˜ï¼ˆç»“æŸæ‘˜è¦ï¼‰
            if in_summary and line.strip().startswith('#'):
                break
            if in_summary and line.strip():
                summary_lines.append(line)
        
        if summary_lines:
            print(f"\nğŸ“ æ‘˜è¦")
            for line in summary_lines:
                print(f"  {line}")
        
        # æå–è¯¦ç»†çš„ä¸»è¦å†…å®¹æ¦‚æ‹¬
        detail_lines = []
        in_detail = False
        for line in lines:
            # æ£€æµ‹ä¸»è¦å†…å®¹æ¦‚æ‹¬æ ‡é¢˜
            if ('è¯¦ç»†' in line and 'ä¸»è¦å†…å®¹' in line) or ('ä¸»è¦å†…å®¹æ¦‚æ‹¬' in line):
                in_detail = True
                continue
            # æ£€æµ‹ä¸‹ä¸€ä¸ªç« èŠ‚æ ‡é¢˜ï¼ˆç»“æŸï¼‰
            if in_detail and line.strip().startswith('#') and 'è¯¦ç»†' not in line:
                break
            if in_detail and line.strip():
                detail_lines.append(line)
        
        if detail_lines:
            print(f"\nğŸ“‹ ä¸»è¦å†…å®¹æ¦‚æ‹¬")
            for line in detail_lines[:30]:  # æœ€å¤šæ˜¾ç¤º30è¡Œ
                print(f"  {line}")
            if len(detail_lines) > 30:
                print(f"  ... (å…± {len(detail_lines)} è¡Œ)")
    
    if artifacts:
        # åªæ˜¾ç¤ºæ¯ç§ç±»å‹çš„æœ€æ–°æ–‡ä»¶
        seen_types = set()
        latest_artifacts = []
        for a in artifacts:
            type_name = a.artifact_type.value if a.artifact_type else 'unknown'
            if type_name not in seen_types:
                seen_types.add(type_name)
                latest_artifacts.append(a)
        
        print(f"\nğŸ“„ ç›¸å…³æ–‡ä»¶ ({len(latest_artifacts)} ä¸ª)")
        for a in latest_artifacts:
            type_name = a.artifact_type.value if a.artifact_type else 'unknown'
            print(f"  â€¢ {type_name}: {a.file_path or '(å†…åµŒ)'}")
            if args.full and a.content_text:
                print(f"\n--- {type_name} å†…å®¹ ---")
                print(a.content_text[:2000] if len(a.content_text) > 2000 else a.content_text)
                if len(a.content_text) > 2000:
                    print(f"\n... (å…± {len(a.content_text)} å­—ç¬¦ï¼Œå·²æˆªæ–­)")
                print(f"--- {type_name} ç»“æŸ ---\n")
    
    print(f"\n{'='*60}")


def delete_command(args):
    """åˆ é™¤ç‰¹å®šIDçš„è§†é¢‘è®°å½•"""
    from db import VideoRepository
    from db.whoosh_search import WhooshSearchIndex
    
    video_repo = VideoRepository()
    whoosh_index = WhooshSearchIndex()
    
    # æ£€æŸ¥è§†é¢‘æ˜¯å¦å­˜åœ¨
    video = video_repo.get_video_by_id(args.id)
    if not video:
        print(f"\nâŒ æœªæ‰¾åˆ° ID ä¸º {args.id} çš„è§†é¢‘")
        return
    
    # æ˜¾ç¤ºè§†é¢‘ä¿¡æ¯
    print(f"\nğŸ“¹ å³å°†åˆ é™¤ä»¥ä¸‹è§†é¢‘è®°å½•ï¼š")
    print(f"   ID: {video.id}")
    print(f"   æ ‡é¢˜: {video.title}")
    print(f"   æ¥æº: {video.source_type.value if video.source_type else 'N/A'}")
    print(f"   URL: {video.source_url}")
    print(f"   æ–‡ä»¶: {video.file_path}")
    
    # ç¡®è®¤åˆ é™¤ï¼ˆé™¤éä½¿ç”¨ --forceï¼‰
    if not args.force:
        confirm = input("\nâš ï¸  ç¡®è®¤åˆ é™¤ï¼Ÿæ­¤æ“ä½œä¸å¯æ¢å¤ï¼(yes/no): ")
        if confirm.lower() not in ['yes', 'y']:
            print("âŒ å·²å–æ¶ˆåˆ é™¤")
            return
    
    # æ‰§è¡Œåˆ é™¤
    try:
        # 1. ä»æ•°æ®åº“åˆ é™¤
        success = video_repo.delete_video(args.id)
        if not success:
            print(f"âŒ åˆ é™¤å¤±è´¥ï¼šè§†é¢‘è®°å½•ä¸å­˜åœ¨")
            return
        
        # 2. ä»Whooshæœç´¢ç´¢å¼•åˆ é™¤
        whoosh_index.delete_video(args.id)
        
        print(f"\nâœ… æˆåŠŸåˆ é™¤è§†é¢‘è®°å½• ID={args.id}")
        print(f"   â„¹ï¸  æ³¨æ„ï¼šæ–‡ä»¶æœªè¢«åˆ é™¤ï¼Œå¦‚éœ€åˆ é™¤è¯·æ‰‹åŠ¨æ“ä½œï¼š")
        print(f"   rm -rf \"{video.file_path}\"")
        
    except Exception as e:
        print(f"\nâŒ åˆ é™¤å¤±è´¥: {e}")


def list_command(args):
    """åˆ—å‡ºæ‰€æœ‰è§†é¢‘"""
    from db import VideoRepository
    repo = VideoRepository()
    
    videos = repo.list_videos_with_summary(limit=args.limit, offset=args.offset)
    
    if not videos:
        print("\nâŒ æ•°æ®åº“ä¸­æ²¡æœ‰è§†é¢‘")
        return
    
    # JSON è¾“å‡º
    if args.json:
        # è½¬æ¢ datetime ä¸ºå­—ç¬¦ä¸²
        for v in videos:
            if 'created_at' in v and v['created_at']:
                v['created_at'] = str(v['created_at'])
        print(json.dumps(videos, ensure_ascii=False, indent=2))
        return
    
    # è¡¨æ ¼è¾“å‡º
    print(f"\nğŸ“¹ è§†é¢‘åˆ—è¡¨ (å…± {len(videos)} æ¡):\n")
    
    table_data = []
    for i, video in enumerate(videos, 1):
        table_data.append([
            i,
            video['id'],
            truncate_text(video['title'], 30),
            video['source_type'],
            format_duration(video['duration']),
            truncate_text(', '.join(video['tags']), 30) if video['tags'] else 'æ— ',
            truncate_text(video['summary'], 50)
        ])
    
    headers = ['#', 'ID', 'æ ‡é¢˜', 'æ¥æº', 'æ—¶é•¿', 'æ ‡ç­¾', 'æ‘˜è¦']
    print(tabulate(table_data, headers=headers, tablefmt='grid'))


def main():
    parser = argparse.ArgumentParser(
        prog='memidx',
        description='MemoryIndex - æ™ºèƒ½è§†é¢‘çŸ¥è¯†åº“æœç´¢å·¥å…·',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ” å¿«é€Ÿç¤ºä¾‹
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“ æœç´¢å†…å®¹ï¼š
  memidx search "æœºå™¨å­¦ä¹ "                    # å…¨æ–‡æœç´¢
  memidx search "äººå·¥æ™ºèƒ½" --field transcript  # ä»…åœ¨è½¬å†™ä¸­æœç´¢
  memidx search "æ·±åº¦å­¦ä¹ " --match-all         # AND é€»è¾‘ï¼ˆæ‰€æœ‰å…³é”®è¯ï¼‰
  memidx search "ç¥ç»ç½‘ç»œ" --exact             # ç²¾ç¡®åŒ¹é…

ğŸ·ï¸  æŒ‰æ ‡ç­¾æŸ¥æ‰¾ï¼š
  memidx tags --tags æ•™è‚² ç§‘æŠ€                # æ ‡ç­¾è¿‡æ»¤ï¼ˆOR é€»è¾‘ï¼‰
  memidx tags --tags æ•™è‚² ç§‘æŠ€ --match-all    # æ ‡ç­¾è¿‡æ»¤ï¼ˆAND é€»è¾‘ï¼‰
  memidx list-tags --limit 20                 # åˆ—å‡ºçƒ­é—¨æ ‡ç­¾
  memidx suggest "æœºå™¨"                        # æ ‡ç­¾è‡ªåŠ¨è¡¥å…¨

ğŸ¯ ä¸»é¢˜å’Œç®¡ç†ï¼š
  memidx topics "ç¥ç»ç½‘ç»œ"                     # ä¸»é¢˜æœç´¢
  memidx list                                 # åˆ—å‡ºæ‰€æœ‰è§†é¢‘
  memidx show 123                             # æŸ¥çœ‹ç‰¹å®šè§†é¢‘è¯¦æƒ…
  memidx delete 123                           # åˆ é™¤è§†é¢‘è®°å½•

ğŸ’¡ æ›´å¤šé€‰é¡¹è¯·ä½¿ç”¨ï¼šmemidx <command> --help
"""
    )
    parser.add_argument('--version', action='version', version='memoryindex 1.0.1')
    
    subparsers = parser.add_subparsers(dest='command', help='å­å‘½ä»¤')
    
    # å…¨æ–‡æœç´¢
    search_parser = subparsers.add_parser('search', help='å…¨æ–‡æœç´¢ï¼ˆæ”¯æŒå¤šå…³é”®è¯ï¼‰')
    search_parser.add_argument('query', help='æœç´¢æŸ¥è¯¢ï¼ˆæ”¯æŒç©ºæ ¼åˆ†éš”å¤šä¸ªå…³é”®è¯ï¼‰')
    search_parser.add_argument('--tags', nargs='+', help='æ ‡ç­¾è¿‡æ»¤')
    search_parser.add_argument('--field', choices=['all', 'report', 'transcript', 'ocr', 'topic'],
                              default='all', help='æœç´¢å­—æ®µ')
    search_parser.add_argument('--sort', choices=['relevance', 'date', 'duration', 'title'],
                              default='relevance', help='æ’åºæ–¹å¼')
    search_parser.add_argument('--limit', type=int, default=20, help='è¿”å›ç»“æœæ•°')
    search_parser.add_argument('--offset', type=int, default=0, help='åˆ†é¡µåç§»')
    search_parser.add_argument('--min-relevance', type=float, default=0.0, help='æœ€å°ç›¸å…³æ€§')
    search_parser.add_argument('--match-all', action='store_true', help='å¤šå…³é”®è¯ANDé€»è¾‘ï¼ˆé»˜è®¤ORï¼‰')
    search_parser.add_argument('--exact', action='store_true', help='ç²¾ç¡®æœç´¢ï¼ˆé»˜è®¤æ¨¡ç³Šæœç´¢ï¼‰')
    search_parser.add_argument('--show-all-matches', action='store_true', help='æ˜¾ç¤ºæ‰€æœ‰åŒ¹é…ç‰‡æ®µï¼ˆé»˜è®¤æ¯ä¸ªè§†é¢‘åªæ˜¾ç¤ºä¸€æ¬¡ï¼‰')
    search_parser.add_argument('--json', action='store_true', help='JSONæ ¼å¼è¾“å‡º')
    search_parser.add_argument('-v', '--verbose', action='store_true', help='è¯¦ç»†è¾“å‡º')
    search_parser.set_defaults(func=search_command)
    
    # æ ‡ç­¾æœç´¢
    tags_parser = subparsers.add_parser('tags', help='æŒ‰æ ‡ç­¾æœç´¢')
    tags_parser.add_argument('--tags', nargs='+', required=True, help='æ ‡ç­¾åˆ—è¡¨')
    tags_parser.add_argument('--match-all', action='store_true', help='åŒ¹é…æ‰€æœ‰æ ‡ç­¾ï¼ˆANDé€»è¾‘ï¼‰')
    tags_parser.add_argument('--limit', type=int, default=20, help='è¿”å›ç»“æœæ•°')
    tags_parser.add_argument('--offset', type=int, default=0, help='åˆ†é¡µåç§»')
    tags_parser.add_argument('--json', action='store_true', help='JSONæ ¼å¼è¾“å‡º')
    tags_parser.set_defaults(func=tag_search_command)
    
    # ä¸»é¢˜æœç´¢
    topics_parser = subparsers.add_parser('topics', help='æœç´¢ä¸»é¢˜')
    topics_parser.add_argument('query', help='æœç´¢æŸ¥è¯¢')
    topics_parser.add_argument('--limit', type=int, default=20, help='è¿”å›ç»“æœæ•°')
    topics_parser.add_argument('--offset', type=int, default=0, help='åˆ†é¡µåç§»')
    topics_parser.add_argument('--json', action='store_true', help='JSONæ ¼å¼è¾“å‡º')
    topics_parser.set_defaults(func=topic_search_command)
    
    # åˆ—å‡ºæ ‡ç­¾
    list_tags_parser = subparsers.add_parser('list-tags', help='åˆ—å‡ºçƒ­é—¨æ ‡ç­¾')
    list_tags_parser.add_argument('--limit', type=int, default=50, help='è¿”å›ç»“æœæ•°')
    list_tags_parser.add_argument('--json', action='store_true', help='JSONæ ¼å¼è¾“å‡º')
    list_tags_parser.set_defaults(func=list_tags_command)
    
    # æ ‡ç­¾å»ºè®®
    suggest_parser = subparsers.add_parser('suggest', help='æ ‡ç­¾è‡ªåŠ¨è¡¥å…¨')
    suggest_parser.add_argument('prefix', help='æ ‡ç­¾å‰ç¼€')
    suggest_parser.add_argument('--limit', type=int, default=10, help='è¿”å›ç»“æœæ•°')
    suggest_parser.set_defaults(func=suggest_tags_command)
    
    # åˆ—å‡ºè§†é¢‘
    list_parser = subparsers.add_parser('list', help='åˆ—å‡ºæ‰€æœ‰è§†é¢‘')
    list_parser.add_argument('--limit', type=int, default=20, help='è¿”å›ç»“æœæ•°')
    list_parser.add_argument('--offset', type=int, default=0, help='åˆ†é¡µåç§»')
    list_parser.add_argument('--json', action='store_true', help='JSONæ ¼å¼è¾“å‡º')
    list_parser.set_defaults(func=list_command)
    
    # å±•ç¤ºè§†é¢‘è¯¦æƒ…
    show_parser = subparsers.add_parser('show', help='å±•ç¤ºç‰¹å®šIDçš„è§†é¢‘è¯¦æƒ…')
    show_parser.add_argument('id', type=int, help='è§†é¢‘ID')
    show_parser.add_argument('--json', action='store_true', help='JSONæ ¼å¼è¾“å‡º')
    show_parser.add_argument('--full', action='store_true', help='æ˜¾ç¤ºå®Œæ•´å†…å®¹ï¼ˆåŒ…å«è½¬å†™ã€OCRç­‰ï¼‰')
    show_parser.set_defaults(func=show_command)
    
    # åˆ é™¤è§†é¢‘è®°å½•
    delete_parser = subparsers.add_parser('delete', help='åˆ é™¤ç‰¹å®šIDçš„è§†é¢‘è®°å½•')
    delete_parser.add_argument('id', type=int, help='è§†é¢‘ID')
    delete_parser.add_argument('--force', action='store_true', help='å¼ºåˆ¶åˆ é™¤ï¼Œä¸æç¤ºç¡®è®¤')
    delete_parser.set_defaults(func=delete_command)
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return
    
    # æ‰§è¡Œå‘½ä»¤
    args.func(args)


if __name__ == '__main__':
    main()
