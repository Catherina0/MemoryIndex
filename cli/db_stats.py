#!/usr/bin/env python3
"""
æ•°æ®åº“è¯¦ç»†ç»Ÿè®¡å·¥å…·
æä¾›æ›´æ·±å…¥çš„æ•°æ®åˆ†æ
"""
import sys
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Any
from tabulate import tabulate

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from db import VideoRepository
from db.schema import get_connection


def get_archive_stats() -> Dict[str, Any]:
    """è·å–ç½‘é¡µå½’æ¡£çš„è¯¦ç»†ç»Ÿè®¡"""
    conn = get_connection()
    try:
        stats = {}
        
        # ç½‘é¡µå½’æ¡£æŒ‰å¹³å°ç»Ÿè®¡
        cursor = conn.execute("""
            SELECT source_type, COUNT(*) as count,
                   AVG(file_size_bytes) as avg_size
            FROM videos 
            WHERE source_type IN ('zhihu', 'reddit', 'twitter', 'web_archive')
            GROUP BY source_type
        """)
        stats['by_platform'] = [dict(row) for row in cursor.fetchall()]
        
        # æœ€è¿‘å½’æ¡£çš„ç½‘é¡µ
        cursor = conn.execute("""
            SELECT id, title, source_type, source_url, created_at
            FROM videos 
            WHERE source_type IN ('zhihu', 'reddit', 'twitter', 'web_archive')
            ORDER BY created_at DESC
            LIMIT 10
        """)
        stats['recent'] = [dict(row) for row in cursor.fetchall()]
        
        # å½’æ¡£ç½‘é¡µçš„OCRä½¿ç”¨ç‡
        cursor = conn.execute("""
            SELECT 
                COUNT(DISTINCT v.id) as total,
                COUNT(DISTINCT a.video_id) as with_ocr
            FROM videos v
            LEFT JOIN artifacts a ON v.id = a.video_id AND a.artifact_type = 'ocr'
            WHERE v.source_type IN ('zhihu', 'reddit', 'twitter', 'web_archive')
        """)
        row = cursor.fetchone()
        stats['ocr_usage'] = {
            'total': row['total'],
            'with_ocr': row['with_ocr'],
            'percentage': (row['with_ocr'] / row['total'] * 100) if row['total'] > 0 else 0
        }
        
        return stats
    finally:
        conn.close()


def get_video_stats() -> Dict[str, Any]:
    """è·å–è§†é¢‘æ–‡ä»¶çš„è¯¦ç»†ç»Ÿè®¡"""
    conn = get_connection()
    try:
        stats = {}
        
        # è§†é¢‘æŒ‰å¹³å°ç»Ÿè®¡ï¼ˆåŒ…å«æ—¶é•¿ï¼‰
        cursor = conn.execute("""
            SELECT source_type, COUNT(*) as count,
                   AVG(duration_seconds) as avg_duration,
                   SUM(duration_seconds) as total_duration,
                   AVG(file_size_bytes) as avg_size
            FROM videos 
            WHERE source_type IN ('local', 'bilibili', 'youtube', 'xiaohongshu')
                  AND duration_seconds IS NOT NULL
            GROUP BY source_type
        """)
        stats['by_platform'] = [dict(row) for row in cursor.fetchall()]
        
        # æ€»æ—¶é•¿
        cursor = conn.execute("""
            SELECT SUM(duration_seconds) as total
            FROM videos 
            WHERE duration_seconds IS NOT NULL
        """)
        stats['total_duration'] = cursor.fetchone()['total'] or 0
        
        # OCRä½¿ç”¨ç‡
        cursor = conn.execute("""
            SELECT 
                COUNT(DISTINCT v.id) as total,
                COUNT(DISTINCT a.video_id) as with_ocr
            FROM videos v
            LEFT JOIN artifacts a ON v.id = a.video_id AND a.artifact_type = 'ocr'
            WHERE v.source_type IN ('local', 'bilibili', 'youtube', 'xiaohongshu')
        """)
        row = cursor.fetchone()
        stats['ocr_usage'] = {
            'total': row['total'],
            'with_ocr': row['with_ocr'],
            'percentage': (row['with_ocr'] / row['total'] * 100) if row['total'] > 0 else 0
        }
        
        return stats
    finally:
        conn.close()


def get_tag_stats() -> Dict[str, Any]:
    """è·å–æ ‡ç­¾ä½¿ç”¨ç»Ÿè®¡"""
    conn = get_connection()
    try:
        stats = {}
        
        # æœ€å¸¸ç”¨çš„æ ‡ç­¾
        cursor = conn.execute("""
            SELECT t.name, COUNT(*) as usage_count
            FROM video_tags vt
            JOIN tags t ON vt.tag_id = t.id
            GROUP BY t.name
            ORDER BY usage_count DESC
            LIMIT 20
        """)
        stats['top_tags'] = [dict(row) for row in cursor.fetchall()]
        
        # æ ‡ç­¾ä½¿ç”¨åˆ†å¸ƒ
        cursor = conn.execute("""
            SELECT usage_count, COUNT(*) as tag_count
            FROM (
                SELECT COUNT(*) as usage_count
                FROM video_tags
                GROUP BY tag_id
            )
            GROUP BY usage_count
            ORDER BY usage_count DESC
        """)
        stats['distribution'] = [dict(row) for row in cursor.fetchall()]
        
        return stats
    finally:
        conn.close()


def format_duration(seconds: float) -> str:
    """æ ¼å¼åŒ–æ—¶é•¿"""
    if not seconds:
        return 'N/A'
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    if hours > 0:
        return f"{hours}h {minutes}m"
    return f"{minutes}m"


def format_size(bytes: float) -> str:
    """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
    if not bytes:
        return 'N/A'
    mb = bytes / 1024 / 1024
    if mb > 1024:
        return f"{mb / 1024:.2f} GB"
    return f"{mb:.2f} MB"


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='æ•°æ®åº“è¯¦ç»†ç»Ÿè®¡')
    parser.add_argument('--archives', action='store_true', help='æ˜¾ç¤ºç½‘é¡µå½’æ¡£ç»Ÿè®¡')
    parser.add_argument('--videos', action='store_true', help='æ˜¾ç¤ºè§†é¢‘æ–‡ä»¶ç»Ÿè®¡')
    parser.add_argument('--tags', action='store_true', help='æ˜¾ç¤ºæ ‡ç­¾ç»Ÿè®¡')
    parser.add_argument('--all', action='store_true', help='æ˜¾ç¤ºæ‰€æœ‰ç»Ÿè®¡')
    
    args = parser.parse_args()
    
    # å¦‚æœæ²¡æœ‰æŒ‡å®šå‚æ•°ï¼Œé»˜è®¤æ˜¾ç¤ºæ‰€æœ‰
    if not (args.archives or args.videos or args.tags):
        args.all = True
    
    if args.all or args.archives:
        print("\n" + "=" * 60)
        print("ğŸŒ ç½‘é¡µå½’æ¡£è¯¦ç»†ç»Ÿè®¡")
        print("=" * 60)
        
        archive_stats = get_archive_stats()
        
        # æŒ‰å¹³å°ç»Ÿè®¡
        if archive_stats['by_platform']:
            print("\nğŸ“Š æŒ‰å¹³å°ç»Ÿè®¡:")
            table = []
            for item in archive_stats['by_platform']:
                platform_names = {
                    'twitter': 'Twitter/X',
                    'zhihu': 'çŸ¥ä¹',
                    'reddit': 'Reddit',
                    'web_archive': 'é€šç”¨ç½‘é¡µ'
                }
                platform = platform_names.get(item['source_type'], item['source_type'])
                table.append([
                    platform,
                    item['count'],
                    format_size(item['avg_size'])
                ])
            print(tabulate(table, headers=['å¹³å°', 'æ•°é‡', 'å¹³å‡å¤§å°'], tablefmt='simple'))
        
        # OCRä½¿ç”¨ç‡
        ocr_usage = archive_stats['ocr_usage']
        print(f"\nğŸ” OCRä½¿ç”¨æƒ…å†µ:")
        print(f"  æ€»è®¡: {ocr_usage['total']} æ¡")
        print(f"  ä½¿ç”¨OCR: {ocr_usage['with_ocr']} æ¡ ({ocr_usage['percentage']:.1f}%)")
        
        # æœ€è¿‘å½’æ¡£
        if archive_stats['recent']:
            print(f"\nğŸ“… æœ€è¿‘å½’æ¡£ (å‰10æ¡):")
            table = []
            for item in archive_stats['recent'][:5]:  # åªæ˜¾ç¤ºå‰5æ¡
                title = item['title'][:40] + '...' if len(item['title']) > 40 else item['title']
                # å¤„ç†æ—¥æœŸæ ¼å¼
                if isinstance(item['created_at'], str):
                    created = datetime.fromisoformat(item['created_at']).strftime('%m-%d %H:%M')
                else:
                    created = item['created_at'].strftime('%m-%d %H:%M') if item['created_at'] else 'N/A'
                table.append([
                    item['id'],
                    title,
                    item['source_type'],
                    created
                ])
            print(tabulate(table, headers=['ID', 'æ ‡é¢˜', 'å¹³å°', 'å½’æ¡£æ—¶é—´'], tablefmt='simple'))
    
    if args.all or args.videos:
        print("\n" + "=" * 60)
        print("ğŸ¥ è§†é¢‘æ–‡ä»¶è¯¦ç»†ç»Ÿè®¡")
        print("=" * 60)
        
        video_stats = get_video_stats()
        
        # æŒ‰å¹³å°ç»Ÿè®¡
        if video_stats['by_platform']:
            print("\nğŸ“Š æŒ‰å¹³å°ç»Ÿè®¡:")
            table = []
            for item in video_stats['by_platform']:
                platform_names = {
                    'local': 'æœ¬åœ°è§†é¢‘',
                    'bilibili': 'Bç«™',
                    'youtube': 'YouTube',
                    'xiaohongshu': 'å°çº¢ä¹¦'
                }
                platform = platform_names.get(item['source_type'], item['source_type'])
                table.append([
                    platform,
                    item['count'],
                    format_duration(item['avg_duration']),
                    format_duration(item['total_duration']),
                    format_size(item['avg_size'])
                ])
            print(tabulate(table, headers=['å¹³å°', 'æ•°é‡', 'å¹³å‡æ—¶é•¿', 'æ€»æ—¶é•¿', 'å¹³å‡å¤§å°'], tablefmt='simple'))
        
        # æ€»æ—¶é•¿
        print(f"\nâ±ï¸  è§†é¢‘æ€»æ—¶é•¿: {format_duration(video_stats['total_duration'])}")
        
        # OCRä½¿ç”¨ç‡
        ocr_usage = video_stats['ocr_usage']
        print(f"\nğŸ” OCRä½¿ç”¨æƒ…å†µ:")
        print(f"  æ€»è®¡: {ocr_usage['total']} æ¡")
        print(f"  ä½¿ç”¨OCR: {ocr_usage['with_ocr']} æ¡ ({ocr_usage['percentage']:.1f}%)")
    
    if args.all or args.tags:
        print("\n" + "=" * 60)
        print("ğŸ·ï¸  æ ‡ç­¾ä½¿ç”¨ç»Ÿè®¡")
        print("=" * 60)
        
        tag_stats = get_tag_stats()
        
        # æœ€å¸¸ç”¨æ ‡ç­¾
        if tag_stats['top_tags']:
            print("\nğŸ“Š æœ€å¸¸ç”¨æ ‡ç­¾ (Top 20):")
            table = []
            for i, item in enumerate(tag_stats['top_tags'], 1):
                table.append([i, item['name'], item['usage_count']])
            print(tabulate(table, headers=['#', 'æ ‡ç­¾', 'ä½¿ç”¨æ¬¡æ•°'], tablefmt='simple'))
    
    print("\n" + "=" * 60 + "\n")


if __name__ == '__main__':
    main()
