"""
å›¾ç‰‡ä¸‹è½½å™¨
ç”¨äºä¸‹è½½ç½‘é¡µä¸­çš„å›¾ç‰‡å¹¶ä¿å­˜ä¸ºæœ¬åœ°æ–‡ä»¶
"""

import os
import re
import logging
import hashlib
import base64
from pathlib import Path
from typing import List, Dict, Optional
from urllib.parse import urljoin, urlparse

try:
    import requests
    REQUESTS_AVAILABLE = True
except ImportError:
    REQUESTS_AVAILABLE = False
    logging.warning("requests not installed. Run: pip install requests")

try:
    from PIL import Image
    from io import BytesIO
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False
    logging.warning("Pillow not installed. Run: pip install pillow")


logger = logging.getLogger(__name__)


class ImageDownloader:
    """å›¾ç‰‡ä¸‹è½½å™¨"""
    
    def __init__(self, output_dir: str, format: str = "jpg"):
        """
        åˆå§‹åŒ–å›¾ç‰‡ä¸‹è½½å™¨
        
        Args:
            output_dir: å›¾ç‰‡ä¿å­˜ç›®å½•
            format: å›¾ç‰‡æ ¼å¼ (jpg, png, webpç­‰)
        """
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.format = format.lower()
        self.downloaded_images = {}  # URL -> æœ¬åœ°è·¯å¾„æ˜ å°„
        
    def extract_image_urls(self, html: str, base_url: str) -> List[str]:
        """
        ä»HTMLä¸­æå–æ‰€æœ‰å›¾ç‰‡URLï¼ˆåŒ…æ‹¬base64ï¼‰
        
        Args:
            html: HTMLå†…å®¹
            base_url: åŸºç¡€URLï¼Œç”¨äºè½¬æ¢ç›¸å¯¹è·¯å¾„
        
        Returns:
            å›¾ç‰‡URLåˆ—è¡¨ï¼ˆåŒ…æ‹¬data: URLï¼‰
        """
        # å…ˆè§£ç  HTML å®ä½“
        import html as html_module
        html = html_module.unescape(html)
        
        # åŒ¹é… img src å’Œ data-src å±æ€§
        patterns = [
            r'<img[^>]+src=["\']([^"\']+)["\']',
            r'<img[^>]+data-src=["\']([^"\']+)["\']',
            r'<img[^>]+data-original=["\']([^"\']+)["\']',
            # ğŸ†• æ¨ç‰¹çš„èƒŒæ™¯å›¾ç‰‡
            r'background-image:\s*url\(["\']?([^"\'()]+)["\']?\)',
        ]
        
        urls = set()
        for pattern in patterns:
            matches = re.findall(pattern, html, re.IGNORECASE)
            for url in matches:
                # å†æ¬¡æ£€æŸ¥å’Œæ¸…ç† URL
                url = url.strip()
                
                # è¿‡æ»¤æ— æ•ˆ URLï¼ˆåŒ…å«å¼•å·ã€ä¸å®Œæ•´çš„ URL ç­‰ï¼‰
                if '"' in url or "'" in url:
                    # æå–å¼•å·ä¹‹é—´çš„å†…å®¹
                    clean_match = re.search(r'https?://[^"\' ]+', url)
                    if clean_match:
                        url = clean_match.group(0)
                    else:
                        continue  # è·³è¿‡æ— æ•ˆ URL
                
                # å¤„ç† data URLï¼ˆbase64 å›¾ç‰‡ï¼‰
                if url.startswith('data:'):
                    urls.add(url)
                    continue
                
                # è½¬æ¢ä¸ºç»å¯¹URL
                abs_url = urljoin(base_url, url)
                # åªå¤„ç†http/httpså›¾ç‰‡
                if abs_url.startswith(('http://', 'https://')):
                    # ğŸ†• æ¨ç‰¹å›¾ç‰‡ç‰¹æ®Šå¤„ç†ï¼šç¡®ä¿ä½¿ç”¨largeå°ºå¯¸
                    if 'twimg.com' in abs_url:
                        # å¯¹äºprofileå›¾ç‰‡ï¼ˆå¤´åƒï¼‰ï¼Œä¿æŒåŸå°ºå¯¸ï¼Œä¸å¼ºåˆ¶large
                        if 'profile_images' in abs_url:
                            # ç§»é™¤æˆ‘ä»¬æ·»åŠ çš„formatå’Œnameå‚æ•°
                            if '?format=jpg&name=large' in abs_url:
                                abs_url = abs_url.replace('?format=jpg&name=large', '')
                        # å¯¹äºåª’ä½“å›¾ç‰‡ï¼Œç¡®ä¿ä½¿ç”¨largeå°ºå¯¸
                        elif '/media/' in abs_url:
                            if 'name=' in abs_url:
                                abs_url = re.sub(r'name=\w+', 'name=large', abs_url)
                            elif '?' not in abs_url:
                                abs_url += '?format=jpg&name=large'
                    urls.add(abs_url)
        
        logger.info(f"æå–åˆ° {len(urls)} ä¸ªå›¾ç‰‡URL")
        return list(urls)
    
    def download_image(
        self,
        url: str,
        filename: Optional[str] = None,
        headers: Optional[Dict[str, str]] = None,
        referer: Optional[str] = None
    ) -> Optional[str]:
        """ï¼ˆæ”¯æŒHTTPå’Œbase64ï¼‰
        
        Args:
            url: å›¾ç‰‡URLï¼ˆHTTPæˆ–data: URLï¼‰
            filename: ä¿å­˜æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰
            headers: è¯·æ±‚å¤´
            referer: Referer URLï¼ˆç”¨äºé˜²ç›—é“¾ï¼‰
        
        Returns:
            æœ¬åœ°æ–‡ä»¶è·¯å¾„ï¼Œå¤±è´¥è¿”å›None
        """
        # æ£€æŸ¥ç¼“å­˜
        if url in self.downloaded_images:
            logger.debug(f"ä½¿ç”¨ç¼“å­˜çš„å›¾ç‰‡: {url[:50]}...")
            return self.downloaded_images[url]
        
        try:
            # ç”Ÿæˆæ–‡ä»¶å
            if not filename:
                # ä½¿ç”¨URLçš„å“ˆå¸Œå€¼ä½œä¸ºæ–‡ä»¶å
                url_hash = hashlib.md5(url.encode()).hexdigest()[:12]
                filename = f"image_{url_hash}"
            
            # å¤„ç† base64 å›¾ç‰‡
            if url.startswith('data:'):
                return self._save_base64_image(url, filename)
            
            # å¤„ç† HTTP å›¾ç‰‡
            if not REQUESTS_AVAILABLE:
                logger.error("requests not installed")
                return None
            
            # è®¾ç½®è¯·æ±‚å¤´
            if not headers:
                headers = {
                    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36',
                    'Accept': 'image/avif,image/webp,image/apng,image/svg+xml,image/*,*/*;q=0.8',
                    'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
                }
            
            # è®¾ç½®Refererï¼ˆé˜²æ­¢é˜²ç›—é“¾ï¼‰
            # æ³¨æ„ï¼šReferer å¿…é¡»æ˜¯ ASCII ç¼–ç ï¼Œé¿å…ä¸­æ–‡å­—ç¬¦
            if referer:
                # ç¡®ä¿ referer ä¸åŒ…å«ä¸­æ–‡å­—ç¬¦
                try:
                    referer.encode('latin-1')
                    headers['Referer'] = referer
                except UnicodeEncodeError:
                    # å¦‚æœåŒ…å«ä¸­æ–‡ï¼Œä½¿ç”¨åŸŸåä½œä¸º referer
                    from urllib.parse import urlparse
                    parsed = urlparse(referer)
                    headers['Referer'] = f"{parsed.scheme}://{parsed.netloc}/"
            elif 'xiaohongshu' in url or 'xhscdn' in url:
                headers['Referer'] = 'https://www.xiaohongshu.com/'
            elif 'zhihu' in url or 'zhimg' in url:
                headers['Referer'] = 'https://www.zhihu.com/'
            else:
                # ä» URL ä¸­æå–åŸŸåä½œä¸º referer
                from urllib.parse import urlparse
                parsed = urlparse(url)
                headers['Referer'] = f"{parsed.scheme}://{parsed.netloc}/"
            
            # ä¸‹è½½å›¾ç‰‡
            response = requests.get(url, headers=headers, timeout=10)
            response.raise_for_status()
            
            # ä¿å­˜å›¾ç‰‡
            return self._save_image_data(response.content, filename)
            
        except Exception as e:
            logger.error(f"ä¸‹è½½å›¾ç‰‡å¤±è´¥ {url[:80]}...: {e}")
            return None
    
    def _save_base64_image(self, data_url: str, filename: str) -> Optional[str]:
        """
        ä¿å­˜ base64 ç¼–ç çš„å›¾ç‰‡
        
        Args:
            data_url: data: URL (å¦‚ data:image/png;base64,...)
            filename: æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰
        
        Returns:
            æœ¬åœ°æ–‡ä»¶è·¯å¾„ï¼Œå¤±è´¥è¿”å›None
        """
        try:
            # è§£æ data URL
            # æ ¼å¼: data:image/png;base64,iVBORw0KGgo...
            match = re.match(r'data:image/([^;]+);base64,(.+)', data_url)
            if not match:
                logger.error(f"æ— æ•ˆçš„ data URL æ ¼å¼")
                return None
            
            image_format = match.group(1)  # png, jpeg, etc.
            base64_data = match.group(2)
            
            # è§£ç  base64
            image_data = base64.b64decode(base64_data)
            
            # ä¿å­˜å›¾ç‰‡
            local_path = self._save_image_data(image_data, filename, hint_format=image_format)
            
            if local_path:
                # ç¼“å­˜ç»“æœ
                self.downloaded_images[data_url] = local_path
                logger.info(f"æˆåŠŸä¿å­˜ base64 å›¾ç‰‡: {local_path}")
            
            return local_path
            
        except Exception as e:
            logger.error(f"ä¿å­˜ base64 å›¾ç‰‡å¤±è´¥: {e}")
            return None
    
    def _save_image_data(
        self,
        image_data: bytes,
        filename: str,
        hint_format: Optional[str] = None
    ) -> Optional[str]:
        """
        ä¿å­˜å›¾ç‰‡æ•°æ®åˆ°æ–‡ä»¶
        
        Args:
            image_data: å›¾ç‰‡äºŒè¿›åˆ¶æ•°æ®
            filename: æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰
            hint_format: æç¤ºçš„å›¾ç‰‡æ ¼å¼ï¼ˆç”¨äº base64ï¼‰
        
        Returns:
            æœ¬åœ°æ–‡ä»¶è·¯å¾„ï¼Œå¤±è´¥è¿”å›None
        """
        try:
            # å¤„ç†å›¾ç‰‡
            if PIL_AVAILABLE:
                try:
                    # ä½¿ç”¨PILè½¬æ¢æ ¼å¼
                    img = Image.open(BytesIO(image_data))
                    
                    # è½¬æ¢ä¸ºRGBæ¨¡å¼ï¼ˆå¦‚æœæ˜¯RGBAï¼‰
                    if img.mode in ('RGBA', 'LA', 'P'):
                        rgb_img = Image.new('RGB', img.size, (255, 255, 255))
                        if img.mode == 'P':
                            img = img.convert('RGBA')
                        rgb_img.paste(img, mask=img.split()[-1] if img.mode in ('RGBA', 'LA') else None)
                        img = rgb_img
                    
                    # ç¡®ä¿æ˜¯RGBæ¨¡å¼
                    if img.mode != 'RGB':
                        img = img.convert('RGB')
                    
                    # ä¿å­˜
                    output_path = self.output_dir / f"{filename}.{self.format}"
                    # JPEGæ ¼å¼ä¸æ”¯æŒé€æ˜åº¦ï¼Œå¿…é¡»æ˜¯RGB
                    save_format = 'JPEG' if self.format.lower() in ('jpg', 'jpeg') else self.format.upper()
                    img.save(output_path, save_format, quality=90)
                    
                except Exception as e:
                    logger.debug(f"PILå¤„ç†å›¾ç‰‡å¤±è´¥: {e}ï¼Œå°è¯•ç›´æ¥ä¿å­˜")
                    # fallback: ç›´æ¥ä¿å­˜
                    ext = hint_format or self.format
                    output_path = self.output_dir / f"{filename}.{ext}"
                    with open(output_path, 'wb') as f:
                        f.write(image_data)
                
            else:
                # ç›´æ¥ä¿å­˜åŸå§‹å†…å®¹
                ext = hint_format or self.format
                output_path = self.output_dir / f"{filename}.{ext}"
                with open(output_path, 'wb') as f:
                    f.write(image_data)
            
            return str(output_path.name)  # åªè¿”å›æ–‡ä»¶å
            
        except Exception as e:
            logger.error(f"ä¿å­˜å›¾ç‰‡å¤±è´¥: {e}")
            return None
    
    def download_all(
        self,
        urls: List[str],
        headers: Optional[Dict[str, str]] = None,
        referer: Optional[str] = None
    ) -> Dict[str, str]:
        """
        æ‰¹é‡ä¸‹è½½å›¾ç‰‡
        
        Args:
            urls: å›¾ç‰‡URLåˆ—è¡¨
            headers: è¯·æ±‚å¤´
            referer: Referer URL
        
        Returns:
            URLåˆ°æœ¬åœ°è·¯å¾„çš„æ˜ å°„å­—å…¸
        """
        results = {}
        for i, url in enumerate(urls, 1):
            logger.info(f"ä¸‹è½½å›¾ç‰‡ {i}/{len(urls)}")
            local_path = self.download_image(url, headers=headers, referer=referer)
            if local_path:
                results[url] = local_path
        
        logger.info(f"æˆåŠŸä¸‹è½½ {len(results)}/{len(urls)} å¼ å›¾ç‰‡")
        return results
    
    def replace_markdown_images(
        self,
        markdown: str,
        url_mapping: Dict[str, str]
    ) -> str:
        """
        æ›¿æ¢Markdownä¸­çš„å›¾ç‰‡é“¾æ¥ä¸ºæœ¬åœ°è·¯å¾„
        
        Args:
            markdown: Markdownå†…å®¹
            url_mapping: URLåˆ°æœ¬åœ°è·¯å¾„çš„æ˜ å°„
        
        Returns:
            æ›¿æ¢åçš„Markdown
        """
        for url, local_path in url_mapping.items():
            # æ›¿æ¢å„ç§æ ¼å¼çš„å›¾ç‰‡å¼•ç”¨
            markdown = markdown.replace(url, local_path)
            markdown = markdown.replace(f'({url})', f'({local_path})')
            markdown = markdown.replace(f']({url})', f']({local_path})')
        
        return markdown
