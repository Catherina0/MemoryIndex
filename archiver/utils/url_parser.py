"""
URLè§£æå™¨
ç”¨äºæ£€æµ‹URLæ‰€å±çš„å¹³å°
"""

import re
from urllib.parse import urlparse
from typing import Optional


def extract_url_from_text(text: str) -> Optional[str]:
    """
    ä»æ–‡æœ¬ä¸­æå–URLï¼ˆæ”¯æŒä»åˆ†äº«æ–‡æœ¬ä¸­è‡ªåŠ¨æå–ï¼‰
    
    æ”¯æŒçš„åœºæ™¯ï¼š
    - çº¯URLè¾“å…¥
    - URL + å…¶ä»–æ–‡æœ¬ï¼ˆè‡ªåŠ¨æå–URLï¼‰
    - å¤šä¸ªURLï¼ˆè¿”å›ç¬¬ä¸€ä¸ªæœ‰æ•ˆçš„ï¼‰
    
    Args:
        text: è¾“å…¥æ–‡æœ¬ï¼ˆå¯èƒ½åŒ…å«URLå’Œå…¶ä»–å†…å®¹ï¼‰
        
    Returns:
        æå–åˆ°çš„URLï¼Œæˆ–None
    
    ç¤ºä¾‹ï¼š
        >>> extract_url_from_text("57 ã€æ ‡é¢˜ã€‘ ğŸ˜† https://www.xiaohongshu.com/item/123")
        'https://www.xiaohongshu.com/item/123'
    """
    text = text.strip()
    
    # å¦‚æœæ˜¯çº¯URLï¼Œç›´æ¥è¿”å›
    if is_valid_url(text):
        return text
    
    # ä»æ–‡æœ¬ä¸­æå– URLï¼ˆé€šç”¨æ¨¡å¼ï¼‰
    url_pattern = r'https?://[^\s\"\'\u4e00-\u9fff]+'
    match = re.search(url_pattern, text)
    
    if match:
        url = match.group(0)
        # ç§»é™¤å¯èƒ½çš„å°¾éƒ¨æ ‡ç‚¹
        url = url.rstrip('.,;!?')
        return url
    
    return None


def detect_platform(url: str) -> str:
    """
    æ£€æµ‹URLæ‰€å±çš„å¹³å°
    
    Args:
        url: ç›®æ ‡URL
    
    Returns:
        å¹³å°åç§°å­—ç¬¦ä¸²
    """
    parsed = urlparse(url)
    domain = parsed.netloc.lower()
    
    # çŸ¥ä¹
    if 'zhihu.com' in domain:
        return 'zhihu'
    
    # å°çº¢ä¹¦
    if 'xiaohongshu.com' in domain or 'xhslink.com' in domain:
        return 'xiaohongshu'
    
    # Bç«™
    if 'bilibili.com' in domain or 'b23.tv' in domain:
        return 'bilibili'
    
    # Reddit
    if 'reddit.com' in domain:
        return 'reddit'
    
    # é»˜è®¤ä½¿ç”¨WordPress/é€šç”¨é€‚é…å™¨
    return 'wordpress'


def normalize_url(url: str) -> str:
    """
    æ ‡å‡†åŒ–URLæ ¼å¼
    
    Args:
        url: åŸå§‹URL
    
    Returns:
        æ ‡å‡†åŒ–åçš„URL
    """
    # ç¡®ä¿URLæœ‰åè®®
    if not url.startswith(('http://', 'https://')):
        url = 'https://' + url
    
    # ç§»é™¤URLæœ«å°¾çš„æ–œæ 
    url = url.rstrip('/')
    
    return url


def extract_domain(url: str) -> str:
    """
    ä»URLä¸­æå–åŸŸå
    
    Args:
        url: ç›®æ ‡URL
    
    Returns:
        åŸŸåå­—ç¬¦ä¸²
    """
    parsed = urlparse(url)
    return parsed.netloc


def is_valid_url(url: str) -> bool:
    """
    æ£€æŸ¥URLæ˜¯å¦æœ‰æ•ˆ
    
    Args:
        url: å¾…æ£€æŸ¥çš„URL
    
    Returns:
        æ˜¯å¦æœ‰æ•ˆ
    """
    try:
        result = urlparse(url)
        return all([result.scheme, result.netloc])
    except Exception:
        return False
