# process_video.py
import argparse
import os
import subprocess
from pathlib import Path
from datetime import datetime
from dotenv import load_dotenv
from groq import Groq

from ocr_utils import init_ocr, ocr_folder_to_text

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()


# ========== è·¯å¾„/ç›®å½•å¤„ç† ==========
def ensure_dir(path: Path):
    path.mkdir(parents=True, exist_ok=True)


# ========== ffmpeg: éŸ³é¢‘ & æŠ½å¸§ ==========
def extract_audio(video_path: Path, audio_path: Path):
    """
    ç”¨ ffmpeg ä»è§†é¢‘é‡Œåˆ†ç¦»éŸ³é¢‘ï¼Œè¾“å‡ºä¸º wavã€‚
    """
    ensure_dir(audio_path.parent)
    cmd = [
        "ffmpeg",
        "-y",
        "-i", str(video_path),
        "-vn",          # no video
        "-acodec", "pcm_s16le",
        "-ar", "16000",
        "-ac", "1",
        str(audio_path),
    ]
    subprocess.run(cmd, check=True)


def extract_frames(video_path: Path, frames_dir: Path, fps: int = 1):
    """
    ç”¨ ffmpeg æŠ½å¸§ï¼šé»˜è®¤ 1 fpsï¼Œå¯ä»¥åé¢å†è°ƒã€‚
    """
    ensure_dir(frames_dir)
    out_pattern = frames_dir / "frame_%05d.png"
    cmd = [
        "ffmpeg",
        "-y",
        "-i", str(video_path),
        "-vf", f"fps={fps}",
        str(out_pattern),
    ]
    subprocess.run(cmd, check=True)


# ========== Groq API é›†æˆ ==========
def transcribe_audio_with_groq(audio_path: Path) -> str:
    """
    ä½¿ç”¨ Groq çš„ Whisper æ¨¡å‹è¿›è¡Œè¯­éŸ³è½¬æ–‡å­—ã€‚
    """
    api_key = os.getenv("GROQ_API_KEY")
    if not api_key:
        print("  âš ï¸  GROQ_API_KEY æœªè®¾ç½®ï¼Œä½¿ç”¨å ä½ç¬¦")
        return f"[FAKE TRANSCRIPT for {audio_path.name}] è¯·åœ¨ .env ä¸­è®¾ç½® GROQ_API_KEY"
    
    try:
        client = Groq(api_key=api_key)
        model = os.getenv("GROQ_ASR_MODEL", "whisper-large-v3-turbo")
        
        with open(audio_path, "rb") as audio_file:
            transcription = client.audio.transcriptions.create(
                file=(audio_path.name, audio_file.read()),
                model=model,
                response_format="text",
            )
        
        return transcription
    except Exception as e:
        print(f"  âœ— Groq è½¬å†™å¤±è´¥: {e}")
        return f"[è½¬å†™å¤±è´¥: {str(e)}]"


def summarize_with_gpt_oss_120b(full_text: str) -> str:
    """
    ä½¿ç”¨ Groq çš„ LLM è¿›è¡Œæ–‡æœ¬æ€»ç»“ã€‚
    """
    api_key = os.getenv("GROQ_API_KEY")
    if not api_key:
        print("  âš ï¸  GROQ_API_KEY æœªè®¾ç½®ï¼Œè¿”å›åŸæ–‡")
        return f"[FAKE SUMMARY - è¯·åœ¨ .env ä¸­è®¾ç½® GROQ_API_KEY]\n\n{full_text}"
    
    try:
        client = Groq(api_key=api_key)
        model = os.getenv("GROQ_LLM_MODEL", "openai/gpt-oss-120b")
        max_tokens = int(os.getenv("GROQ_MAX_TOKENS", "4096"))
        temperature = float(os.getenv("GROQ_TEMPERATURE", "0.7"))
        
        prompt = f"""è¯·å¯¹ä»¥ä¸‹å†…å®¹è¿›è¡Œæ€»ç»“åˆ†æï¼š

å†…å®¹ï¼š
{full_text[:30000]}  # é™åˆ¶é•¿åº¦é¿å…è¶…å‡º token é™åˆ¶

è¦æ±‚ï¼š
1. æå–æ ¸å¿ƒè¦ç‚¹å’Œå…³é”®ä¿¡æ¯
2. ä¿ç•™é‡è¦çš„æ•°å­—ã€å¼•ç”¨å’Œäº‹å®
3. æŒ‰é€»è¾‘ç»“æ„ç»„ç»‡å†…å®¹
4. å¦‚æœæœ‰ OCR å†…å®¹ï¼Œé‡ç‚¹å…³æ³¨å±å¹•ä¸Šçš„æ–‡å­—ä¿¡æ¯
5. æ€»ç»“é•¿åº¦é€‚ä¸­ï¼Œä¾¿äºå¿«é€Ÿç†è§£

è¯·ç”¨ä¸­æ–‡å›ç­”ã€‚"""

        response = client.chat.completions.create(
            model=model,
            messages=[
                {
                    "role": "system",
                    "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å†…å®¹åˆ†æåŠ©æ‰‹ï¼Œæ“…é•¿ä»è§†é¢‘è½¬å†™å’Œå±å¹•æ–‡å­—ä¸­æå–å…³é”®ä¿¡æ¯ã€‚"
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            max_tokens=max_tokens,
            temperature=temperature,
        )
        
        return response.choices[0].message.content
    except Exception as e:
        print(f"  âœ— Groq æ€»ç»“å¤±è´¥: {e}")
        return f"[æ€»ç»“å¤±è´¥: {str(e)}]\n\nåŸå§‹å†…å®¹:\n{full_text}"


def generate_formatted_report(
    video_name: str,
    timestamp: str,
    transcript_text: str,
    ocr_text: str,
    summary: str,
    with_frames: bool,
    session_dir: Path
) -> str:
    """
    ç”Ÿæˆæ ¼å¼åŒ–çš„æŠ¥å‘Šï¼ŒåŒ…å«å…ƒä¿¡æ¯ã€AIæ€»ç»“å’ŒåŸå§‹æ•°æ®
    """
    # ç»Ÿè®¡ä¿¡æ¯
    transcript_chars = len(transcript_text)
    transcript_lines = transcript_text.count('\n')
    ocr_chars = len(ocr_text) if ocr_text else 0
    ocr_lines = ocr_text.count('\n') if ocr_text else 0
    
    # æ ¼å¼åŒ–æ—¶é—´
    dt = datetime.strptime(timestamp, "%Y%m%d_%H%M%S")
    formatted_time = dt.strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S")
    
    report = []
    report.append("=" * 70)
    report.append("ğŸ“¹ è§†é¢‘åˆ†ææŠ¥å‘Š")
    report.append("=" * 70)
    report.append("")
    report.append(f"ğŸ“ è§†é¢‘åç§°: {video_name}")
    report.append(f"ğŸ•’ å¤„ç†æ—¶é—´: {formatted_time}")
    report.append(f"ğŸ“ è¾“å‡ºç›®å½•: {session_dir.name}")
    report.append(f"ğŸ”§ å¤„ç†æ¨¡å¼: {'å®Œæ•´æ¨¡å¼ (OCR + éŸ³é¢‘)' if with_frames else 'éŸ³é¢‘æ¨¡å¼'}")
    report.append("")
    report.append("ğŸ“Š æ•°æ®ç»Ÿè®¡:")
    report.append(f"   â€¢ è¯­éŸ³è¯†åˆ«: {transcript_chars} å­—ç¬¦, {transcript_lines} è¡Œ")
    if with_frames:
        report.append(f"   â€¢ OCRè¯†åˆ«:  {ocr_chars} å­—ç¬¦, {ocr_lines} è¡Œ")
    report.append("")
    report.append("=" * 70)
    report.append("")
    
    # AI æ€»ç»“
    report.append("ğŸ¤– AI æ™ºèƒ½æ€»ç»“")
    report.append("-" * 70)
    report.append("")
    report.append(summary)
    report.append("")
    report.append("=" * 70)
    report.append("")
    
    # åŸå§‹æ•°æ®å¼•ç”¨
    report.append("ğŸ“‚ åŸå§‹æ•°æ®æ–‡ä»¶")
    report.append("-" * 70)
    report.append("")
    report.append(f"â€¢ è¯­éŸ³è¯†åˆ«åŸæ–‡: transcript_raw.txt ({transcript_chars} å­—ç¬¦)")
    if with_frames:
        report.append(f"â€¢ OCRè¯†åˆ«åŸæ–‡:  ocr_raw.txt ({ocr_chars} å­—ç¬¦)")
        report.append(f"â€¢ è§†é¢‘å¸§å›¾ç‰‡:   frames/ ç›®å½•")
    report.append(f"â€¢ éŸ³é¢‘æ–‡ä»¶:     {video_name}.wav")
    report.append("")
    report.append("ğŸ’¡ æç¤º: æŸ¥çœ‹åŸå§‹æ•°æ®æ–‡ä»¶è·å–å®Œæ•´çš„è¯†åˆ«å†…å®¹")
    report.append("")
    report.append("=" * 70)
    report.append(f"ğŸ“Œ æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {formatted_time}")
    report.append("=" * 70)
    
    return "\n".join(report)


# ========== ä¸»æ§åˆ¶æµç¨‹ ==========
def process_video(
    video_path: Path,
    output_dir: Path,
    with_frames: bool = False,
    ocr_lang: str = "ch",
    ocr_det_model: str = "mobile",
    ocr_rec_model: str = "mobile",
    use_gpu: bool = False,
):
    ensure_dir(output_dir)

    # 1. åˆ›å»ºå¸¦æ—¶é—´æˆ³çš„è¾“å‡ºæ–‡ä»¶å¤¹
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    video_name = video_path.stem
    session_dir = output_dir / f"{video_name}_{timestamp}"
    ensure_dir(session_dir)
    
    # 2. å„ç±»æ–‡ä»¶è·¯å¾„
    audio_path = session_dir / f"{video_name}.wav"
    frames_dir = session_dir / "frames"
    ocr_raw_path = session_dir / "ocr_raw.txt"
    transcript_raw_path = session_dir / "transcript_raw.txt"
    report_path = session_dir / "report.txt"
    
    print(f"\nğŸ“ è¾“å‡ºç›®å½•: {session_dir}")
    print(f"   æ—¶é—´æˆ³: {timestamp}\n")

    ocr_text = ""
    transcript_text = ""
    
    # 2. å¦‚æœæ˜¯OCRæ¨¡å¼ï¼Œå…ˆå¤„ç†è§†é¢‘å¸§å’ŒOCR
    if with_frames:
        print("\n" + "="*60)
        print("ğŸ“¹ ç¬¬ä¸€æ­¥ï¼šå¤„ç†è§†é¢‘å¸§ OCR")
        print("="*60)
        
        print(">> æŠ½å¸§ä¸­...")
        extract_frames(video_path, frames_dir, fps=1)

        print(f"\n>> åˆå§‹åŒ–æœ¬åœ° OCR (det={ocr_det_model}, rec={ocr_rec_model})...")
        ocr = init_ocr(
            lang=ocr_lang,
            use_gpu=use_gpu,
            det_model=ocr_det_model,
            rec_model=ocr_rec_model
        )

        print("\n>> å¯¹æ‰€æœ‰å¸§åš OCRï¼ˆå¸¦è¿›åº¦æ˜¾ç¤ºï¼‰...")
        ocr_text = ocr_folder_to_text(ocr, str(frames_dir))
        
        print()  # ç©ºè¡Œ
        if ocr_text.strip():
            char_count = len(ocr_text)
            line_count = ocr_text.count('\n')
            print(f"âœ… OCR å®Œæˆï¼è¯†åˆ«åˆ° {char_count} ä¸ªå­—ç¬¦ï¼Œ{line_count} è¡Œæ–‡æœ¬")
            
            # ä¿å­˜OCRåŸå§‹ç»“æœ
            print(f"   ğŸ’¾ ä¿å­˜OCRåŸå§‹ç»“æœ: {ocr_raw_path.name}")
            ocr_raw_path.write_text(ocr_text, encoding="utf-8")
        else:
            print("âš ï¸  è­¦å‘Šï¼šOCR æœªè¯†åˆ«åˆ°ä»»ä½•æ–‡å­—ï¼ˆå¯èƒ½è§†é¢‘ä¸­æ²¡æœ‰æ–‡å­—å†…å®¹ï¼‰")
        
        print("\n" + "="*60)
        print("ğŸ¤ ç¬¬äºŒæ­¥ï¼šå¤„ç†éŸ³é¢‘è½¬å†™")
        print("="*60)
    
    # 3. å¤„ç†éŸ³é¢‘ï¼ˆOCRæ¨¡å¼åœ¨OCRä¹‹åï¼Œæ™®é€šæ¨¡å¼ç›´æ¥å¤„ç†ï¼‰
    print(">> æå–éŸ³é¢‘ä¸­...")
    extract_audio(video_path, audio_path)

    # 4. Groq è¯­éŸ³è½¬æ–‡å­—ï¼ˆå ä½ï¼‰
    print(">> è°ƒç”¨ Groq è¯­éŸ³è½¬å†™ï¼ˆå ä½ï¼‰...")
    transcript_text = transcribe_audio_with_groq(audio_path)
    
    # ä¿å­˜è¯­éŸ³è¯†åˆ«åŸå§‹ç»“æœ
    if transcript_text.strip():
        print(f"   ğŸ’¾ ä¿å­˜è¯­éŸ³è¯†åˆ«åŸå§‹ç»“æœ: {transcript_raw_path.name}")
        transcript_raw_path.write_text(transcript_text, encoding="utf-8")

    # 5. åˆå¹¶æ–‡æœ¬ï¼šéŸ³é¢‘æ–‡å­— + OCR ç»“æœ
    combined_text_parts = [f"=== Audio Transcript ===\n{transcript_text}\n"]
    if with_frames:
        combined_text_parts.append(f"\n\n=== OCR from Frames ===\n{ocr_text}\n")

    combined_text = "\n".join(combined_text_parts)

    # 6. è°ƒ GPT-OSS 120B åšæ€»ç»“ï¼ˆå ä½ï¼‰
    print("\n>> è°ƒç”¨ GPT-OSS 120B åšæ€»ç»“ï¼ˆå ä½ï¼‰...")
    summary = summarize_with_gpt_oss_120b(combined_text)

    # 7. ç”Ÿæˆæ ¼å¼åŒ–æŠ¥å‘Š
    report_content = generate_formatted_report(
        video_name=video_name,
        timestamp=timestamp,
        transcript_text=transcript_text,
        ocr_text=ocr_text,
        summary=summary,
        with_frames=with_frames,
        session_dir=session_dir
    )
    
    report_path.write_text(report_content, encoding="utf-8")
    print(f"\nğŸ“„ æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")
    print(f"ğŸ“ å®Œæ•´è¾“å‡ºç›®å½•: {session_dir}")


# ========== CLI ==========
def main():
    parser = argparse.ArgumentParser(description="Video â†’ Text Report pipeline")
    parser.add_argument("video", type=str, help="è¾“å…¥è§†é¢‘è·¯å¾„")
    parser.add_argument(
        "--with-frames",
        action="store_true",
        help="æ˜¯å¦å¯ç”¨æŠ½å¸§ + OCR åˆ†æ”¯",
    )
    parser.add_argument(
        "--out-dir",
        type=str,
        default="output",
        help="è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤: ./outputï¼‰",
    )
    parser.add_argument(
        "--ocr-lang",
        type=str,
        default="ch",
        help="PaddleOCR è¯­è¨€ï¼ˆé»˜è®¤: chï¼‰",
    )
    parser.add_argument(
        "--ocr-det-model",
        type=str,
        default="mobile",
        choices=["server", "mobile"],
        help="OCR æ£€æµ‹æ¨¡å‹ç±»å‹ï¼ˆé»˜è®¤: mobileï¼‰",
    )
    parser.add_argument(
        "--ocr-rec-model",
        type=str,
        default="mobile",
        choices=["server", "mobile"],
        help="OCR è¯†åˆ«æ¨¡å‹ç±»å‹ï¼ˆé»˜è®¤: mobileï¼‰",
    )
    parser.add_argument(
        "--use-gpu",
        action="store_true",
        help="æ˜¯å¦ä½¿ç”¨ GPU åŠ é€Ÿ",
    )

    args = parser.parse_args()

    video_path = Path(args.video).resolve()
    output_dir = Path(args.out_dir).resolve()

    process_video(
        video_path=video_path,
        output_dir=output_dir,
        with_frames=args.with_frames,
        ocr_lang=args.ocr_lang,
        ocr_det_model=args.ocr_det_model,
        ocr_rec_model=args.ocr_rec_model,
        use_gpu=args.use_gpu,
    )


if __name__ == "__main__":
    main()
