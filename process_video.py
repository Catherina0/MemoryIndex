# process_video.py
import argparse
import os
import subprocess
from pathlib import Path
from datetime import datetime
from dotenv import load_dotenv
from groq import Groq

from ocr_utils import init_ocr, ocr_folder_to_text

# å¯é€‰ï¼šæ”¯æŒä» URL ç›´æ¥ä¸‹è½½
try:
    from video_downloader import VideoDownloader
    DOWNLOADER_AVAILABLE = True
except ImportError:
    DOWNLOADER_AVAILABLE = False

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()


# ========== è·¯å¾„/ç›®å½•å¤„ç† ==========
def ensure_dir(path: Path):
    path.mkdir(parents=True, exist_ok=True)


# ========== ffmpeg: éŸ³é¢‘ & æŠ½å¸§ ==========
def extract_audio(video_path: Path, audio_path: Path):
    """
    ç”¨ ffmpeg ä»è§†é¢‘é‡Œåˆ†ç¦»éŸ³é¢‘ï¼Œè¾“å‡ºä¸º wavã€‚
    """
    ensure_dir(audio_path.parent)
    cmd = [
        "ffmpeg",
        "-y",
        "-i", str(video_path),
        "-vn",          # no video
        "-acodec", "pcm_s16le",
        "-ar", "16000",
        "-ac", "1",
        str(audio_path),
    ]
    subprocess.run(cmd, check=True)


def extract_frames(video_path: Path, frames_dir: Path, fps: int = 1):
    """
    ç”¨ ffmpeg æŠ½å¸§ï¼šé»˜è®¤ 1 fpsï¼ˆæ¯ç§’ä¸€å¸§ï¼‰ã€‚
    å¸§ç¼–å·ä» 1 å¼€å§‹ï¼Œframe_00001.png å¯¹åº”ç¬¬ 0-1 ç§’ã€‚
    """
    ensure_dir(frames_dir)
    out_pattern = frames_dir / "frame_%05d.png"
    cmd = [
        "ffmpeg",
        "-y",
        "-i", str(video_path),
        "-vf", f"fps={fps}",
        str(out_pattern),
    ]
    subprocess.run(cmd, check=True)


def match_audio_with_frames(transcript_data: dict, frames_dir: Path, fps: int = 1) -> list:
    """
    éŸ³ç”»åŒ¹é…ï¼šå°†éŸ³é¢‘è½¬å†™ç‰‡æ®µä¸è§†é¢‘å¸§å…³è”ã€‚
    
    Args:
        transcript_data: åŒ…å« segments çš„è½¬å†™æ•°æ®
        frames_dir: è§†é¢‘å¸§ç›®å½•
        fps: æŠ½å¸§é¢‘ç‡ï¼ˆæ¯ç§’å¸§æ•°ï¼‰
    
    Returns:
        list: [{'second': 0, 'frame': 'frame_00001.png', 'text': 'å¯¹åº”çš„æ–‡æœ¬'}, ...]
    """
    import glob
    
    # è·å–æ‰€æœ‰å¸§æ–‡ä»¶
    frame_files = sorted(glob.glob(str(frames_dir / "frame_*.png")))
    frame_count = len(frame_files)
    
    # ä¸ºæ¯ä¸€ç§’å»ºç«‹æ–‡æœ¬ç´¢å¼•
    timeline = []
    
    for i in range(frame_count):
        second = i  # å¸§ç¼–å·ä»1å¼€å§‹ï¼Œå¯¹åº”ç¬¬ i ç§’
        frame_name = f"frame_{i+1:05d}.png"
        
        # æŸ¥æ‰¾è¿™ä¸€ç§’å¯¹åº”çš„æ–‡æœ¬
        texts_in_second = []
        if 'segments' in transcript_data:
            for seg in transcript_data['segments']:
                seg_start = int(seg['start'])
                seg_end = int(seg['end'])
                # å¦‚æœç‰‡æ®µè¦†ç›–å½“å‰ç§’
                if seg_start <= second < seg_end:
                    texts_in_second.append(seg['text'].strip())
        
        timeline.append({
            'second': second,
            'frame': frame_name,
            'text': ' '.join(texts_in_second) if texts_in_second else ''
        })
    
    return timeline


# ========== Groq API é›†æˆ ==========
def transcribe_audio_with_groq(audio_path: Path) -> dict:
    """
    ä½¿ç”¨ Groq çš„ Whisper æ¨¡å‹è¿›è¡Œè¯­éŸ³è½¬æ–‡å­—ï¼Œè¿”å›å¸¦æ—¶é—´æˆ³çš„æ•°æ®ã€‚
    
    Returns:
        dict: {
            'text': 'å®Œæ•´æ–‡æœ¬',
            'segments': [{'start': 0.0, 'end': 2.5, 'text': 'ç‰‡æ®µæ–‡æœ¬'}, ...]
        }
    """
    api_key = os.getenv("GROQ_API_KEY")
    if not api_key:
        print("  âš ï¸  GROQ_API_KEY æœªè®¾ç½®ï¼Œä½¿ç”¨å ä½ç¬¦")
        return {
            'text': f"[FAKE TRANSCRIPT for {audio_path.name}] è¯·åœ¨ .env ä¸­è®¾ç½® GROQ_API_KEY",
            'segments': []
        }
    
    try:
        client = Groq(api_key=api_key)
        model = os.getenv("GROQ_ASR_MODEL", "whisper-large-v3-turbo")
        
        with open(audio_path, "rb") as audio_file:
            # ä½¿ç”¨ verbose_json æ ¼å¼è·å–æ—¶é—´æˆ³ä¿¡æ¯
            transcription = client.audio.transcriptions.create(
                file=(audio_path.name, audio_file.read()),
                model=model,
                response_format="verbose_json",
                timestamp_granularities=["segment"]
            )
        
        # æå–æ–‡æœ¬å’Œæ—¶é—´æˆ³ç‰‡æ®µ
        result = {
            'text': transcription.text,
            'segments': []
        }
        
        if hasattr(transcription, 'segments') and transcription.segments:
            for seg in transcription.segments:
                result['segments'].append({
                    'start': seg.get('start', 0),
                    'end': seg.get('end', 0),
                    'text': seg.get('text', '')
                })
        
        return result
    except Exception as e:
        print(f"  âœ— Groq è½¬å†™å¤±è´¥: {e}")
        return {
            'text': f"[è½¬å†™å¤±è´¥: {str(e)}]",
            'segments': []
        }


def summarize_with_gpt_oss_120b(full_text: str) -> str:
    """
    ä½¿ç”¨ Groq çš„ LLM è¿›è¡Œæ–‡æœ¬æ€»ç»“ã€‚
    """
    api_key = os.getenv("GROQ_API_KEY")
    if not api_key:
        print("  âš ï¸  GROQ_API_KEY æœªè®¾ç½®ï¼Œè¿”å›åŸæ–‡")
        return f"[FAKE SUMMARY - è¯·åœ¨ .env ä¸­è®¾ç½® GROQ_API_KEY]\n\n{full_text}"
    
    try:
        client = Groq(api_key=api_key)
        model = os.getenv("GROQ_LLM_MODEL", "openai/gpt-oss-120b")
        # å¢åŠ  token é™åˆ¶ä»¥æ”¯æŒæ›´é•¿çš„è¾“å‡º
        max_tokens = int(os.getenv("GROQ_MAX_TOKENS", "8192"))  # ä» 4096 æå‡åˆ° 8192
        temperature = float(os.getenv("GROQ_TEMPERATURE", "0.7"))
        
        prompt = f"""

è¯·å°†ä»¥ä¸‹â€œå¸¦æ—¶é—´æˆ³çš„éŸ³é¢‘è½¬å†™ + OCR æ–‡æœ¬â€æ•´ç†æˆä¸€ä»½**ç»“æ„åŒ– Markdown çŸ¥è¯†æ¡£æ¡ˆ**ã€‚

ä½ éœ€è¦ï¼š
1. **ä½¿ç”¨ Markdown** è¾“å‡ºï¼ˆæ ‡é¢˜ã€åˆ—è¡¨ã€å¼•ç”¨ã€è¡¨æ ¼ç­‰ï¼‰
2. æŒ‰æ—¶é—´é¡ºåºæ¢³ç†ä¸»è¦ç‰‡æ®µï¼Œå¹¶ä¸ºå…³é”®å†…å®¹æ ‡æ³¨å¯¹åº”æ—¶é—´æˆ³
3. åˆå¹¶éŸ³é¢‘ä¸ OCR å†…å®¹ï¼š  
   - å¦‚æœ OCR æ–‡å­—ä¸å®Œæ•´ï¼Œè¯·æ ¹æ®ä¸Šä¸‹æ–‡**æ¨æ–­åˆç†å«ä¹‰**  
   - å¦‚æœæŸäº›å±å¹•æ–‡å­—é‡è¦ï¼ˆå¦‚ PPTã€ç•Œé¢æŒ‰é’®ã€å‚æ•°ã€ä»£ç ï¼‰ï¼Œè¯·å•ç‹¬æå–å¹¶è§£é‡Š
4. è‡ªåŠ¨è¯†åˆ«â€œä¸»é¢˜/ç« èŠ‚â€å¹¶ç»“æ„åŒ–æ€»ç»“ï¼šæ¦‚å¿µã€æ­¥éª¤ã€åœºæ™¯ã€ç»“è®º
5. æå–é‡è¦æ•°æ®ï¼šæ•°å­—ã€é˜ˆå€¼ã€è§„åˆ™ã€å¼•ç”¨ã€å‘½ä»¤ã€æ—¥æœŸç­‰
6. ä¸ºæœªæ¥æ£€ç´¢ç”Ÿæˆè‹¥å¹²å…³é”®è¯ï¼ˆtagsï¼‰
7. ç¨å¾®è¯¦ç»†ä¸€äº›ï¼Œä½†ä¸è¦å†™åºŸè¯ï¼ˆé‡ç‚¹æ˜¯**å¯å›æº¯ã€å¯æœç´¢ã€å¯ç†è§£**ï¼‰

æ¨èç»“æ„ï¼š
## å†…å®¹æ¦‚è§ˆ
## æ—¶é—´çº¿ï¼ˆå…³é”®ç‰‡æ®µ + æ—¶é—´æˆ³ï¼‰
## ä¸»é¢˜æ€»ç»“ï¼ˆè‡ªåŠ¨ç”Ÿæˆä¸»é¢˜åï¼‰
## è¯¦ç»†è¯´æ˜ï¼ˆåˆå¹¶éŸ³é¢‘ä¸ OCRï¼‰
## OCR ä¿¡æ¯ä¸æ¨æ–­ï¼ˆåˆ—å‡ºé‡è¦å±å¹•æ–‡å­—å¹¶è§£é‡Šï¼‰
## å…³é”®ä¿¡æ¯ï¼ˆæ•°å­—ã€è§„åˆ™ã€å‚æ•°ï¼‰
## å…³é”®å¥ï¼ˆå«æ—¶é—´æˆ³ï¼‰
## æ ‡ç­¾ï¼ˆtagsï¼‰

ä»¥ä¸‹æ˜¯å†…å®¹ï¼š
{full_text[:40000]}  



"""

        response = client.chat.completions.create(
            model=model,
            messages=[
                {
                    "role": "system",
                    "content": """ä½ æ˜¯ä¸€ä¸ªå¤šæ¨¡æ€çŸ¥è¯†æ¡£æ¡ˆç”Ÿæˆå™¨ã€‚

                    è¾“å…¥æ¥è‡ªåŒä¸€æ®µè§†é¢‘ï¼ŒåŒ…æ‹¬ï¼š
                    - å¸¦æ—¶é—´æˆ³çš„éŸ³é¢‘è½¬å†™
                    - å¸¦æ—¶é—´æˆ³æˆ–å¸§åºåˆ—çš„ OCR æ–‡æœ¬

                    ä½ çš„èŒè´£æ˜¯ï¼š
                    - èåˆéŸ³é¢‘ä¸ OCR å†…å®¹
                    - åˆ©ç”¨æ—¶é—´æˆ³é‡å»ºç»“æ„ä¸é¡ºåº
                    - æ ¹æ®å†…å®¹è‡ªåŠ¨è¯†åˆ«ä¸»é¢˜ä¸é‡ç‚¹
                    - æ¨æ–­çº æ­£ OCR å¯èƒ½çš„é”™è¯¯
                    - ç”Ÿæˆæ¸…æ™°ã€å¯é•¿æœŸä¿å­˜ã€é€‚åˆæ£€ç´¢çš„ Markdown çŸ¥è¯†æ¡£æ¡ˆ"""
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            max_tokens=max_tokens,
            temperature=temperature,
        )
        
        return response.choices[0].message.content
    except Exception as e:
        print(f"  âœ— Groq æ€»ç»“å¤±è´¥: {e}")
        return f"[æ€»ç»“å¤±è´¥: {str(e)}]\n\nåŸå§‹å†…å®¹:\n{full_text}"


def generate_timeline_report(timeline: list, output_path: Path):
    """
    ç”ŸæˆéŸ³ç”»æ—¶é—´è½´å¯¹ç…§æŠ¥å‘Š
    
    Args:
        timeline: éŸ³ç”»åŒ¹é…çš„æ—¶é—´è½´æ•°æ®
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    report = []
    report.append("# ğŸ¬ éŸ³ç”»æ—¶é—´è½´å¯¹ç…§\n")
    report.append(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}  \n")
    report.append(f"**æ€»æ—¶é•¿**: {len(timeline)} ç§’  \n")
    report.append("\n---\n")
    
    report.append("## ğŸ“Š é€ç§’å¯¹ç…§è¡¨\n")
    
    for item in timeline:
        second = item['second']
        frame = item['frame']
        text = item['text']
        
        # æ ¼å¼åŒ–æ—¶é—´
        minutes = second // 60
        seconds = second % 60
        time_str = f"{minutes:02d}:{seconds:02d}"
        
        report.append(f"### [{time_str}] ç¬¬ {second} ç§’\n")
        report.append(f"**ç”»é¢**: `{frame}`  \n")
        if text:
            report.append(f"**éŸ³é¢‘**: {text}\n")
        else:
            report.append(f"**éŸ³é¢‘**: *(æ— è¯­éŸ³)*\n")
        report.append("\n")
    
    output_path.write_text('\n'.join(report), encoding='utf-8')


def generate_formatted_report(
    video_name: str,
    timestamp: str,
    transcript_text: str,
    ocr_text: str,
    summary: str,
    with_frames: bool,
    session_dir: Path,
    timeline: list = None
) -> str:
    """
    ç”Ÿæˆæ ¼å¼åŒ–çš„æŠ¥å‘Šï¼ŒåŒ…å«å…ƒä¿¡æ¯ã€AIæ€»ç»“å’ŒåŸå§‹æ•°æ®
    """
    # ç»Ÿè®¡ä¿¡æ¯
    transcript_chars = len(transcript_text)
    transcript_lines = transcript_text.count('\n')
    ocr_chars = len(ocr_text) if ocr_text else 0
    ocr_lines = ocr_text.count('\n') if ocr_text else 0
    
    # æ ¼å¼åŒ–æ—¶é—´
    dt = datetime.strptime(timestamp, "%Y%m%d_%H%M%S")
    formatted_time = dt.strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S")
    
    # ä½¿ç”¨ Markdown æ ¼å¼
    report = []
    report.append("# ğŸ“¹ è§†é¢‘åˆ†ææŠ¥å‘Š\n")
    report.append(f"**ğŸ“ è§†é¢‘åç§°**: {video_name}  ")
    report.append(f"**ğŸ•’ å¤„ç†æ—¶é—´**: {formatted_time}  ")
    report.append(f"**ğŸ“ è¾“å‡ºç›®å½•**: `{session_dir.name}`  ")
    report.append(f"**ğŸ”§ å¤„ç†æ¨¡å¼**: {'å®Œæ•´æ¨¡å¼ (OCR + éŸ³é¢‘)' if with_frames else 'éŸ³é¢‘æ¨¡å¼'}  ")
    report.append("\n---\n")
    report.append("## ğŸ“Š æ•°æ®ç»Ÿè®¡\n")
    report.append(f"- **è¯­éŸ³è¯†åˆ«**: {transcript_chars} å­—ç¬¦, {transcript_lines} è¡Œ")
    if with_frames:
        report.append(f"- **OCRè¯†åˆ«**: {ocr_chars} å­—ç¬¦, {ocr_lines} è¡Œ")
    report.append("\n---\n")
    
    # AI æ€»ç»“ï¼ˆå·²ç»æ˜¯ markdown æ ¼å¼ï¼‰
    report.append("## ğŸ¤– AI æ™ºèƒ½æ€»ç»“\n")
    report.append(summary)
    report.append("\n---\n")
    
    # åŸå§‹æ•°æ®å¼•ç”¨
    report.append("## ğŸ“‚ åŸå§‹æ•°æ®æ–‡ä»¶\n")
    report.append(f"- ğŸ“„ [è¯­éŸ³è¯†åˆ«åŸæ–‡](transcript_raw.md) ({transcript_chars} å­—ç¬¦)")
    if with_frames:
        report.append(f"- ğŸ“„ [OCRè¯†åˆ«åŸæ–‡](ocr_raw.md) ({ocr_chars} å­—ç¬¦)")
        report.append(f"- ğŸ“ è§†é¢‘å¸§å›¾ç‰‡: `frames/` ç›®å½•")
        if timeline:
            report.append(f"- ğŸ¬ [éŸ³ç”»æ—¶é—´è½´å¯¹ç…§](timeline.md) (é€ç§’åŒ¹é…)")
    report.append(f"- ğŸ”Š éŸ³é¢‘æ–‡ä»¶: `{video_name}.wav`")
    report.append("\n> ğŸ’¡ **æç¤º**: ç‚¹å‡»é“¾æ¥æŸ¥çœ‹åŸå§‹æ•°æ®æ–‡ä»¶è·å–å®Œæ•´çš„è¯†åˆ«å†…å®¹\n")
    report.append("---\n")
    report.append(f"*ğŸ“Œ æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {formatted_time}*")
    
    return "\n".join(report)


# ========== ä¸»æ§åˆ¶æµç¨‹ ==========
def process_video(
    video_path: Path,
    output_dir: Path,
    with_frames: bool = False,
    ocr_lang: str = "ch",
    ocr_det_model: str = "mobile",
    ocr_rec_model: str = "mobile",
    use_gpu: bool = False,
):
    ensure_dir(output_dir)

    # 1. åˆ›å»ºå¸¦æ—¶é—´æˆ³çš„è¾“å‡ºæ–‡ä»¶å¤¹
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    video_name = video_path.stem
    session_dir = output_dir / f"{video_name}_{timestamp}"
    ensure_dir(session_dir)
    
    # 2. å„ç±»æ–‡ä»¶è·¯å¾„
    audio_path = session_dir / f"{video_name}.wav"
    frames_dir = session_dir / "frames"
    ocr_raw_path = session_dir / "ocr_raw.md"
    transcript_raw_path = session_dir / "transcript_raw.md"
    report_path = session_dir / "report.md"
    
    print(f"\nğŸ“ è¾“å‡ºç›®å½•: {session_dir}")
    print(f"   æ—¶é—´æˆ³: {timestamp}\n")

    ocr_text = ""
    transcript_text = ""
    
    # 2. å¦‚æœæ˜¯OCRæ¨¡å¼ï¼Œå…ˆå¤„ç†è§†é¢‘å¸§å’ŒOCR
    if with_frames:
        print("\n" + "="*60)
        print("ğŸ“¹ ç¬¬ä¸€æ­¥ï¼šå¤„ç†è§†é¢‘å¸§ OCR")
        print("="*60)
        
        print(">> æŠ½å¸§ä¸­...")
        extract_frames(video_path, frames_dir, fps=1)

        print(f"\n>> åˆå§‹åŒ–æœ¬åœ° OCR (det={ocr_det_model}, rec={ocr_rec_model})...")
        ocr = init_ocr(
            lang=ocr_lang,
            use_gpu=use_gpu,
            det_model=ocr_det_model,
            rec_model=ocr_rec_model
        )

        print("\n>> å¯¹æ‰€æœ‰å¸§åš OCRï¼ˆPP-OCRv4 Server + é¢„å¤„ç† + æ··åˆæ¨¡å¼ï¼‰...")
        # ä½¿ç”¨æ··åˆæ¨¡å¼ï¼šåŒæ—¶è¯†åˆ«åº•éƒ¨å­—å¹•å’Œç”»é¢å…¶ä»–æ–‡å­—
        ocr_text = ocr_folder_to_text(
            ocr, 
            str(frames_dir), 
            min_score=0.3,  # è¯†åˆ«é˜¶æ®µä¸¥æ ¼ï¼šåªä¿ç•™é«˜ç½®ä¿¡åº¦ç»“æœ
            debug=False,
            use_preprocessing=True,  # å¯ç”¨å›¾åƒé¢„å¤„ç†ï¼ˆå¯¹æ¯”åº¦+é”åŒ–ï¼‰
            roi_bottom_only=True,    # åœ¨å•ä¸€æ¨¡å¼ä¸‹ç”Ÿæ•ˆ
            hybrid_mode=True,        # ã€æ··åˆæ¨¡å¼ã€‘åŒæ—¶è¯†åˆ«å­—å¹•åŒºå’Œå…¨ç”»é¢
        )
        
        print()  # ç©ºè¡Œ
        if ocr_text.strip():
            char_count = len(ocr_text)
            line_count = ocr_text.count('\n')
            print(f"âœ… OCR å®Œæˆï¼è¯†åˆ«åˆ° {char_count} ä¸ªå­—ç¬¦ï¼Œ{line_count} è¡Œæ–‡æœ¬")
            
            # ä¿å­˜OCRåŸå§‹ç»“æœï¼ˆMarkdown æ ¼å¼ï¼‰
            print(f"   ğŸ’¾ ä¿å­˜OCRåŸå§‹ç»“æœ: {ocr_raw_path.name}")
            ocr_markdown = f"# ğŸ” OCR è¯†åˆ«åŸå§‹æ•°æ®\n\n"
            ocr_markdown += f"**è¯†åˆ«æ—¶é—´**: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}  \n"
            ocr_markdown += f"**æ€»å­—ç¬¦æ•°**: {char_count}  \n"
            ocr_markdown += f"**æ€»è¡Œæ•°**: {line_count}  \n"
            ocr_markdown += f"**å¤„ç†æ¨¡å¼**: æ··åˆæ¨¡å¼ï¼ˆå­—å¹•åŒº + å…¨ç”»é¢ï¼‰\n\n"
            ocr_markdown += "---\n\n"
            ocr_markdown += "## ğŸ“ è¯†åˆ«å†…å®¹\n\n"
            ocr_markdown += "```\n"
            ocr_markdown += ocr_text
            ocr_markdown += "\n```\n"
            ocr_raw_path.write_text(ocr_markdown, encoding="utf-8")
        else:
            print("âš ï¸  è­¦å‘Šï¼šOCR æœªè¯†åˆ«åˆ°ä»»ä½•æ–‡å­—ï¼ˆå¯èƒ½è§†é¢‘ä¸­æ²¡æœ‰æ–‡å­—å†…å®¹ï¼‰")
        
        print("\n" + "="*60)
        print("ğŸ¤ ç¬¬äºŒæ­¥ï¼šå¤„ç†éŸ³é¢‘è½¬å†™")
        print("="*60)
    
    # 3. å¤„ç†éŸ³é¢‘ï¼ˆOCRæ¨¡å¼åœ¨OCRä¹‹åï¼Œæ™®é€šæ¨¡å¼ç›´æ¥å¤„ç†ï¼‰
    print(">> æå–éŸ³é¢‘ä¸­...")
    extract_audio(video_path, audio_path)

    # 4. Groq è¯­éŸ³è½¬æ–‡å­—ï¼ˆå¸¦æ—¶é—´æˆ³ï¼‰
    print(">> è°ƒç”¨ Groq è¯­éŸ³è½¬å†™ï¼ˆå¸¦æ—¶é—´æˆ³ï¼‰...")
    transcript_data = transcribe_audio_with_groq(audio_path)
    transcript_text = transcript_data.get('text', '')
    
    # ä¿å­˜è¯­éŸ³è¯†åˆ«åŸå§‹ç»“æœï¼ˆMarkdown æ ¼å¼ï¼ŒåŒ…å«æ—¶é—´æˆ³ï¼‰
    if transcript_text.strip():
        print(f"   ğŸ’¾ ä¿å­˜è¯­éŸ³è¯†åˆ«åŸå§‹ç»“æœ: {transcript_raw_path.name}")
        transcript_markdown = f"# ğŸ¤ è¯­éŸ³è¯†åˆ«åŸå§‹æ•°æ®\n\n"
        transcript_markdown += f"**è¯†åˆ«æ—¶é—´**: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}  \n"
        transcript_markdown += f"**æ€»å­—ç¬¦æ•°**: {len(transcript_text)}  \n"
        transcript_markdown += f"**è¯†åˆ«æ¨¡å‹**: Groq Whisper  \n"
        transcript_markdown += f"**ç‰‡æ®µæ•°é‡**: {len(transcript_data.get('segments', []))}  \n\n"
        transcript_markdown += "---\n\n"
        transcript_markdown += "## ğŸ“ å®Œæ•´è½¬å†™\n\n"
        transcript_markdown += transcript_text + "\n\n"
        
        # æ·»åŠ å¸¦æ—¶é—´æˆ³çš„ç‰‡æ®µ
        if transcript_data.get('segments'):
            transcript_markdown += "---\n\n"
            transcript_markdown += "## â±ï¸ æ—¶é—´æˆ³ç‰‡æ®µ\n\n"
            for seg in transcript_data['segments']:
                start_time = f"{int(seg['start']//60):02d}:{int(seg['start']%60):02d}"
                end_time = f"{int(seg['end']//60):02d}:{int(seg['end']%60):02d}"
                transcript_markdown += f"**[{start_time} - {end_time}]** {seg['text']}\n\n"
        
        transcript_raw_path.write_text(transcript_markdown, encoding="utf-8")

    # 4.5 ç”ŸæˆéŸ³ç”»åŒ¹é…æ—¶é—´è½´
    timeline = None
    if with_frames and transcript_data.get('segments'):
        print(">> ç”ŸæˆéŸ³ç”»æ—¶é—´è½´åŒ¹é…...")
        timeline = match_audio_with_frames(transcript_data, frames_dir, fps=1)
        timeline_path = session_dir / "timeline.md"
        generate_timeline_report(timeline, timeline_path)
        print(f"   ğŸ’¾ ä¿å­˜éŸ³ç”»æ—¶é—´è½´: {timeline_path.name}")

    # 5. åˆå¹¶æ–‡æœ¬ï¼šéŸ³é¢‘æ–‡å­— + OCR ç»“æœ
    combined_text_parts = [f"=== Audio Transcript ===\n{transcript_text}\n"]
    if with_frames:
        combined_text_parts.append(f"\n\n=== OCR from Frames ===\n{ocr_text}\n")

    combined_text = "\n".join(combined_text_parts)

    # 6. è°ƒ GPT-OSS 120B åšæ€»ç»“ï¼ˆå ä½ï¼‰
    print("\n>> è°ƒç”¨ GPT-OSS 120B åšæ€»ç»“ï¼ˆå ä½ï¼‰...")
    summary = summarize_with_gpt_oss_120b(combined_text)

    # 7. ç”Ÿæˆæ ¼å¼åŒ–æŠ¥å‘Š
    report_content = generate_formatted_report(
        video_name=video_name,
        timestamp=timestamp,
        transcript_text=transcript_text,
        ocr_text=ocr_text,
        summary=summary,
        with_frames=with_frames,
        session_dir=session_dir,
        timeline=timeline
    )
    
    report_path.write_text(report_content, encoding="utf-8")
    print(f"\nğŸ“„ æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")
    print(f"ğŸ“ å®Œæ•´è¾“å‡ºç›®å½•: {session_dir}")


# ========== CLI ==========
def main():
    parser = argparse.ArgumentParser(
        description="Video â†’ Text Report pipeline",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•ï¼š
  # å¤„ç†æœ¬åœ°è§†é¢‘æ–‡ä»¶
  python process_video.py video.mp4
  python process_video.py video.mp4 --with-frames
  
  # ä»URLä¸‹è½½å¹¶å¤„ç†ï¼ˆå¦‚æœå®‰è£…äº† video_downloaderï¼‰
  python process_video.py "https://www.youtube.com/watch?v=xxxxx"
  python process_video.py "https://www.bilibili.com/video/BVxxxxx" --with-frames
        """
    )
    parser.add_argument("video", type=str, help="è¾“å…¥è§†é¢‘è·¯å¾„æˆ–URL")
    parser.add_argument(
        "--with-frames",
        action="store_true",
        help="æ˜¯å¦å¯ç”¨æŠ½å¸§ + OCR åˆ†æ”¯",
    )
    parser.add_argument(
        "--out-dir",
        type=str,
        default="output",
        help="è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤: ./outputï¼‰",
    )
    parser.add_argument(
        "--ocr-lang",
        type=str,
        default="ch",
        help="PaddleOCR è¯­è¨€ï¼ˆé»˜è®¤: chï¼‰",
    )
    parser.add_argument(
        "--ocr-det-model",
        type=str,
        default="server",  # æ”¹ä¸º server ä»¥è·å¾—æ›´å¥½çš„æ•ˆæœ
        choices=["server", "mobile"],
        help="OCR æ£€æµ‹æ¨¡å‹ç±»å‹ï¼ˆé»˜è®¤: serverï¼Œå¤æ‚èƒŒæ™¯å»ºè®®ä½¿ç”¨ï¼‰",
    )
    parser.add_argument(
        "--ocr-rec-model",
        type=str,
        default="server",  # æ”¹ä¸º server ä»¥è·å¾—æ›´å¥½çš„æ•ˆæœ
        choices=["server", "mobile"],
        help="OCR è¯†åˆ«æ¨¡å‹ç±»å‹ï¼ˆé»˜è®¤: serverï¼Œæå‡å‡†ç¡®åº¦ï¼‰",
    )
    parser.add_argument(
        "--use-gpu",
        action="store_true",
        help="æ˜¯å¦ä½¿ç”¨ GPU åŠ é€Ÿ",
    )
    parser.add_argument(
        "--download-dir",
        type=str,
        default="videos",
        help="è§†é¢‘ä¸‹è½½ç›®å½•ï¼ˆé»˜è®¤: videos/ï¼‰",
    )

    args = parser.parse_args()

    # æ£€æµ‹è¾“å…¥æ˜¯URLè¿˜æ˜¯æ–‡ä»¶è·¯å¾„
    input_str = args.video
    is_url = input_str.startswith("http://") or input_str.startswith("https://")
    
    if is_url:
        # å¦‚æœæ˜¯URLï¼Œå°è¯•ä¸‹è½½
        if not DOWNLOADER_AVAILABLE:
            print("âŒ é”™è¯¯ï¼šæ£€æµ‹åˆ°URLä½†æœªå®‰è£… video_downloader æ¨¡å—")
            print("   è¯·å…ˆå®‰è£…ä¾èµ–: pip install yt-dlp")
            exit(1)
        
        print(f"ğŸ“¥ æ£€æµ‹åˆ°URLï¼Œå¼€å§‹ä¸‹è½½...")
        downloader = VideoDownloader(download_dir=args.download_dir)
        
        try:
            file_info = downloader.download_video(input_str)
            video_path = file_info.file_path
            print(f"âœ… ä¸‹è½½å®Œæˆ: {video_path}")
        except Exception as e:
            print(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
            exit(1)
    else:
        # å¦‚æœæ˜¯æœ¬åœ°æ–‡ä»¶è·¯å¾„
        video_path = Path(input_str).resolve()
        if not video_path.exists():
            print(f"âŒ é”™è¯¯ï¼šè§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
            exit(1)

    output_dir = Path(args.out_dir).resolve()

    process_video(
        video_path=video_path,
        output_dir=output_dir,
        with_frames=args.with_frames,
        ocr_lang=args.ocr_lang,
        ocr_det_model=args.ocr_det_model,
        ocr_rec_model=args.ocr_rec_model,
        use_gpu=args.use_gpu,
    )


if __name__ == "__main__":
    main()
