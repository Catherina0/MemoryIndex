# process_video.py
import argparse
import os
import subprocess
from pathlib import Path
from datetime import datetime
from dotenv import load_dotenv
from groq import Groq

from ocr_utils import init_ocr, ocr_folder_to_text

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()


# ========== è·¯å¾„/ç›®å½•å¤„ç† ==========
def ensure_dir(path: Path):
    path.mkdir(parents=True, exist_ok=True)


# ========== ffmpeg: éŸ³é¢‘ & æŠ½å¸§ ==========
def extract_audio(video_path: Path, audio_path: Path):
    """
    ç”¨ ffmpeg ä»è§†é¢‘é‡Œåˆ†ç¦»éŸ³é¢‘ï¼Œè¾“å‡ºä¸º wavã€‚
    """
    ensure_dir(audio_path.parent)
    cmd = [
        "ffmpeg",
        "-y",
        "-i", str(video_path),
        "-vn",          # no video
        "-acodec", "pcm_s16le",
        "-ar", "16000",
        "-ac", "1",
        str(audio_path),
    ]
    subprocess.run(cmd, check=True)


def extract_frames(video_path: Path, frames_dir: Path, fps: int = 1):
    """
    ç”¨ ffmpeg æŠ½å¸§ï¼šé»˜è®¤ 1 fpsï¼Œå¯ä»¥åé¢å†è°ƒã€‚
    """
    ensure_dir(frames_dir)
    out_pattern = frames_dir / "frame_%05d.png"
    cmd = [
        "ffmpeg",
        "-y",
        "-i", str(video_path),
        "-vf", f"fps={fps}",
        str(out_pattern),
    ]
    subprocess.run(cmd, check=True)


# ========== Groq API é›†æˆ ==========
def transcribe_audio_with_groq(audio_path: Path) -> str:
    """
    ä½¿ç”¨ Groq çš„ Whisper æ¨¡å‹è¿›è¡Œè¯­éŸ³è½¬æ–‡å­—ã€‚
    """
    api_key = os.getenv("GROQ_API_KEY")
    if not api_key:
        print("  âš ï¸  GROQ_API_KEY æœªè®¾ç½®ï¼Œä½¿ç”¨å ä½ç¬¦")
        return f"[FAKE TRANSCRIPT for {audio_path.name}] è¯·åœ¨ .env ä¸­è®¾ç½® GROQ_API_KEY"
    
    try:
        client = Groq(api_key=api_key)
        model = os.getenv("GROQ_ASR_MODEL", "whisper-large-v3-turbo")
        
        with open(audio_path, "rb") as audio_file:
            transcription = client.audio.transcriptions.create(
                file=(audio_path.name, audio_file.read()),
                model=model,
                response_format="text",
            )
        
        return transcription
    except Exception as e:
        print(f"  âœ— Groq è½¬å†™å¤±è´¥: {e}")
        return f"[è½¬å†™å¤±è´¥: {str(e)}]"


def summarize_with_gpt_oss_120b(full_text: str) -> str:
    """
    ä½¿ç”¨ Groq çš„ LLM è¿›è¡Œæ–‡æœ¬æ€»ç»“ã€‚
    """
    api_key = os.getenv("GROQ_API_KEY")
    if not api_key:
        print("  âš ï¸  GROQ_API_KEY æœªè®¾ç½®ï¼Œè¿”å›åŸæ–‡")
        return f"[FAKE SUMMARY - è¯·åœ¨ .env ä¸­è®¾ç½® GROQ_API_KEY]\n\n{full_text}"
    
    try:
        client = Groq(api_key=api_key)
        model = os.getenv("GROQ_LLM_MODEL", "openai/gpt-oss-120b")
        # å¢åŠ  token é™åˆ¶ä»¥æ”¯æŒæ›´é•¿çš„è¾“å‡º
        max_tokens = int(os.getenv("GROQ_MAX_TOKENS", "8192"))  # ä» 4096 æå‡åˆ° 8192
        temperature = float(os.getenv("GROQ_TEMPERATURE", "0.7"))
        
        prompt = f"""è¯·å¯¹ä»¥ä¸‹å†…å®¹è¿›è¡Œè¯¦ç»†çš„æ€»ç»“åˆ†æï¼š

å†…å®¹ï¼š
{full_text[:40000]}  # æå‡è¾“å…¥é•¿åº¦é™åˆ¶

è¦æ±‚ï¼š
1. **ä½¿ç”¨å®Œæ•´çš„ Markdown æ ¼å¼è¾“å‡º**ï¼ˆæ ‡é¢˜ã€åˆ—è¡¨ã€åŠ ç²—ã€ä»£ç å—ç­‰ï¼‰
2. æå–æ ¸å¿ƒè¦ç‚¹å’Œå…³é”®ä¿¡æ¯
3. åˆ—å‡ºé‡è¦çš„æ•°å­—ã€å¼•ç”¨ã€æ—¶é—´ç‚¹å’Œäº‹å®
4. æŒ‰é€»è¾‘ç»“æ„ç»„ç»‡å†…å®¹ï¼ˆä½¿ç”¨ ## æ ‡é¢˜åˆ†èŠ‚ï¼‰
5. å¦‚æœæœ‰ OCR å†…å®¹ï¼Œé‡ç‚¹åˆ†æå±å¹•æ–‡å­—å’Œè§†è§‰ä¿¡æ¯
6. å¦‚æœæœ‰å¤šä¸ªä¸»é¢˜ï¼Œåˆ†åˆ«æ€»ç»“
7. è¾“å‡ºè¦è¯¦ç»†å®Œæ•´ï¼Œä¸è¦è¿‡åº¦ç²¾ç®€
8. åˆ†æå’Œæ¨ç†ä¸€äº›OCRè¯†åˆ«çš„æ–‡æœ¬å¯èƒ½å­˜åœ¨çš„å«ä¹‰å’ŒèƒŒæ™¯
9. åˆ—å‡ºå…³é”®å¥å­å’Œæ®µè½ä¾¿äºå›å¿†

è¾“å‡ºæ ¼å¼ç¤ºä¾‹ï¼š
## ğŸ“‹ å†…å®¹æ¦‚è¿°
[ä¸€å¥è¯æ¦‚æ‹¬ä¸»è¦å†…å®¹]

## ğŸ”‘ æ ¸å¿ƒè¦ç‚¹
- è¦ç‚¹1
- è¦ç‚¹2
- è¦ç‚¹3

## ğŸ“Š è¯¦ç»†å†…å®¹
### ä¸»é¢˜1
[è¯¦ç»†è¯´æ˜...]

### ä¸»é¢˜2
[è¯¦ç»†è¯´æ˜...]

## ğŸ’¡ å…³é”®ä¿¡æ¯
- é‡è¦æ•°å­—ã€æ—¶é—´ã€å¼•ç”¨ç­‰

è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œå……åˆ†åˆ©ç”¨ token é™åˆ¶è¾“å‡ºè¯¦ç»†å†…å®¹ã€‚"""

        response = client.chat.completions.create(
            model=model,
            messages=[
                {
                    "role": "system",
                    "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å†…å®¹åˆ†æåŠ©æ‰‹ï¼Œæ“…é•¿ä»è§†é¢‘è½¬å†™å’Œå±å¹•æ–‡å­—ä¸­æå–å…³é”®ä¿¡æ¯å¹¶ç”¨ç»“æ„åŒ–çš„ Markdown æ ¼å¼å‘ˆç°ã€‚ä½ çš„æ€»ç»“åº”è¯¥è¯¦ç»†ã€å®Œæ•´ã€æ˜“è¯»ã€‚"
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            max_tokens=max_tokens,
            temperature=temperature,
        )
        
        return response.choices[0].message.content
    except Exception as e:
        print(f"  âœ— Groq æ€»ç»“å¤±è´¥: {e}")
        return f"[æ€»ç»“å¤±è´¥: {str(e)}]\n\nåŸå§‹å†…å®¹:\n{full_text}"


def generate_formatted_report(
    video_name: str,
    timestamp: str,
    transcript_text: str,
    ocr_text: str,
    summary: str,
    with_frames: bool,
    session_dir: Path
) -> str:
    """
    ç”Ÿæˆæ ¼å¼åŒ–çš„æŠ¥å‘Šï¼ŒåŒ…å«å…ƒä¿¡æ¯ã€AIæ€»ç»“å’ŒåŸå§‹æ•°æ®
    """
    # ç»Ÿè®¡ä¿¡æ¯
    transcript_chars = len(transcript_text)
    transcript_lines = transcript_text.count('\n')
    ocr_chars = len(ocr_text) if ocr_text else 0
    ocr_lines = ocr_text.count('\n') if ocr_text else 0
    
    # æ ¼å¼åŒ–æ—¶é—´
    dt = datetime.strptime(timestamp, "%Y%m%d_%H%M%S")
    formatted_time = dt.strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S")
    
    # ä½¿ç”¨ Markdown æ ¼å¼
    report = []
    report.append("# ğŸ“¹ è§†é¢‘åˆ†ææŠ¥å‘Š\n")
    report.append(f"**ğŸ“ è§†é¢‘åç§°**: {video_name}  ")
    report.append(f"**ğŸ•’ å¤„ç†æ—¶é—´**: {formatted_time}  ")
    report.append(f"**ğŸ“ è¾“å‡ºç›®å½•**: `{session_dir.name}`  ")
    report.append(f"**ğŸ”§ å¤„ç†æ¨¡å¼**: {'å®Œæ•´æ¨¡å¼ (OCR + éŸ³é¢‘)' if with_frames else 'éŸ³é¢‘æ¨¡å¼'}  ")
    report.append("\n---\n")
    report.append("## ğŸ“Š æ•°æ®ç»Ÿè®¡\n")
    report.append(f"- **è¯­éŸ³è¯†åˆ«**: {transcript_chars} å­—ç¬¦, {transcript_lines} è¡Œ")
    if with_frames:
        report.append(f"- **OCRè¯†åˆ«**: {ocr_chars} å­—ç¬¦, {ocr_lines} è¡Œ")
    report.append("\n---\n")
    
    # AI æ€»ç»“ï¼ˆå·²ç»æ˜¯ markdown æ ¼å¼ï¼‰
    report.append("## ğŸ¤– AI æ™ºèƒ½æ€»ç»“\n")
    report.append(summary)
    report.append("\n---\n")
    
    # åŸå§‹æ•°æ®å¼•ç”¨
    report.append("## ğŸ“‚ åŸå§‹æ•°æ®æ–‡ä»¶\n")
    report.append(f"- ğŸ“„ [è¯­éŸ³è¯†åˆ«åŸæ–‡](transcript_raw.md) ({transcript_chars} å­—ç¬¦)")
    if with_frames:
        report.append(f"- ğŸ“„ [OCRè¯†åˆ«åŸæ–‡](ocr_raw.md) ({ocr_chars} å­—ç¬¦)")
        report.append(f"- ğŸ“ è§†é¢‘å¸§å›¾ç‰‡: `frames/` ç›®å½•")
    report.append(f"- ğŸ”Š éŸ³é¢‘æ–‡ä»¶: `{video_name}.wav`")
    report.append("\n> ğŸ’¡ **æç¤º**: ç‚¹å‡»é“¾æ¥æŸ¥çœ‹åŸå§‹æ•°æ®æ–‡ä»¶è·å–å®Œæ•´çš„è¯†åˆ«å†…å®¹\n")
    report.append("---\n")
    report.append(f"*ğŸ“Œ æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {formatted_time}*")
    
    return "\n".join(report)


# ========== ä¸»æ§åˆ¶æµç¨‹ ==========
def process_video(
    video_path: Path,
    output_dir: Path,
    with_frames: bool = False,
    ocr_lang: str = "ch",
    ocr_det_model: str = "mobile",
    ocr_rec_model: str = "mobile",
    use_gpu: bool = False,
):
    ensure_dir(output_dir)

    # 1. åˆ›å»ºå¸¦æ—¶é—´æˆ³çš„è¾“å‡ºæ–‡ä»¶å¤¹
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    video_name = video_path.stem
    session_dir = output_dir / f"{video_name}_{timestamp}"
    ensure_dir(session_dir)
    
    # 2. å„ç±»æ–‡ä»¶è·¯å¾„
    audio_path = session_dir / f"{video_name}.wav"
    frames_dir = session_dir / "frames"
    ocr_raw_path = session_dir / "ocr_raw.md"
    transcript_raw_path = session_dir / "transcript_raw.md"
    report_path = session_dir / "report.md"
    
    print(f"\nğŸ“ è¾“å‡ºç›®å½•: {session_dir}")
    print(f"   æ—¶é—´æˆ³: {timestamp}\n")

    ocr_text = ""
    transcript_text = ""
    
    # 2. å¦‚æœæ˜¯OCRæ¨¡å¼ï¼Œå…ˆå¤„ç†è§†é¢‘å¸§å’ŒOCR
    if with_frames:
        print("\n" + "="*60)
        print("ğŸ“¹ ç¬¬ä¸€æ­¥ï¼šå¤„ç†è§†é¢‘å¸§ OCR")
        print("="*60)
        
        print(">> æŠ½å¸§ä¸­...")
        extract_frames(video_path, frames_dir, fps=1)

        print(f"\n>> åˆå§‹åŒ–æœ¬åœ° OCR (det={ocr_det_model}, rec={ocr_rec_model})...")
        ocr = init_ocr(
            lang=ocr_lang,
            use_gpu=use_gpu,
            det_model=ocr_det_model,
            rec_model=ocr_rec_model
        )

        print("\n>> å¯¹æ‰€æœ‰å¸§åš OCRï¼ˆPP-OCRv4 Server + é¢„å¤„ç† + æ··åˆæ¨¡å¼ï¼‰...")
        # ä½¿ç”¨æ··åˆæ¨¡å¼ï¼šåŒæ—¶è¯†åˆ«åº•éƒ¨å­—å¹•å’Œç”»é¢å…¶ä»–æ–‡å­—
        ocr_text = ocr_folder_to_text(
            ocr, 
            str(frames_dir), 
            min_score=0.3,  # è¯†åˆ«é˜¶æ®µä¸¥æ ¼ï¼šåªä¿ç•™é«˜ç½®ä¿¡åº¦ç»“æœ
            debug=False,
            use_preprocessing=True,  # å¯ç”¨å›¾åƒé¢„å¤„ç†ï¼ˆå¯¹æ¯”åº¦+é”åŒ–ï¼‰
            roi_bottom_only=True,    # åœ¨å•ä¸€æ¨¡å¼ä¸‹ç”Ÿæ•ˆ
            hybrid_mode=True,        # ã€æ··åˆæ¨¡å¼ã€‘åŒæ—¶è¯†åˆ«å­—å¹•åŒºå’Œå…¨ç”»é¢
        )
        
        print()  # ç©ºè¡Œ
        if ocr_text.strip():
            char_count = len(ocr_text)
            line_count = ocr_text.count('\n')
            print(f"âœ… OCR å®Œæˆï¼è¯†åˆ«åˆ° {char_count} ä¸ªå­—ç¬¦ï¼Œ{line_count} è¡Œæ–‡æœ¬")
            
            # ä¿å­˜OCRåŸå§‹ç»“æœï¼ˆMarkdown æ ¼å¼ï¼‰
            print(f"   ğŸ’¾ ä¿å­˜OCRåŸå§‹ç»“æœ: {ocr_raw_path.name}")
            ocr_markdown = f"# ğŸ” OCR è¯†åˆ«åŸå§‹æ•°æ®\n\n"
            ocr_markdown += f"**è¯†åˆ«æ—¶é—´**: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}  \n"
            ocr_markdown += f"**æ€»å­—ç¬¦æ•°**: {char_count}  \n"
            ocr_markdown += f"**æ€»è¡Œæ•°**: {line_count}  \n"
            ocr_markdown += f"**å¤„ç†æ¨¡å¼**: æ··åˆæ¨¡å¼ï¼ˆå­—å¹•åŒº + å…¨ç”»é¢ï¼‰\n\n"
            ocr_markdown += "---\n\n"
            ocr_markdown += "## ğŸ“ è¯†åˆ«å†…å®¹\n\n"
            ocr_markdown += "```\n"
            ocr_markdown += ocr_text
            ocr_markdown += "\n```\n"
            ocr_raw_path.write_text(ocr_markdown, encoding="utf-8")
        else:
            print("âš ï¸  è­¦å‘Šï¼šOCR æœªè¯†åˆ«åˆ°ä»»ä½•æ–‡å­—ï¼ˆå¯èƒ½è§†é¢‘ä¸­æ²¡æœ‰æ–‡å­—å†…å®¹ï¼‰")
        
        print("\n" + "="*60)
        print("ğŸ¤ ç¬¬äºŒæ­¥ï¼šå¤„ç†éŸ³é¢‘è½¬å†™")
        print("="*60)
    
    # 3. å¤„ç†éŸ³é¢‘ï¼ˆOCRæ¨¡å¼åœ¨OCRä¹‹åï¼Œæ™®é€šæ¨¡å¼ç›´æ¥å¤„ç†ï¼‰
    print(">> æå–éŸ³é¢‘ä¸­...")
    extract_audio(video_path, audio_path)

    # 4. Groq è¯­éŸ³è½¬æ–‡å­—ï¼ˆå ä½ï¼‰
    print(">> è°ƒç”¨ Groq è¯­éŸ³è½¬å†™ï¼ˆå ä½ï¼‰...")
    transcript_text = transcribe_audio_with_groq(audio_path)
    
    # ä¿å­˜è¯­éŸ³è¯†åˆ«åŸå§‹ç»“æœï¼ˆMarkdown æ ¼å¼ï¼‰
    if transcript_text.strip():
        print(f"   ğŸ’¾ ä¿å­˜è¯­éŸ³è¯†åˆ«åŸå§‹ç»“æœ: {transcript_raw_path.name}")
        transcript_markdown = f"# ğŸ¤ è¯­éŸ³è¯†åˆ«åŸå§‹æ•°æ®\n\n"
        transcript_markdown += f"**è¯†åˆ«æ—¶é—´**: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}  \n"
        transcript_markdown += f"**æ€»å­—ç¬¦æ•°**: {len(transcript_text)}  \n"
        transcript_markdown += f"**è¯†åˆ«æ¨¡å‹**: Groq Whisper  \n\n"
        transcript_markdown += "---\n\n"
        transcript_markdown += "## ğŸ“ è½¬å†™å†…å®¹\n\n"
        transcript_markdown += transcript_text
        transcript_raw_path.write_text(transcript_markdown, encoding="utf-8")

    # 5. åˆå¹¶æ–‡æœ¬ï¼šéŸ³é¢‘æ–‡å­— + OCR ç»“æœ
    combined_text_parts = [f"=== Audio Transcript ===\n{transcript_text}\n"]
    if with_frames:
        combined_text_parts.append(f"\n\n=== OCR from Frames ===\n{ocr_text}\n")

    combined_text = "\n".join(combined_text_parts)

    # 6. è°ƒ GPT-OSS 120B åšæ€»ç»“ï¼ˆå ä½ï¼‰
    print("\n>> è°ƒç”¨ GPT-OSS 120B åšæ€»ç»“ï¼ˆå ä½ï¼‰...")
    summary = summarize_with_gpt_oss_120b(combined_text)

    # 7. ç”Ÿæˆæ ¼å¼åŒ–æŠ¥å‘Š
    report_content = generate_formatted_report(
        video_name=video_name,
        timestamp=timestamp,
        transcript_text=transcript_text,
        ocr_text=ocr_text,
        summary=summary,
        with_frames=with_frames,
        session_dir=session_dir
    )
    
    report_path.write_text(report_content, encoding="utf-8")
    print(f"\nğŸ“„ æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")
    print(f"ğŸ“ å®Œæ•´è¾“å‡ºç›®å½•: {session_dir}")


# ========== CLI ==========
def main():
    parser = argparse.ArgumentParser(description="Video â†’ Text Report pipeline")
    parser.add_argument("video", type=str, help="è¾“å…¥è§†é¢‘è·¯å¾„")
    parser.add_argument(
        "--with-frames",
        action="store_true",
        help="æ˜¯å¦å¯ç”¨æŠ½å¸§ + OCR åˆ†æ”¯",
    )
    parser.add_argument(
        "--out-dir",
        type=str,
        default="output",
        help="è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤: ./outputï¼‰",
    )
    parser.add_argument(
        "--ocr-lang",
        type=str,
        default="ch",
        help="PaddleOCR è¯­è¨€ï¼ˆé»˜è®¤: chï¼‰",
    )
    parser.add_argument(
        "--ocr-det-model",
        type=str,
        default="server",  # æ”¹ä¸º server ä»¥è·å¾—æ›´å¥½çš„æ•ˆæœ
        choices=["server", "mobile"],
        help="OCR æ£€æµ‹æ¨¡å‹ç±»å‹ï¼ˆé»˜è®¤: serverï¼Œå¤æ‚èƒŒæ™¯å»ºè®®ä½¿ç”¨ï¼‰",
    )
    parser.add_argument(
        "--ocr-rec-model",
        type=str,
        default="server",  # æ”¹ä¸º server ä»¥è·å¾—æ›´å¥½çš„æ•ˆæœ
        choices=["server", "mobile"],
        help="OCR è¯†åˆ«æ¨¡å‹ç±»å‹ï¼ˆé»˜è®¤: serverï¼Œæå‡å‡†ç¡®åº¦ï¼‰",
    )
    parser.add_argument(
        "--use-gpu",
        action="store_true",
        help="æ˜¯å¦ä½¿ç”¨ GPU åŠ é€Ÿ",
    )

    args = parser.parse_args()

    video_path = Path(args.video).resolve()
    output_dir = Path(args.out_dir).resolve()

    process_video(
        video_path=video_path,
        output_dir=output_dir,
        with_frames=args.with_frames,
        ocr_lang=args.ocr_lang,
        ocr_det_model=args.ocr_det_model,
        ocr_rec_model=args.ocr_rec_model,
        use_gpu=args.use_gpu,
    )


if __name__ == "__main__":
    main()
