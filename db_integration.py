#!/usr/bin/env python3
"""
è§†é¢‘å¤„ç†å®Œæˆåçš„æ•°æ®åº“å­˜å‚¨é›†æˆ
ä¿®æ”¹ process_video.py çš„å­˜å‚¨é€»è¾‘ï¼Œå°†ç»“æœè½åº“
"""
import json
from pathlib import Path
from typing import Dict, Any, Optional
from datetime import datetime

from db import VideoRepository, SearchRepository
from db.models import (
    Video, Artifact, Topic, TimelineEntry,
    SourceType, ProcessingStatus, ArtifactType
)


class VideoProcessor:
    """è§†é¢‘å¤„ç†ä¸æ•°æ®åº“é›†æˆ"""
    
    def __init__(self, db_path: Optional[str] = None):
        self.repo = VideoRepository(db_path)
    
    def process_and_save(
        self,
        video_path: str,
        output_dir: Path,
        source_url: Optional[str] = None,
        source_type: str = 'local',
        video_id: Optional[str] = None,
        processing_config: Optional[Dict[str, Any]] = None
    ) -> int:
        """
        å¤„ç†è§†é¢‘å¹¶ä¿å­˜åˆ°æ•°æ®åº“ï¼ˆå®Œæ•´æµç¨‹ï¼‰
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•
            source_url: æ¥æºURL
            source_type: æ¥æºç±»å‹
            video_id: å¹³å°è§†é¢‘ID
            processing_config: å¤„ç†é…ç½®
        
        Returns:
            int: video_idï¼ˆæ•°æ®åº“ä¸»é”®ï¼‰
        """
        # 1. è®¡ç®— hashï¼ˆå»é‡ï¼‰
        content_hash = self.repo.calculate_content_hash(video_path)
        
        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
        existing = self.repo.get_video_by_hash(content_hash)
        if existing:
            print(f"âš ï¸  è§†é¢‘å·²å­˜åœ¨ï¼ˆID: {existing.id}ï¼‰ï¼Œè·³è¿‡å¤„ç†")
            return existing.id
        
        # 2. åˆ›å»ºè§†é¢‘è®°å½•
        video = Video(
            content_hash=content_hash,
            video_id=video_id,
            source_type=SourceType(source_type),
            source_url=source_url,
            title=Path(video_path).stem,  # ä¸´æ—¶æ ‡é¢˜
            file_path=video_path,
            file_size_bytes=Path(video_path).stat().st_size,
            processing_config=processing_config,
            status=ProcessingStatus.PROCESSING
        )
        
        try:
            db_video_id = self.repo.create_video(video)
            print(f"âœ… åˆ›å»ºè§†é¢‘è®°å½•: ID={db_video_id}")
            
            # 3. æ‰§è¡Œè§†é¢‘å¤„ç†ï¼ˆè°ƒç”¨åŸæœ‰é€»è¾‘ï¼‰
            # è¿™é‡Œæ˜¯åŸ process_video.py çš„å¤„ç†æµç¨‹
            transcript_data = self._process_transcript(video_path, output_dir)
            ocr_data = self._process_ocr(video_path, output_dir)
            report_data = self._generate_report(transcript_data, ocr_data, output_dir)
            
            # 4. ä¿å­˜å¤„ç†äº§ç‰©
            # 4.1 è½¬å†™æ–‡æœ¬
            if transcript_data:
                transcript_artifact = Artifact(
                    video_id=db_video_id,
                    artifact_type=ArtifactType.TRANSCRIPT,
                    content_text=self._extract_plain_text(transcript_data),
                    content_json=transcript_data,
                    file_path=str(output_dir / 'transcript_raw.json'),
                    model_name='whisper-large-v3'
                )
                self.repo.save_artifact(transcript_artifact)
                print("âœ… ä¿å­˜è½¬å†™æ–‡æœ¬")
            
            # 4.2 OCRæ–‡æœ¬
            if ocr_data:
                ocr_artifact = Artifact(
                    video_id=db_video_id,
                    artifact_type=ArtifactType.OCR,
                    content_text=self._extract_plain_text(ocr_data),
                    content_json=ocr_data,
                    file_path=str(output_dir / 'ocr_raw.json'),
                    model_name='paddleocr'
                )
                self.repo.save_artifact(ocr_artifact)
                print("âœ… ä¿å­˜OCRæ–‡æœ¬")
            
            # 4.3 æœ€ç»ˆæŠ¥å‘Š
            if report_data:
                report_artifact = Artifact(
                    video_id=db_video_id,
                    artifact_type=ArtifactType.REPORT,
                    content_text=report_data.get('content', ''),
                    content_json=report_data,
                    file_path=str(output_dir / 'report.md'),
                    model_name='llama-3.3-70b'
                )
                self.repo.save_artifact(report_artifact)
                print("âœ… ä¿å­˜æœ€ç»ˆæŠ¥å‘Š")
                
                # æ›´æ–°è§†é¢‘æ ‡é¢˜
                if 'title' in report_data:
                    # TODO: æ·»åŠ  update_video æ–¹æ³•
                    pass
            
            # 5. ä¿å­˜æ ‡ç­¾
            tags = self._extract_tags(report_data)
            if tags:
                self.repo.save_tags(db_video_id, tags, source='auto')
                print(f"âœ… ä¿å­˜æ ‡ç­¾: {', '.join(tags)}")
            
            # 6. ä¿å­˜ä¸»é¢˜
            topics = self._extract_topics(report_data)
            if topics:
                self.repo.save_topics(db_video_id, topics)
                print(f"âœ… ä¿å­˜ {len(topics)} ä¸ªä¸»é¢˜")
            
            # 7. ä¿å­˜æ—¶é—´çº¿
            timeline = self._build_timeline(transcript_data, ocr_data, output_dir)
            if timeline:
                self.repo.save_timeline(db_video_id, timeline)
                print(f"âœ… ä¿å­˜ {len(timeline)} ä¸ªæ—¶é—´çº¿æ¡ç›®")
            
            # 8. æ›´æ–°å…¨æ–‡æœç´¢ç´¢å¼•
            self.repo.update_fts_index(db_video_id)
            print("âœ… æ›´æ–°æœç´¢ç´¢å¼•")
            
            # 9. æ ‡è®°å¤„ç†å®Œæˆ
            self.repo.update_video_status(db_video_id, ProcessingStatus.COMPLETED)
            print(f"ğŸ‰ å¤„ç†å®Œæˆ: video_id={db_video_id}")
            
            return db_video_id
            
        except Exception as e:
            # æ ‡è®°å¤±è´¥
            self.repo.update_video_status(
                db_video_id, 
                ProcessingStatus.FAILED, 
                str(e)
            )
            print(f"âŒ å¤„ç†å¤±è´¥: {e}")
            raise
    
    # ä»¥ä¸‹æ˜¯è¾…åŠ©æ–¹æ³•ï¼ˆéœ€è¦æ ¹æ®å®é™…å¤„ç†é€»è¾‘å®ç°ï¼‰
    
    def _process_transcript(self, video_path: str, output_dir: Path) -> Dict:
        """æ‰§è¡Œè¯­éŸ³è½¬å†™ï¼ˆè°ƒç”¨åŸæœ‰é€»è¾‘ï¼‰"""
        # TODO: è°ƒç”¨ process_video.py çš„è½¬å†™é€»è¾‘
        # è¿”å›æ ¼å¼: {'segments': [{'start': 0, 'end': 5, 'text': '...'}]}
        return {}
    
    def _process_ocr(self, video_path: str, output_dir: Path) -> Dict:
        """æ‰§è¡ŒOCRè¯†åˆ«ï¼ˆè°ƒç”¨åŸæœ‰é€»è¾‘ï¼‰"""
        # TODO: è°ƒç”¨ ocr_utils.py çš„OCRé€»è¾‘
        return {}
    
    def _generate_report(self, transcript_data: Dict, ocr_data: Dict, output_dir: Path) -> Dict:
        """ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Šï¼ˆè°ƒç”¨åŸæœ‰é€»è¾‘ï¼‰"""
        # TODO: è°ƒç”¨ LLM ç”ŸæˆæŠ¥å‘Š
        # è¿”å›æ ¼å¼: {'title': '...', 'content': '...', 'tags': [], 'topics': []}
        return {}
    
    def _extract_plain_text(self, data: Dict) -> str:
        """ä»ç»“æ„åŒ–æ•°æ®æå–çº¯æ–‡æœ¬"""
        if 'segments' in data:
            # è½¬å†™æ•°æ®
            return '\n'.join([seg['text'] for seg in data['segments']])
        elif 'frames' in data:
            # OCRæ•°æ®
            return '\n'.join([frame.get('text', '') for frame in data['frames']])
        elif 'content' in data:
            # æŠ¥å‘Šæ•°æ®
            return data['content']
        return json.dumps(data, ensure_ascii=False)
    
    def _extract_tags(self, report_data: Dict) -> list:
        """ä»æŠ¥å‘Šä¸­æå–æ ‡ç­¾"""
        return report_data.get('tags', [])
    
    def _extract_topics(self, report_data: Dict) -> list:
        """ä»æŠ¥å‘Šä¸­æå–ä¸»é¢˜"""
        topics_data = report_data.get('topics', [])
        topics = []
        
        for i, topic_data in enumerate(topics_data):
            topic = Topic(
                video_id=0,  # ç¨åå¡«å……
                title=topic_data.get('title', ''),
                summary=topic_data.get('summary'),
                start_time=topic_data.get('start_time'),
                end_time=topic_data.get('end_time'),
                keywords=topic_data.get('keywords', []),
                key_points=topic_data.get('key_points', []),
                sequence=i
            )
            topics.append(topic)
        
        return topics
    
    def _build_timeline(self, transcript_data: Dict, ocr_data: Dict, output_dir: Path) -> list:
        """æ„å»ºæ—¶é—´çº¿ï¼ˆåˆå¹¶è½¬å†™å’ŒOCRï¼‰"""
        timeline = []
        
        # ä»è½¬å†™æ•°æ®æå–
        if 'segments' in transcript_data:
            for seg in transcript_data['segments']:
                entry = TimelineEntry(
                    video_id=0,
                    timestamp_seconds=seg['start'],
                    transcript_text=seg['text']
                )
                timeline.append(entry)
        
        # ä»OCRæ•°æ®æå–
        if 'frames' in ocr_data:
            for frame in ocr_data['frames']:
                entry = TimelineEntry(
                    video_id=0,
                    timestamp_seconds=frame.get('timestamp', 0),
                    frame_number=frame.get('frame_number'),
                    ocr_text=frame.get('text'),
                    frame_path=frame.get('frame_path')
                )
                timeline.append(entry)
        
        # æŒ‰æ—¶é—´æ’åº
        timeline.sort(key=lambda x: x.timestamp_seconds)
        
        return timeline


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == '__main__':
    """
    é›†æˆåˆ° process_video.py çš„æ–¹æ³•ï¼š
    
    1. åœ¨ process_video.py çš„ä¸»å‡½æ•°æœ«å°¾æ·»åŠ ï¼š
    
    from db_integration import VideoProcessor
    
    processor = VideoProcessor()
    video_id = processor.process_and_save(
        video_path=args.video,
        output_dir=output_dir,
        source_url=args.url,
        source_type='bilibili',
        video_id='BV1xxx',
        processing_config={'fps': args.fps, 'model': 'whisper-large-v3'}
    )
    
    print(f"æ•°æ®åº“è§†é¢‘ID: {video_id}")
    """
    pass
