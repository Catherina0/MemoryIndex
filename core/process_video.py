# process_video.py
import argparse
import os
import subprocess
import sys
from pathlib import Path
from datetime import datetime
from dotenv import load_dotenv
from groq import Groq
from google import genai
import re
import json
import warnings
import logging

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

# æŠ‘åˆ¶ PaddleOCR/PaddleX æ¨¡å‹åŠ è½½æ—¥å¿—ï¼ˆå¿…é¡»åœ¨ import å‰è®¾ç½®ï¼‰
os.environ['PADDLEX_DISABLE_PRINT'] = '1'
os.environ['DISABLE_MODEL_SOURCE_CHECK'] = 'True'
warnings.filterwarnings('ignore')
logging.getLogger('ppocr').setLevel(logging.ERROR)
logging.getLogger('paddle').setLevel(logging.ERROR)
logging.getLogger('paddlex').setLevel(logging.ERROR)

# OCR å¼•æ“é€‰æ‹©ï¼šä¼˜å…ˆä½¿ç”¨ Vision OCRï¼ˆmacOSï¼‰ï¼Œå¦åˆ™ä½¿ç”¨ PaddleOCR
import platform
OCR_ENGINE = None  # 'vision' æˆ– 'paddle'

# å°è¯•å¯¼å…¥ Vision OCRï¼ˆmacOSï¼‰
try:
    from ocr.ocr_vision import init_vision_ocr, ocr_folder_vision
    if platform.system() == 'Darwin':  # macOS
        OCR_ENGINE = 'vision'
        print("âœ… ä½¿ç”¨ Apple Vision OCRï¼ˆç³»ç»ŸåŸç”Ÿï¼‰")
except ImportError:
    pass

# å¦‚æœ Vision OCR ä¸å¯ç”¨ï¼Œå°è¯•å¯¼å…¥ PaddleOCR
if not OCR_ENGINE:
    try:
        from ocr.ocr_utils import init_ocr, ocr_folder_to_text
        OCR_ENGINE = 'paddle'
        print("âœ… ä½¿ç”¨ PaddleOCR")
    except ImportError:
        print("âš ï¸  è­¦å‘Šï¼šæœªæ‰¾åˆ°å¯ç”¨çš„ OCR å¼•æ“")
        print("   â€¢ macOS: æ— éœ€å®‰è£…ï¼Œåº”è¯¥è‡ªåŠ¨æ£€æµ‹ Vision OCR")
        print("   â€¢ å…¶ä»–å¹³å°: è¯·è¿è¡Œ 'make install-paddle-ocr'")

# å¯¼å…¥å¤šè¿›ç¨‹OCRï¼ˆç”¨äºæå‡CPUåˆ©ç”¨ç‡ï¼‰
try:
    from ocr.ocr_parallel import ocr_folder_parallel
    PARALLEL_OCR_AVAILABLE = True
except ImportError:
    PARALLEL_OCR_AVAILABLE = False
    print("âš ï¸  å¤šè¿›ç¨‹OCRæ¨¡å—ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨å•è¿›ç¨‹æ¨¡å¼")

# å¯¼å…¥æ•°æ®åº“æ¨¡å—
from db import VideoRepository
from db.models import Video, Artifact, Topic, TimelineEntry, SourceType, ArtifactType, ProcessingStatus

# å¯é€‰ï¼šæ”¯æŒä» URL ç›´æ¥ä¸‹è½½
try:
    from core.video_downloader import VideoDownloader
    DOWNLOADER_AVAILABLE = True
except ImportError:
    DOWNLOADER_AVAILABLE = False

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()


# ========== è·¯å¾„/ç›®å½•å¤„ç† ==========
def ensure_dir(path: Path):
    path.mkdir(parents=True, exist_ok=True)


# ========== ffmpeg: éŸ³é¢‘ & æŠ½å¸§ ==========

# Groq Whisper API é™åˆ¶
MAX_AUDIO_SIZE_MB = 20
MAX_AUDIO_SIZE_BYTES = MAX_AUDIO_SIZE_MB * 1024 * 1024

def get_video_duration(video_path: Path) -> float:
    """
    ä½¿ç”¨ ffprobe è·å–è§†é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰ã€‚
    
    Returns:
        float: è§†é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œå¦‚æœè·å–å¤±è´¥è¿”å› 0
    """
    try:
        cmd = [
            "ffprobe",
            "-v", "error",
            "-show_entries", "format=duration",
            "-of", "default=noprint_wrappers=1:nokey=1",
            str(video_path)
        ]
        result = subprocess.run(cmd, capture_output=True, text=True, check=True)
        duration = float(result.stdout.strip())
        return duration
    except (subprocess.CalledProcessError, ValueError) as e:
        print(f"âš ï¸  è­¦å‘Šï¼šæ— æ³•è·å–è§†é¢‘æ—¶é•¿: {e}")
        return 0


def extract_audio(video_path: Path, audio_path: Path):
    """
    ç”¨ ffmpeg ä»è§†é¢‘é‡Œåˆ†ç¦»éŸ³é¢‘ï¼Œè¾“å‡ºä¸ºå‹ç¼©çš„ wavã€‚
    ä½¿ç”¨ä»¥ä¸‹å‚æ•°å‹ç¼©éŸ³é¢‘ï¼š
      - ac 1: å•å£°é“
      - ar 16000: é‡‡æ ·ç‡ 16kHz
      - sample_fmt s16: 16-bit PCM
    """
    ensure_dir(audio_path.parent)
    cmd = [
        "ffmpeg",
        "-y",
        "-i", str(video_path),
        "-vn",                    # no video
        "-acodec", "pcm_s16le",   # 16-bit PCM
        "-ar", "16000",           # é‡‡æ ·ç‡ 16kHz
        "-ac", "1",               # å•å£°é“
        str(audio_path),
    ]
    subprocess.run(cmd, check=True, capture_output=True)


def get_audio_duration(audio_path: Path) -> float:
    """
    ä½¿ç”¨ ffprobe è·å–éŸ³é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰ã€‚
    """
    try:
        cmd = [
            "ffprobe",
            "-v", "error",
            "-show_entries", "format=duration",
            "-of", "default=noprint_wrappers=1:nokey=1",
            str(audio_path)
        ]
        result = subprocess.run(cmd, capture_output=True, text=True, check=True)
        return float(result.stdout.strip())
    except (subprocess.CalledProcessError, ValueError):
        return 0


def split_audio(audio_path: Path, max_size_mb: float = MAX_AUDIO_SIZE_MB) -> list:
    """
    å¦‚æœéŸ³é¢‘æ–‡ä»¶è¶…è¿‡æŒ‡å®šå¤§å°ï¼Œæ‹†åˆ†æˆå¤šä¸ªç‰‡æ®µã€‚
    
    Args:
        audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        max_size_mb: æœ€å¤§æ–‡ä»¶å¤§å°ï¼ˆMBï¼‰
    
    Returns:
        list: [(chunk_path, start_time), ...] æ¯ä¸ªç‰‡æ®µçš„è·¯å¾„å’Œèµ·å§‹æ—¶é—´ï¼ˆç§’ï¼‰
    """
    file_size = audio_path.stat().st_size
    max_size_bytes = max_size_mb * 1024 * 1024
    
    if file_size <= max_size_bytes:
        return [(audio_path, 0.0)]
    
    # è®¡ç®—éœ€è¦æ‹†åˆ†çš„æ®µæ•°
    num_chunks = int(file_size / max_size_bytes) + 1
    duration = get_audio_duration(audio_path)
    
    if duration <= 0:
        print(f"   âš ï¸  æ— æ³•è·å–éŸ³é¢‘æ—¶é•¿ï¼Œå°è¯•ç›´æ¥ä¸Šä¼ ")
        return [(audio_path, 0.0)]
    
    chunk_duration = duration / num_chunks
    
    print(f"   ğŸ“Š éŸ³é¢‘æ–‡ä»¶: {file_size / 1024 / 1024:.1f}MB > {max_size_mb}MB")
    print(f"   âœ‚ï¸  æ‹†åˆ†ä¸º {num_chunks} æ®µ (æ¯æ®µçº¦ {chunk_duration:.0f}ç§’)")
    
    chunks = []
    chunk_dir = audio_path.parent / "audio_chunks"
    ensure_dir(chunk_dir)
    
    for i in range(num_chunks):
        start_time = i * chunk_duration
        chunk_path = chunk_dir / f"chunk_{i:03d}.wav"
        
        cmd = [
            "ffmpeg",
            "-y",
            "-i", str(audio_path),
            "-ss", str(start_time),
            "-t", str(chunk_duration),
            "-acodec", "pcm_s16le",
            "-ar", "16000",
            "-ac", "1",
            str(chunk_path),
        ]
        subprocess.run(cmd, check=True, capture_output=True)
        chunks.append((chunk_path, start_time))
        print(f"   âœ… ç‰‡æ®µ {i+1}/{num_chunks}: {chunk_path.name}")
    
    return chunks


def extract_frames(video_path: Path, frames_dir: Path, fps: int = 1):
    """
    ç”¨ ffmpeg æŠ½å¸§ï¼šé»˜è®¤ 1 fpsï¼ˆæ¯ç§’ä¸€å¸§ï¼‰ã€‚
    å¸§ç¼–å·ä» 1 å¼€å§‹ï¼Œframe_00001.png å¯¹åº”ç¬¬ 0-1 ç§’ã€‚
    """
    ensure_dir(frames_dir)
    out_pattern = frames_dir / "frame_%05d.png"
    cmd = [
        "ffmpeg",
        "-y",
        "-loglevel", "error",  # åªæ˜¾ç¤ºé”™è¯¯
        "-i", str(video_path),
        "-vf", f"fps={fps}",
        str(out_pattern),
    ]
    subprocess.run(cmd, check=True)


def match_audio_with_frames(transcript_data: dict, frames_dir: Path, fps: int = 1) -> list:
    """
    éŸ³ç”»åŒ¹é…ï¼šå°†éŸ³é¢‘è½¬å†™ç‰‡æ®µä¸è§†é¢‘å¸§å…³è”ã€‚
    
    Args:
        transcript_data: åŒ…å« segments çš„è½¬å†™æ•°æ®
        frames_dir: è§†é¢‘å¸§ç›®å½•
        fps: æŠ½å¸§é¢‘ç‡ï¼ˆæ¯ç§’å¸§æ•°ï¼‰
    
    Returns:
        list: [{'second': 0, 'frame': 'frame_00001.png', 'text': 'å¯¹åº”çš„æ–‡æœ¬'}, ...]
    """
    import glob
    
    # è·å–æ‰€æœ‰å¸§æ–‡ä»¶
    frame_files = sorted(glob.glob(str(frames_dir / "frame_*.png")))
    frame_count = len(frame_files)
    
    # ä¸ºæ¯ä¸€ç§’å»ºç«‹æ–‡æœ¬ç´¢å¼•
    timeline = []
    
    for i in range(frame_count):
        second = i  # å¸§ç¼–å·ä»1å¼€å§‹ï¼Œå¯¹åº”ç¬¬ i ç§’
        frame_name = f"frame_{i+1:05d}.png"
        
        # æŸ¥æ‰¾è¿™ä¸€ç§’å¯¹åº”çš„æ–‡æœ¬
        texts_in_second = []
        if 'segments' in transcript_data:
            for seg in transcript_data['segments']:
                seg_start = int(seg['start'])
                seg_end = int(seg['end'])
                # å¦‚æœç‰‡æ®µè¦†ç›–å½“å‰ç§’
                if seg_start <= second < seg_end:
                    texts_in_second.append(seg['text'].strip())
        
        timeline.append({
            'second': second,
            'frame': frame_name,
            'text': ' '.join(texts_in_second) if texts_in_second else ''
        })
    
    return timeline


# ========== Groq API é›†æˆ ==========
def _transcribe_single_audio(client, model_name: str, audio_path: Path) -> dict:
    """
    è½¬å†™å•ä¸ªéŸ³é¢‘æ–‡ä»¶ï¼ˆå†…éƒ¨å‡½æ•°ï¼‰ã€‚
    """
    with open(audio_path, "rb") as audio_file:
        transcription = client.audio.transcriptions.create(
            file=(audio_path.name, audio_file.read()),
            model=model_name,
            response_format="verbose_json",
            timestamp_granularities=["segment"]
        )
    
    result = {
        'text': transcription.text,
        'segments': []
    }
    
    if hasattr(transcription, 'segments') and transcription.segments:
        for seg in transcription.segments:
            result['segments'].append({
                'start': seg.get('start', 0),
                'end': seg.get('end', 0),
                'text': seg.get('text', '')
            })
    
    return result


def transcribe_audio_with_groq(audio_path: Path) -> dict:
    """
    ä½¿ç”¨ Groq çš„ Whisper æ¨¡å‹è¿›è¡Œè¯­éŸ³è½¬æ–‡å­—ï¼Œè¿”å›å¸¦æ—¶é—´æˆ³çš„æ•°æ®ã€‚
    å¦‚æœéŸ³é¢‘æ–‡ä»¶è¶…è¿‡ 20MBï¼Œè‡ªåŠ¨æ‹†åˆ†æˆå¤šæ®µåˆ†åˆ«è¯†åˆ«ï¼Œç„¶åæ‹¼æ¥ç»“æœã€‚
    
    Returns:
        dict: {
            'text': 'å®Œæ•´æ–‡æœ¬',
            'segments': [{'start': 0.0, 'end': 2.5, 'text': 'ç‰‡æ®µæ–‡æœ¬'}, ...]
        }
    """
    api_key = os.getenv("GROQ_API_KEY")
    if not api_key:
        print("  âš ï¸  GROQ_API_KEY æœªè®¾ç½®ï¼Œä½¿ç”¨å ä½ç¬¦")
        return {
            'text': f"[FAKE TRANSCRIPT for {audio_path.name}] è¯·åœ¨ .env ä¸­è®¾ç½® GROQ_API_KEY",
            'segments': []
        }
    
    try:
        client = Groq(api_key=api_key)
        
        # ç¡®å®š ASR æ¨¡å‹
        asr_type = os.getenv("ASR_MODEL_TYPE", "").lower()
        if asr_type == "v3":
            model = "whisper-large-v3"
            print("  ğŸ¤ ä½¿ç”¨æ¨¡å‹: Whisper Large V3")
        elif asr_type == "turbo":
            model = "whisper-large-v3-turbo"
            print("  ğŸ¤ ä½¿ç”¨æ¨¡å‹: Whisper Large V3 Turbo")
        else:
            # é»˜è®¤ fallback åˆ°ç¯å¢ƒå˜é‡é…ç½®
            model = os.getenv("GROQ_ASR_MODEL", "whisper-large-v3")
        
        # æ£€æŸ¥æ–‡ä»¶å¤§å°ï¼Œå†³å®šæ˜¯å¦éœ€è¦æ‹†åˆ†
        file_size = audio_path.stat().st_size
        
        if file_size <= MAX_AUDIO_SIZE_BYTES:
            # æ–‡ä»¶è¶³å¤Ÿå°ï¼Œç›´æ¥è½¬å†™
            result = _transcribe_single_audio(client, model, audio_path)
            result['asr_model'] = model
            return result
        
        # æ–‡ä»¶è¿‡å¤§ï¼Œéœ€è¦æ‹†åˆ†
        chunks = split_audio(audio_path)
        
        if len(chunks) == 1:
            # æ‹†åˆ†å¤±è´¥æˆ–ä¸éœ€è¦æ‹†åˆ†ï¼Œå°è¯•ç›´æ¥ä¸Šä¼ 
            result = _transcribe_single_audio(client, model, audio_path)
            result['asr_model'] = model
            return result
        
        # åˆ†æ®µè½¬å†™å¹¶åˆå¹¶ç»“æœ
        all_text = []
        all_segments = []
        
        for i, (chunk_path, time_offset) in enumerate(chunks):
            print(f"   ğŸ¤ è½¬å†™ç‰‡æ®µ {i+1}/{len(chunks)}...")
            try:
                chunk_result = _transcribe_single_audio(client, model, chunk_path)
                
                # æ·»åŠ æ–‡æœ¬
                if chunk_result.get('text'):
                    all_text.append(chunk_result['text'])
                
                # æ·»åŠ ç‰‡æ®µï¼ˆè°ƒæ•´æ—¶é—´åç§»ï¼‰
                for seg in chunk_result.get('segments', []):
                    all_segments.append({
                        'start': seg['start'] + time_offset,
                        'end': seg['end'] + time_offset,
                        'text': seg['text']
                    })
                    
            except Exception as chunk_err:
                print(f"   âš ï¸  ç‰‡æ®µ {i+1} è½¬å†™å¤±è´¥: {chunk_err}")
                all_text.append(f"[ç‰‡æ®µ{i+1}è½¬å†™å¤±è´¥]")
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        chunk_dir = audio_path.parent / "audio_chunks"
        if chunk_dir.exists():
            import shutil
            shutil.rmtree(chunk_dir)
        
        print(f"   âœ… åˆå¹¶ {len(chunks)} ä¸ªç‰‡æ®µçš„è½¬å†™ç»“æœ")
        
        return {
            'text': ' '.join(all_text),
            'segments': all_segments,
            'asr_model': model
        }
        
    except Exception as e:
        print(f"  âœ— Groq è½¬å†™å¤±è´¥: {e}")
        return {
            'text': f"[è½¬å†™å¤±è´¥: {str(e)}]",
            'segments': [],
            'asr_model': f"{model} (å¤±è´¥)"
        }


def estimate_token_count(text: str) -> int:
    """
    ä¼°ç®—æ–‡æœ¬çš„ token æ•°é‡
    è§„åˆ™ï¼š
    - ä¸­æ–‡å­—ç¬¦ï¼š1:1 (1ä¸ªå­—ç¬¦ = 1 token)
    - å…¶ä»–å­—ç¬¦ï¼ˆä¸»è¦æ˜¯è‹±æ–‡ï¼‰ï¼š2:1 (2ä¸ªå­—ç¬¦ = 1 tokenï¼Œå³ count / 2)
    """
    import re
    # ç»Ÿè®¡ä¸­æ–‡å­—ç¬¦æ•° (åŸºæœ¬æ±‰å­—èŒƒå›´)
    chinese_chars = len(re.findall(r'[\u4e00-\u9fa5]', text))
    # ç»Ÿè®¡å…¶ä»–å­—ç¬¦æ•°
    other_chars = len(text) - chinese_chars
    
    # è®¡ç®— token
    token_count = chinese_chars + int(other_chars / 2)
    return token_count


def summarize_with_gemini(full_text: str, custom_prompt: str = None) -> tuple:
    """
    ä½¿ç”¨ Gemini API å¤„ç†æ–‡æœ¬
    Args:
        full_text: è¾“å…¥æ–‡æœ¬
        custom_prompt: å¯é€‰çš„è‡ªå®šä¹‰æç¤ºè¯ã€‚å¦‚æœæœªæä¾›ï¼Œä½¿ç”¨é»˜è®¤çš„"çŸ¥è¯†æ¡£æ¡ˆ"æç¤ºè¯ã€‚
    
    Returns: 
        (summary_text, model_name)
    """
    api_key = os.getenv("GEMINI_API_KEY")
    model_name = os.getenv("GEMINI_MODEL", "gemini-3-flash-preview")
    
    if not api_key:
        print("  âš ï¸  GEMINI_API_KEY æœªè®¾ç½®ï¼Œæ— æ³•å¤„ç†é•¿æ–‡æœ¬")
        return (f"[ERROR: GEMINI_API_KEY æœªè®¾ç½®]\n\n{full_text[:1000]}...(æ–‡æœ¬è¿‡é•¿å·²æˆªæ–­)", f"{model_name} (å¤±è´¥)")
    
    try:
        client = genai.Client(api_key=api_key)
        
        # å¦‚æœæä¾›äº†è‡ªå®šä¹‰æç¤ºè¯ï¼Œç›´æ¥ä½¿ç”¨å®ƒ
        if custom_prompt:
            prompt = f"{custom_prompt}\n\nä»¥ä¸‹æ˜¯å†…å®¹ï¼š\n{full_text}"
        else:
            # é»˜è®¤æç¤ºè¯ï¼ˆç”Ÿæˆçš„æ‘˜è¦/çŸ¥è¯†æ¡£æ¡ˆï¼‰
            prompt = f"""

è¯·å°†ä»¥ä¸‹"å¸¦æ—¶é—´æˆ³çš„éŸ³é¢‘è½¬å†™ + OCR æ–‡æœ¬"æ•´ç†æˆä¸€ä»½**ç»“æ„åŒ– Markdown çŸ¥è¯†æ¡£æ¡ˆå’Œå†…å®¹æ¦‚è¦**ã€‚


**âš ï¸ é‡è¦ï¼šè¯†åˆ«é”™è¯¯ä¿®æ­£**
- è¯­éŸ³è¯†åˆ«(ASR)å’ŒOCRéƒ½å¯èƒ½å­˜åœ¨**åŒéŸ³å­—/è¯çš„è¯†åˆ«é”™è¯¯**ï¼Œç‰¹åˆ«æ˜¯ä¸“ä¸šæœ¯è¯­
- ä½ å¿…é¡»æ ¹æ®ä¸Šä¸‹æ–‡**ä¸»åŠ¨è¯†åˆ«å¹¶ä¿®æ­£**è¿™äº›é”™è¯¯
- å¸¸è§é”™è¯¯ç±»å‹ï¼š
  * ä¸“ä¸šæœ¯è¯­ï¼š"æœºå™¨å­¦ä¹ "è¢«è¯†åˆ«ä¸º"é¸¡å™¨å­¦ä¹ "ã€"ç¥ç»ç½‘ç»œ"è¯†åˆ«ä¸º"ç¥ç»å¾€ç½—"
  * äººååœ°åï¼š"å¼ ä¸‰"è¯†åˆ«ä¸º"ç« ä¸‰"ã€"åŒ—äº¬"è¯†åˆ«ä¸º"èƒŒæ™¯"
  * è‹±æ–‡æœ¯è¯­ï¼š"API"è¯†åˆ«ä¸º"å“æ‰¹çˆ±"ã€"Python"è¯†åˆ«ä¸º"æ´¾æ£®"
  * æ•°å­—å•ä½ï¼š"3åƒå…‹"è¯†åˆ«ä¸º"3åƒå®¢"ã€"2ç±³"è¯†åˆ«ä¸º"2å¯†"
- ä¿®æ­£æ—¶è¯·ä½¿ç”¨ä¸“ä¸šã€å‡†ç¡®çš„æœ¯è¯­

**âš ï¸ å†…å®¹æ¸…æ´—ï¼šå¿½ç•¥å¹¿å‘Šå¹²æ‰°**
- è¯·è¯†åˆ«å¹¶**å®Œå…¨å¿½ç•¥**è§†é¢‘ä¸­çš„æ’æ’­å¹¿å‘Šã€èµåŠ©å•†å£æ’­æˆ–è·‘é©¬ç¯ä¿¡æ¯
- å…¸å‹ä¾‹å­ï¼šè½¬è½¬äºŒæ‰‹æœºã€æ‹¼å¤šå¤šã€æŸæŸç§‘æŠ€ä¼ä¸šå®£ä¼ ã€"ç‚¹å‡»å…³æ³¨"ã€"ä¸€é”®ä¸‰è¿"ç­‰
- ç¡®ä¿è¾“å‡ºå†…å®¹ä»…å…³äºè§†é¢‘çš„æ ¸å¿ƒä¸»é¢˜çŸ¥è¯†ï¼Œä¸è¦åŒ…å«ä»»ä½•æ¨å¹¿ä¿¡æ¯

ä½ éœ€è¦ï¼š
1. **ä½¿ç”¨ Markdown** è¾“å‡ºï¼ˆæ ‡é¢˜ã€åˆ—è¡¨ã€å¼•ç”¨ã€è¡¨æ ¼ç­‰ï¼‰
2. æŒ‰æ—¶é—´é¡ºåºæ¢³ç†ä¸»è¦ç‰‡æ®µï¼Œå¹¶ä¸ºå…³é”®å†…å®¹æ ‡æ³¨å¯¹åº”æ—¶é—´æˆ³
3. åˆå¹¶éŸ³é¢‘ä¸ OCR å†…å®¹ï¼š  
   - å¦‚æœ OCR æ–‡å­—ä¸å®Œæ•´ï¼Œè¯·æ ¹æ®ä¸Šä¸‹æ–‡**æ¨æ–­åˆç†å«ä¹‰**  
   - å¦‚æœæŸäº›å±å¹•æ–‡å­—é‡è¦ï¼ˆå¦‚ PPTã€ç•Œé¢æŒ‰é’®ã€å‚æ•°ã€ä»£ç ï¼‰ï¼Œè¯·å•ç‹¬æå–å¹¶è§£é‡Š
   - **ä¸è¦ç¼–é€ ä¸å­˜åœ¨çš„OCRä¿¡æ¯**ï¼šå¦‚æœæ— æ³•ç¡®è®¤å±å¹•ä¸Šæœ‰å…·ä½“æ–‡å­—ï¼Œè¯·ä¸è¦åœ¨"OCRä¿¡æ¯ä¸æ¨æ–­"ä¸­å¼ºè¡Œç¼–é€ ã€‚ä»…åœ¨ç¡®æœ‰ä¾æ®ï¼ˆæ—¶é—´æˆ³å¯¹åº”çš„OCRæ–‡æœ¬ï¼‰æ—¶æ‰åˆ—å‡ºã€‚
   - **ä¸»åŠ¨ä¿®æ­£è¯†åˆ«é”™è¯¯**ï¼šåŒéŸ³å­—æ›¿æ¢ã€æœ¯è¯­çº æ­£ã€æ‹¼å†™ä¿®å¤
4. è‡ªåŠ¨è¯†åˆ«"ä¸»é¢˜/ç« èŠ‚"å¹¶ç»“æ„åŒ–æ€»ç»“ï¼šæ¦‚å¿µã€æ­¥éª¤ã€åœºæ™¯ã€ç»“è®º
5. æå–é‡è¦æ•°æ®ï¼šæ•°å­—ã€é˜ˆå€¼ã€è§„åˆ™ã€å¼•ç”¨ã€å‘½ä»¤ã€æ—¥æœŸç­‰
6. ç”Ÿæˆæ ‡ç­¾å’Œæ‘˜è¦ï¼š
   - **æ ‡ç­¾ï¼ˆtagsï¼‰**ï¼š3-6ä¸ªé«˜åº¦æ¦‚æ‹¬çš„ä¸»é¢˜æ ‡ç­¾ï¼Œå¦‚"æƒ…æ„Ÿ"ã€"å‘Šç™½"ã€"äººç”Ÿæ„ä¹‰"ã€"ç§‘æŠ€"ã€"æ•™è‚²"ç­‰ã€‚é¿å…ä½¿ç”¨"è¯­éŸ³è½¬å†™"ã€"OCRæ¨æ–­"ç­‰æŠ€æœ¯æ€§æè¿°è¯ã€‚æ ‡ç­¾åº”ç®€çŸ­ï¼ˆ1-4ä¸ªå­—ï¼‰ï¼Œæ¦‚æ‹¬æ€§å¼ºï¼Œä¾¿äºæ•°æ®åº“æœç´¢ã€‚
   - **æ‘˜è¦**ï¼šä¸è¶…è¿‡50ä¸ªå­—çš„ç³»ç»Ÿæ€§å†…å®¹æ¦‚æ‹¬ï¼Œæç‚¼æ ¸å¿ƒä¸»é¢˜å’Œè¦ç‚¹ã€‚
7. ç¨å¾®è¯¦ç»†ä¸€äº›ï¼Œä½†ä¸è¦å†™åºŸè¯ï¼ˆé‡ç‚¹æ˜¯**å¯å›æº¯ã€å¯æœç´¢ã€å¯ç†è§£**ï¼‰

æ¨èç»“æ„ï¼š
## æ‘˜è¦
ï¼ˆä¸è¶…è¿‡50å­—çš„æ ¸å¿ƒå†…å®¹æ¦‚æ‹¬ï¼‰

## ä¸»è¦å†…å®¹æ¦‚æ‹¬
## ä¸»é¢˜æ€»ç»“ï¼ˆè‡ªåŠ¨ç”Ÿæˆä¸»é¢˜åï¼‰
## è¯¦ç»†è¯´æ˜ï¼ˆåˆå¹¶éŸ³é¢‘ä¸ OCRï¼‰
## å…³é”®ä¿¡æ¯ï¼ˆæ•°å­—ã€è§„åˆ™ã€å‚æ•°ï¼‰
## OCR ä¿¡æ¯ä¸æ¨æ–­ï¼ˆä»…åˆ—å‡ºç¡®å‡¿çš„å±å¹•å…³é”®æ–‡å­—ï¼Œä¸è¦ç¼–é€ ï¼‰
## æ—¶é—´çº¿ï¼ˆå…³é”®ç‰‡æ®µ + æ—¶é—´æˆ³ï¼‰
## å…³é”®å¥ï¼ˆå«æ—¶é—´æˆ³ï¼‰
## æ ‡ç­¾
æ ¼å¼ï¼šæ ‡ç­¾: æ ‡ç­¾1, æ ‡ç­¾2, æ ‡ç­¾3

ä»¥ä¸‹æ˜¯å†…å®¹ï¼š
{full_text}

"""

        response = client.models.generate_content(
            model=model_name,
            contents=prompt,
        )
        
        return (response.text, model_name)
    except Exception as e:
        print(f"  âœ— Gemini æ€»ç»“å¤±è´¥: {e}")
        return (f"[æ€»ç»“å¤±è´¥: {str(e)}]\n\nåŸå§‹å†…å®¹:\n{full_text[:1000]}...(å·²æˆªæ–­)", f"{model_name} (å¤±è´¥)")


def summarize_with_gpt_oss_120b(full_text: str) -> tuple:
    """
    ä½¿ç”¨ Groq çš„ LLM è¿›è¡Œæ–‡æœ¬æ€»ç»“ã€‚
    æ”¯æŒè‡ªåŠ¨åˆ‡æ¢æˆ–å¼ºåˆ¶ä½¿ç”¨ Geminiã€‚
    è¿”å›: (summary_text, model_name)
    """
    # æ£€æŸ¥æ˜¯å¦å¼ºåˆ¶ä½¿ç”¨ Gemini
    llm_provider = os.getenv("LLM_PROVIDER", "").lower()
    if llm_provider == "gemini":
        print("  ğŸ”„ ç”¨æˆ·å¼ºåˆ¶é€‰æ‹©: ä½¿ç”¨ Gemini API")
        return summarize_with_gemini(full_text)

    # ä¼°ç®— token æ•°é‡
    estimated_tokens = estimate_token_count(full_text)
    print(f"  ğŸ“Š ä¼°ç®—æ–‡æœ¬é•¿åº¦: ~{estimated_tokens:,} tokens ({len(full_text):,} å­—ç¬¦)")
    
    # å¦‚æœè¶…è¿‡ 5 ä¸‡ tokenï¼Œä½¿ç”¨ Gemini (ä¸”æ²¡å¼ºåˆ¶æŒ‡å®š oss)
    if estimated_tokens > 50000 and llm_provider != "oss":
        print(f"  ğŸ”„ æ–‡æœ¬è¿‡é•¿ (>{50000:,} tokens)ï¼Œåˆ‡æ¢åˆ° Gemini API")
        return summarize_with_gemini(full_text)
    
    # å¦åˆ™ä½¿ç”¨ Groq
    api_key = os.getenv("GROQ_API_KEY")
    model_name = os.getenv("GROQ_LLM_MODEL", "openai/gpt-oss-120b")
    
    if not api_key:
        print("  âš ï¸  GROQ_API_KEY æœªè®¾ç½®ï¼Œè¿”å›åŸæ–‡")
        return (f"[FAKE SUMMARY - è¯·åœ¨ .env ä¸­è®¾ç½® GROQ_API_KEY]\n\n{full_text}", f"{model_name} (å¤±è´¥)")
    
    try:
        client = Groq(api_key=api_key)
        # å¢åŠ  token é™åˆ¶ä»¥æ”¯æŒæ›´é•¿çš„è¾“å‡º
        max_tokens = int(os.getenv("GROQ_MAX_TOKENS", "8192"))  # ä» 4096 æå‡åˆ° 8192
        temperature = float(os.getenv("GROQ_TEMPERATURE", "0.7"))
        
        prompt = f"""

è¯·å°†ä»¥ä¸‹â€œå¸¦æ—¶é—´æˆ³çš„éŸ³é¢‘è½¬å†™ + OCR æ–‡æœ¬â€æ•´ç†æˆä¸€ä»½**ç»“æ„åŒ– Markdown çŸ¥è¯†æ¡£æ¡ˆå’Œå†…å®¹æ¦‚è¦**ã€‚


**âš ï¸ é‡è¦ï¼šè¯†åˆ«é”™è¯¯ä¿®æ­£**
- è¯­éŸ³è¯†åˆ«(ASR)å’ŒOCRéƒ½å¯èƒ½å­˜åœ¨**åŒéŸ³å­—/è¯çš„è¯†åˆ«é”™è¯¯**ï¼Œç‰¹åˆ«æ˜¯ä¸“ä¸šæœ¯è¯­
- ä½ å¿…é¡»æ ¹æ®ä¸Šä¸‹æ–‡**ä¸»åŠ¨è¯†åˆ«å¹¶ä¿®æ­£**è¿™äº›é”™è¯¯
- å¸¸è§é”™è¯¯ç±»å‹ï¼š
  * ä¸“ä¸šæœ¯è¯­ï¼š"æœºå™¨å­¦ä¹ "è¢«è¯†åˆ«ä¸º"é¸¡å™¨å­¦ä¹ "ã€"ç¥ç»ç½‘ç»œ"è¯†åˆ«ä¸º"ç¥ç»å¾€ç½—"
  * äººååœ°åï¼š"å¼ ä¸‰"è¯†åˆ«ä¸º"ç« ä¸‰"ã€"åŒ—äº¬"è¯†åˆ«ä¸º"èƒŒæ™¯"
  * è‹±æ–‡æœ¯è¯­ï¼š"API"è¯†åˆ«ä¸º"å“æ‰¹çˆ±"ã€"Python"è¯†åˆ«ä¸º"æ´¾æ£®"
  * æ•°å­—å•ä½ï¼š"3åƒå…‹"è¯†åˆ«ä¸º"3åƒå®¢"ã€"2ç±³"è¯†åˆ«ä¸º"2å¯†"
- ä¿®æ­£æ—¶è¯·ä½¿ç”¨ä¸“ä¸šã€å‡†ç¡®çš„æœ¯è¯­

**âš ï¸ å†…å®¹æ¸…æ´—ï¼šå¿½ç•¥å¹¿å‘Šå¹²æ‰°**
- è¯·è¯†åˆ«å¹¶**å®Œå…¨å¿½ç•¥**è§†é¢‘ä¸­çš„æ’æ’­å¹¿å‘Šã€èµåŠ©å•†å£æ’­æˆ–è·‘é©¬ç¯ä¿¡æ¯
- å…¸å‹ä¾‹å­ï¼šè½¬è½¬äºŒæ‰‹æœºã€æ‹¼å¤šå¤šã€æŸæŸç§‘æŠ€ä¼ä¸šå®£ä¼ ã€"ç‚¹å‡»å…³æ³¨"ã€"ä¸€é”®ä¸‰è¿"ç­‰
- ç¡®ä¿è¾“å‡ºå†…å®¹ä»…å…³äºè§†é¢‘çš„æ ¸å¿ƒä¸»é¢˜çŸ¥è¯†

ä½ éœ€è¦ï¼š
1. **ä½¿ç”¨ Markdown** è¾“å‡ºï¼ˆæ ‡é¢˜ã€åˆ—è¡¨ã€å¼•ç”¨ã€è¡¨æ ¼ç­‰ï¼‰
2. æŒ‰æ—¶é—´é¡ºåºæ¢³ç†ä¸»è¦ç‰‡æ®µï¼Œå¹¶ä¸ºå…³é”®å†…å®¹æ ‡æ³¨å¯¹åº”æ—¶é—´æˆ³
3. åˆå¹¶éŸ³é¢‘ä¸ OCR å†…å®¹ï¼š  
   - å¦‚æœ OCR æ–‡å­—ä¸å®Œæ•´ï¼Œè¯·æ ¹æ®ä¸Šä¸‹æ–‡**æ¨æ–­åˆç†å«ä¹‰**  
   - å¦‚æœæŸäº›å±å¹•æ–‡å­—é‡è¦ï¼ˆå¦‚ PPTã€ç•Œé¢æŒ‰é’®ã€å‚æ•°ã€ä»£ç ï¼‰ï¼Œè¯·å•ç‹¬æå–å¹¶è§£é‡Š
   - **ä¸è¦ç¼–é€ ä¸å­˜åœ¨çš„OCRä¿¡æ¯**ï¼šå¦‚æœæ— æ³•ç¡®è®¤å±å¹•ä¸Šæœ‰å…·ä½“æ–‡å­—ï¼Œè¯·ä¸è¦åœ¨"OCRä¿¡æ¯ä¸æ¨æ–­"ä¸­å¼ºè¡Œç¼–é€ ã€‚ä»…åœ¨ç¡®æœ‰ä¾æ®ï¼ˆæ—¶é—´æˆ³å¯¹åº”çš„OCRæ–‡æœ¬ï¼‰æ—¶æ‰åˆ—å‡ºã€‚
   - **ä¸»åŠ¨ä¿®æ­£è¯†åˆ«é”™è¯¯**ï¼šåŒéŸ³å­—æ›¿æ¢ã€æœ¯è¯­çº æ­£ã€æ‹¼å†™ä¿®å¤
4. è‡ªåŠ¨è¯†åˆ«â€œä¸»é¢˜/ç« èŠ‚â€å¹¶ç»“æ„åŒ–æ€»ç»“ï¼šæ¦‚å¿µã€æ­¥éª¤ã€åœºæ™¯ã€ç»“è®º
5. æå–é‡è¦æ•°æ®ï¼šæ•°å­—ã€é˜ˆå€¼ã€è§„åˆ™ã€å¼•ç”¨ã€å‘½ä»¤ã€æ—¥æœŸç­‰
6. ç”Ÿæˆæ ‡ç­¾å’Œæ‘˜è¦ï¼š
   - **æ ‡ç­¾ï¼ˆtagsï¼‰**ï¼š3-6ä¸ªé«˜åº¦æ¦‚æ‹¬çš„ä¸»é¢˜æ ‡ç­¾ï¼Œå¦‚"æƒ…æ„Ÿ"ã€"å‘Šç™½"ã€"äººç”Ÿæ„ä¹‰"ã€"ç§‘æŠ€"ã€"æ•™è‚²"ç­‰ã€‚é¿å…ä½¿ç”¨"è¯­éŸ³è½¬å†™"ã€"OCRæ¨æ–­"ç­‰æŠ€æœ¯æ€§æè¿°è¯ã€‚æ ‡ç­¾åº”ç®€çŸ­ï¼ˆ1-4ä¸ªå­—ï¼‰ï¼Œæ¦‚æ‹¬æ€§å¼ºï¼Œä¾¿äºæ•°æ®åº“æœç´¢ã€‚
   - **æ‘˜è¦**ï¼šä¸è¶…è¿‡50ä¸ªå­—çš„ç³»ç»Ÿæ€§å†…å®¹æ¦‚æ‹¬ï¼Œæç‚¼æ ¸å¿ƒä¸»é¢˜å’Œè¦ç‚¹ã€‚
7. ç¨å¾®è¯¦ç»†ä¸€äº›ï¼Œä½†ä¸è¦å†™åºŸè¯ï¼ˆé‡ç‚¹æ˜¯**å¯å›æº¯ã€å¯æœç´¢ã€å¯ç†è§£**ï¼‰

æ¨èç»“æ„ï¼š
## æ‘˜è¦
ï¼ˆä¸è¶…è¿‡50å­—çš„æ ¸å¿ƒå†…å®¹æ¦‚æ‹¬ï¼‰

## ä¸»è¦å†…å®¹æ¦‚æ‹¬
## ä¸»é¢˜æ€»ç»“ï¼ˆè‡ªåŠ¨ç”Ÿæˆä¸»é¢˜åï¼‰
## è¯¦ç»†è¯´æ˜ï¼ˆåˆå¹¶éŸ³é¢‘ä¸ OCRï¼‰
## å…³é”®ä¿¡æ¯ï¼ˆæ•°å­—ã€è§„åˆ™ã€å‚æ•°ï¼‰
## OCR ä¿¡æ¯ä¸æ¨æ–­ï¼ˆä»…åˆ—å‡ºç¡®å‡¿çš„å±å¹•å…³é”®æ–‡å­—ï¼Œä¸è¦ç¼–é€ ï¼‰
## æ—¶é—´çº¿ï¼ˆå…³é”®ç‰‡æ®µ + æ—¶é—´æˆ³ï¼‰
## å…³é”®å¥ï¼ˆå«æ—¶é—´æˆ³ï¼‰
## æ ‡ç­¾
æ ¼å¼ï¼šæ ‡ç­¾: æ ‡ç­¾1, æ ‡ç­¾2, æ ‡ç­¾3

ä»¥ä¸‹æ˜¯å†…å®¹ï¼š
{full_text}  



"""

        response = client.chat.completions.create(
            model=model_name,
            messages=[
                {
                    "role": "system",
                    "content": """ä½ æ˜¯ä¸€ä¸ªå¤šæ¨¡æ€çŸ¥è¯†æ¡£æ¡ˆç”Ÿæˆå™¨ï¼Œå…·å¤‡æ™ºèƒ½çº é”™èƒ½åŠ›ã€‚

                    è¾“å…¥æ¥è‡ªåŒä¸€æ®µè§†é¢‘ï¼ŒåŒ…æ‹¬ï¼š
                    - å¸¦æ—¶é—´æˆ³çš„éŸ³é¢‘è½¬å†™ï¼ˆå¯èƒ½å«ASRè¯†åˆ«é”™è¯¯ï¼‰
                    - å¸¦æ—¶é—´æˆ³æˆ–å¸§åºåˆ—çš„ OCR æ–‡æœ¬ï¼ˆå¯èƒ½å«OCRè¯†åˆ«é”™è¯¯ï¼‰

                    ä½ çš„èŒè´£æ˜¯ï¼š
                    - èåˆéŸ³é¢‘ä¸ OCR å†…å®¹
                    - åˆ©ç”¨æ—¶é—´æˆ³é‡å»ºç»“æ„ä¸é¡ºåº
                    - æ ¹æ®å†…å®¹è‡ªåŠ¨è¯†åˆ«ä¸»é¢˜ä¸é‡ç‚¹
                    - **æ™ºèƒ½çº é”™**ï¼šä¸»åŠ¨è¯†åˆ«å¹¶ä¿®æ­£åŒéŸ³å­—/è¯é”™è¯¯ï¼Œç‰¹åˆ«æ˜¯ä¸“ä¸šæœ¯è¯­ã€äººååœ°åã€è‹±æ–‡ç¼©å†™
                    - æ¨æ–­çº æ­£ OCR å¯èƒ½çš„æ–‡å­—è¯†åˆ«é”™è¯¯
                    - ç¡®ä¿è¾“å‡ºä½¿ç”¨å‡†ç¡®ã€ä¸“ä¸šçš„æœ¯è¯­è¡¨è¾¾
                    - ç”Ÿæˆæ¸…æ™°ã€å¯é•¿æœŸä¿å­˜ã€é€‚åˆæ£€ç´¢çš„ Markdown çŸ¥è¯†æ¡£æ¡ˆ"""
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            max_tokens=max_tokens,
            temperature=temperature,
        )
        
        return (response.choices[0].message.content, model_name)
    except Exception as e:
        print(f"  âœ— Groq æ€»ç»“å¤±è´¥: {e}")
        return (f"[æ€»ç»“å¤±è´¥: {str(e)}]\n\nåŸå§‹å†…å®¹:\n{full_text}", f"{model_name} (å¤±è´¥)")


def generate_detailed_content(full_text: str) -> tuple:
    """
    ç”Ÿæˆè¯¦ç»†çš„å†…å®¹æ¦‚æ‹¬ï¼ŒåŒ…å«æ›´å¤šç»†èŠ‚ã€‚
    æ”¯æŒè‡ªåŠ¨åˆ‡æ¢æˆ–å¼ºåˆ¶ä½¿ç”¨ Geminiã€‚
    è¿”å›: (detailed_content, model_name)
    """
    # æ„é€  OSS (Groq) å’Œä¸€èˆ¬æƒ…å†µçš„è¯¦ç»†å†…å®¹æç¤ºè¯
    default_prompt_text = f"""
è¯·åŸºäºä»¥ä¸‹è§†é¢‘çš„éŸ³é¢‘è½¬å†™å’ŒOCRæ–‡æœ¬(å¦‚æœæœ‰ï¼‰ï¼Œç”Ÿæˆä¸€ä»½**è¯¦ç»†çš„å†…å®¹æ¦‚æ‹¬**ã€‚

**âš ï¸ è¯†åˆ«é”™è¯¯ä¿®æ­£**ï¼š
- éŸ³é¢‘è½¬å†™å’ŒOCRæ–‡æœ¬å¯èƒ½å­˜åœ¨åŒéŸ³å­—/è¯è¯†åˆ«é”™è¯¯
- è¯·æ ¹æ®ä¸Šä¸‹æ–‡**ä¸»åŠ¨ä¿®æ­£**è¿™äº›é”™è¯¯ï¼Œç‰¹åˆ«æ˜¯ï¼š
  * ä¸“ä¸šæœ¯è¯­ï¼ˆæŠ€æœ¯åè¯ã€å­¦æœ¯æ¦‚å¿µï¼‰
  * äººåã€åœ°åã€æœºæ„å
  * è‹±æ–‡ç¼©å†™å’Œæœ¯è¯­
  * æ•°å­—ã€å•ä½ã€å‚æ•°
- ä¿®æ­£åä½¿ç”¨å‡†ç¡®ã€è§„èŒƒçš„è¡¨è¾¾

**âš ï¸ å†…å®¹æ¸…æ´—ï¼šå¿½ç•¥å¹¿å‘Šå¹²æ‰°**
- è¯·è¯†åˆ«å¹¶**å®Œå…¨å¿½ç•¥**è§†é¢‘ä¸­çš„æ’æ’­å¹¿å‘Šã€èµåŠ©å•†å£æ’­æˆ–è·‘é©¬ç¯ä¿¡æ¯
- å…¸å‹ä¾‹å­ï¼šè½¬è½¬äºŒæ‰‹æœºã€æ‹¼å¤šå¤šã€æŸæŸç§‘æŠ€ä¼ä¸šå®£ä¼ ã€"ç‚¹å‡»å…³æ³¨"ã€"ä¸€é”®ä¸‰è¿"ç­‰
- ç¡®ä¿è¾“å‡ºå†…å®¹ä»…å…³äºè§†é¢‘çš„æ ¸å¿ƒä¸»é¢˜çŸ¥è¯†

è¦æ±‚ï¼š
1. **é€æ®µè¯¦ç»†å±•å¼€**ï¼šæŒ‰è§†é¢‘çš„æ—¶é—´é¡ºåºï¼Œè¯¦ç»†æè¿°æ¯ä¸ªä¸»è¦éƒ¨åˆ†çš„å†…å®¹
2. **ä¿ç•™å…³é”®ç»†èŠ‚**ï¼š
   - å…·ä½“çš„æ•°å­—ã€æ•°æ®ã€å‚æ•°ï¼ˆä¿®æ­£è¯†åˆ«é”™è¯¯åçš„å‡†ç¡®å€¼ï¼‰
   - äººåã€åœ°åã€ä¸“ä¸šæœ¯è¯­ï¼ˆç¡®ä¿æ‹¼å†™å’Œè¡¨è¾¾å‡†ç¡®ï¼‰
   - å…·ä½“çš„æ“ä½œæ­¥éª¤ã€æµç¨‹
   - å¼•ç”¨çš„åŸè¯ã€å…³é”®å¥å­ï¼ˆçº æ­£æ˜æ˜¾çš„è¯†åˆ«é”™è¯¯ï¼‰
   - ä»£ç ç‰‡æ®µã€å‘½ä»¤ã€å…¬å¼
3. **æ—¶é—´æˆ³æ ‡æ³¨**ï¼šä¸ºé‡è¦å†…å®¹æ ‡æ³¨å¯¹åº”çš„æ—¶é—´ç‚¹ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
4. **å®Œæ•´æ€§ä¼˜å…ˆ**ï¼šå®å¯å†…å®¹å¤šä¸€äº›ï¼Œä¹Ÿä¸è¦é—æ¼é‡è¦ä¿¡æ¯
5. **ç»“æ„æ¸…æ™°**ï¼šä½¿ç”¨å±‚çº§æ ‡é¢˜å’Œåˆ—è¡¨ç»„ç»‡å†…å®¹

è¾“å‡ºæ ¼å¼ï¼š
## è¯¦ç»†å†…å®¹æ¦‚æ‹¬

### ç¬¬ä¸€éƒ¨åˆ†ï¼š[ä¸»é¢˜åç§°]
ï¼ˆè¯¦ç»†æè¿°è¿™éƒ¨åˆ†çš„å†…å®¹...ï¼‰

### ç¬¬äºŒéƒ¨åˆ†ï¼š[ä¸»é¢˜åç§°]
ï¼ˆè¯¦ç»†æè¿°è¿™éƒ¨åˆ†çš„å†…å®¹...ï¼‰

### å…³é”®ä¿¡æ¯æ±‡æ€»
- é‡è¦æ•°æ®ï¼š...
- å…³é”®æœ¯è¯­ï¼š...
- æ“ä½œæ­¥éª¤ï¼š...

### åŸæ–‡å…³é”®å¥æ‘˜å½•
> "åŸå¥1..." â€”â€” [æ—¶é—´æˆ³]
> "åŸå¥2..." â€”â€” [æ—¶é—´æˆ³]

"""

    # æ„é€  Gemini ä¸“ç”¨çš„è¯¦ç»†å†…å®¹æç¤ºè¯ (é¼“åŠ±æ›´é•¿è¾“å‡º)
    gemini_prompt_text = f"""
è¯·åŸºäºä»¥ä¸‹è§†é¢‘çš„éŸ³é¢‘è½¬å†™å’Œ OCR æ–‡æœ¬(å¦‚æœæœ‰ï¼‰ï¼Œç”Ÿæˆä¸€ä»½**æè‡´è¯¦ç»†ã€å†…å®¹å…¨é¢**çš„æ·±åº¦å†…å®¹æ¦‚æ‹¬ã€‚

**âš ï¸ æˆ‘ä»¬çš„ç›®æ ‡æ˜¯ï¼šç”Ÿæˆä¸€ä»½æ— éœ€è§‚çœ‹åŸè§†é¢‘å°±èƒ½è·å–æ‰€æœ‰ç»†èŠ‚çš„å®Œæ•´æ¡£æ¡ˆã€‚ä¸è¦åœ¨æ„é•¿åº¦ï¼Œå°½å¯èƒ½å¤šåœ°ä¿ç•™ä¿¡æ¯ã€‚**

**ğŸ” 1. æ·±åº¦å†…å®¹è§£æ**
- **é€å­—é€å¥çš„ç»†èŠ‚ä¿ç•™**ï¼šä¸ä»…è¦æ¦‚æ‹¬å¤§æ„ï¼Œæ›´è¦è¿˜åŸè®²è€…çš„å…·ä½“è®ºè¿°é€»è¾‘ã€ä¸¾ä¾‹è¯´æ˜ã€æ•°æ®æ”¯æ’‘ã€‚
- **æ‰€æœ‰å…³é”®ä¿¡æ¯**ï¼šä»»ä½•æ•°å­—ã€å¹´ä»½ã€äººåã€ä¹¦åã€å·¥å…·åã€ä»£ç ç‰‡æ®µã€é…ç½®å‚æ•°ï¼Œéƒ½å¿…é¡»å‡†ç¡®è®°å½•ã€‚
- **æƒ…æ„Ÿä¸è¯­å¢ƒ**ï¼šå¦‚æœè®²è€…è¡¨è¾¾äº†å¼ºçƒˆè§‚ç‚¹ã€å¹½é»˜ã€åè®½æˆ–æƒ…ç»ªå˜åŒ–ï¼Œè¯·åœ¨æè¿°ä¸­ä½“ç°ã€‚
- **ä¸è¦çœç•¥**ï¼šä¸è¦ä½¿ç”¨"..."æˆ–"ç•¥è¿‡"ç­‰ç®€å†™ï¼ŒæŠŠå†…å®¹å¦‚å®å†™å‡ºæ¥ã€‚

**âš ï¸ 2. è¯†åˆ«é”™è¯¯ä¿®æ­£ä¸æ¸…æ´—**
- **æ™ºèƒ½çº é”™**ï¼šæ ¹æ®ä¸Šä¸‹æ–‡ä¸»åŠ¨ä¿®æ­£ ASR/OCR çš„åŒéŸ³å­—é”™è¯¯ï¼ˆå¦‚ "Python" è¯¯è¯†ä¸º "æ´¾æ£®"ï¼‰ã€‚
- **å±è”½å¹¿å‘Š**ï¼šå®Œå…¨å¿½ç•¥è§†é¢‘ä¸­çš„å£æ’­å¹¿å‘Šï¼ˆå¦‚â€œè½¬è½¬äºŒæ‰‹æœºâ€ã€â€œæ‹¼å¤šå¤šâ€ï¼‰ã€æ±‚å…³æ³¨æ‹‰ç¥¨ç­‰æ— å…³å†…å®¹ã€‚
- **æœ¯è¯­è§„èŒƒ**ï¼šå°†å£è¯­åŒ–çš„è¡¨è¾¾è½¬æ¢ä¸ºä¸“ä¸šã€è§„èŒƒçš„ä¹¦é¢æœ¯è¯­ã€‚

**ğŸ“ 3. è¾“å‡ºç»“æ„è¦æ±‚**
è¯·æŒ‰ç…§è§†é¢‘çš„æ—¶é—´çº¿æ€§æµç¨‹ï¼Œå°†å†…å®¹åˆ’åˆ†ä¸ºå¤šä¸ªè¯¦ç»†çš„ç« èŠ‚ã€‚å¯¹äºæ¯ä¸ªç« èŠ‚ï¼š
- **å°æ ‡é¢˜**ï¼šæ¸…æ™°çš„ä¸»é¢˜ã€‚
- **è¯¦ç»†æ®µè½**ï¼šä½¿ç”¨é•¿æ®µè½è¯¦ç»†é˜è¿°ï¼Œè€Œä¸æ˜¯ç®€çŸ­çš„ bullet pointsã€‚
- **å¼•ç”¨åŸè¯**ï¼šå¯¹äºé‡‘å¥æˆ–æ ¸å¿ƒè§‚ç‚¹ï¼Œè¯·ç›´æ¥å¼•ç”¨ï¼ˆä¿®æ­£é”™åˆ«å­—åï¼‰ã€‚
- **æ—¶é—´æˆ³**ï¼šé¢‘ç¹æ ‡æ³¨æ—¶é—´æˆ³ï¼Œæ–¹ä¾¿å›æº¯ã€‚

**ğŸ“Š 4. ä¸“é¡¹ä¿¡æ¯æå–**
åœ¨æ–‡æœ«è¯·å•ç‹¬æ•´ç†ï¼š
- **æ•°æ®æ±‡æ€»**ï¼šæ‰€æœ‰å‡ºç°çš„ç»Ÿè®¡æ•°æ®ã€ä»·æ ¼ã€å‚æ•°ã€‚
- **çŸ¥è¯†å›¾è°±**ï¼šæåˆ°çš„æ‰€æœ‰æ¦‚å¿µã€ç†è®ºã€æ³•åˆ™ã€‚
- **è¡ŒåŠ¨æŒ‡å—**ï¼šå¦‚æœè§†é¢‘åŒ…å«æ•™ç¨‹ï¼Œåˆ—å‡ºä¸€æ­¥æ­¥çš„æ“ä½œæŒ‡å—ã€‚

è¯·å¿½ç•¥ Token é™åˆ¶ï¼Œå°½å¯èƒ½è¯¦å°½åœ°è¾“å‡ºã€‚

ä»¥ä¸‹æ˜¯è¾“å‡ºæ ¼å¼å‚è€ƒï¼š
## ğŸ“– æ·±åº¦è¯¦ç»†å†…å®¹æ¦‚æ‹¬ï¼ˆå®Œæ•´ç‰ˆï¼‰

### [00:00 - 05:30] ç« èŠ‚ä¸€ï¼šèƒŒæ™¯ä¸æ ¸å¿ƒè®ºç‚¹
ï¼ˆè¿™é‡Œéœ€è¦éå¸¸è¯¦ç»†çš„æè¿°ï¼Œè§£é‡Šè®²è€…çš„å‡ºå‘ç‚¹ï¼Œå¼•ç”¨çš„èƒŒæ™¯æ•…äº‹ï¼Œæå‡ºçš„æ ¸å¿ƒçŸ›ç›¾...ï¼‰

### [05:31 - 12:45] ç« èŠ‚äºŒï¼šæ·±åº¦è§£ææŠ€æœ¯åŸç†
ï¼ˆè¯¦ç»†è§£é‡ŠåŸç†çš„æ¯ä¸€ä¸ªæ­¥éª¤ï¼Œä¸è¦é—æ¼ä»»ä½•æŠ€æœ¯ç»†èŠ‚...ï¼‰
...

### ğŸ’¡ æ ¸å¿ƒçŸ¥è¯†ç‚¹ä¸æ•°æ®æ±‡æ€»
...
"""

    # æ£€æŸ¥æ˜¯å¦å¼ºåˆ¶ä½¿ç”¨ Gemini
    llm_provider = os.getenv("LLM_PROVIDER", "").lower()
    if llm_provider == "gemini":
        print("  ğŸ”„ ç”¨æˆ·å¼ºåˆ¶é€‰æ‹©: è¯¦ç»†å†…å®¹ç”Ÿæˆä½¿ç”¨ Gemini API (ä½¿ç”¨å¢å¼ºæç¤ºè¯)")
        return summarize_with_gemini(full_text, custom_prompt=gemini_prompt_text)

    # ä¼°ç®— token æ•°é‡
    estimated_tokens = estimate_token_count(full_text)
    
    # å¦‚æœè¶…è¿‡ 5 ä¸‡ tokenï¼Œä½¿ç”¨ Gemini (ä¸”æ²¡å¼ºåˆ¶æŒ‡å®š oss)
    if estimated_tokens > 50000 and llm_provider != "oss":
        print(f"  ğŸ”„ è¯¦ç»†å†…å®¹æ–‡æœ¬è¿‡é•¿ (>{50000:,} tokens)ï¼Œä½¿ç”¨ Gemini API (ä½¿ç”¨å¢å¼ºæç¤ºè¯)")
        # ä½¿ç”¨Geminiå¤„ç†é•¿æ–‡æœ¬ï¼Œä½¿ç”¨è¯¦ç»†æç¤ºè¯
        return summarize_with_gemini(full_text, custom_prompt=gemini_prompt_text)
    
    api_key = os.getenv("GROQ_API_KEY")
    if not api_key:
        print("  âš ï¸  GROQ_API_KEY æœªè®¾ç½®ï¼Œè·³è¿‡è¯¦ç»†å†…å®¹ç”Ÿæˆ")
        return ("", "N/A")
    
    try:
        client = Groq(api_key=api_key)
        model_name = os.getenv("GROQ_LLM_MODEL", "openai/gpt-oss-120b")
        # è¯¦ç»†å†…å®¹ä½¿ç”¨æ›´å¤§çš„tokené™åˆ¶
        max_tokens = int(os.getenv("GROQ_DETAIL_MAX_TOKENS", "12000"))
        temperature = float(os.getenv("GROQ_TEMPERATURE", "0.7"))
        
        response = client.chat.completions.create(
            model=model_name,
            messages=[
                {
                    "role": "system",
                    "content": """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å†…å®¹æ•´ç†åŠ©æ‰‹ï¼Œå…·å¤‡æ™ºèƒ½çº é”™èƒ½åŠ›ã€‚ä½ çš„ä»»åŠ¡æ˜¯ï¼š
                    - ä»è§†é¢‘è½¬å†™å’ŒOCRæ–‡æœ¬ä¸­æå–æ‰€æœ‰é‡è¦ä¿¡æ¯
                    - **æ™ºèƒ½çº é”™**ï¼šè¯†åˆ«å¹¶ä¿®æ­£è¯­éŸ³è¯†åˆ«å’ŒOCRçš„åŒéŸ³å­—/è¯é”™è¯¯ï¼Œç‰¹åˆ«æ˜¯ä¸“ä¸šæœ¯è¯­
                    - ç”Ÿæˆè¯¦å°½ã€å®Œæ•´çš„å†…å®¹æ¦‚æ‹¬
                    - ä¿ç•™åŸå§‹å†…å®¹ä¸­çš„å…³é”®ç»†èŠ‚å’Œæ•°æ®ï¼ˆä½¿ç”¨ä¿®æ­£åçš„å‡†ç¡®è¡¨è¾¾ï¼‰
                    - ä½¿ç”¨æ¸…æ™°çš„ç»“æ„ç»„ç»‡ä¿¡æ¯
                    - ç¡®ä¿å†…å®¹å¯ä»¥ä½œä¸ºè§†é¢‘å†…å®¹çš„å®Œæ•´å‚è€ƒ
                    - è¾“å‡ºä½¿ç”¨å‡†ç¡®ã€ä¸“ä¸šã€è§„èŒƒçš„æœ¯è¯­è¡¨è¾¾"""
                },
                {
                    "role": "user",
                    "content": f"{default_prompt_text}\n\nä»¥ä¸‹æ˜¯åŸå§‹å†…å®¹ï¼š\n{full_text}"
                }
            ],
            max_tokens=max_tokens,
            temperature=temperature,
        )
        
        return (response.choices[0].message.content, model_name)
    except Exception as e:
        print(f"  âš ï¸  è¯¦ç»†å†…å®¹ç”Ÿæˆå¤±è´¥: {e}")
        return ("", "N/A")


def merge_summary_with_details(summary: str, detailed_content_tuple: tuple) -> str:
    """
    å°†è¯¦ç»†å†…å®¹æ¦‚æ‹¬è¿½åŠ åˆ°æŠ¥å‘Šæœ«å°¾ã€‚
    ä¿æŒåŸæœ‰æŠ¥å‘Šå†…å®¹ä¸å˜ã€‚
    """
    detailed_content, _ = detailed_content_tuple  # è§£åŒ…tupleï¼Œå¿½ç•¥model_name
    if not detailed_content:
        return summary
    
    # ç›´æ¥è¿½åŠ åˆ°æœ«å°¾
    return summary + f"\n\n---\n\n## ğŸ“– è¯¦ç»†å†…å®¹æ¦‚æ‹¬ï¼ˆå®Œæ•´ç‰ˆï¼‰\n\n{detailed_content}\n"


def generate_folder_name_with_llm(report_content: str, video_name: str) -> str:
    """
    ä½¿ç”¨ GPT-OSS20B æ¨¡å‹æ ¹æ® report å†…å®¹ç”Ÿæˆç®€æ´çš„æ–‡ä»¶å¤¹åç§°
    
    Args:
        report_content: å®Œæ•´çš„æŠ¥å‘Šå†…å®¹
        video_name: åŸå§‹è§†é¢‘åç§°ï¼ˆä½œä¸ºå¤‡ç”¨ï¼‰
    
    Returns:
        ç”Ÿæˆçš„æ–‡ä»¶å¤¹åç§°ï¼ˆé•¿åº¦é™åˆ¶åœ¨30ä¸ªå­—ç¬¦ä»¥å†…ï¼Œä½¿ç”¨ä¸‹åˆ’çº¿åˆ†éš”ï¼‰
    """
    api_key = os.getenv("GROQ_API_KEY")
    if not api_key:
        print("  âš ï¸  GROQ_API_KEY æœªè®¾ç½®ï¼Œä½¿ç”¨é»˜è®¤æ–‡ä»¶å¤¹å")
        return video_name
    
    try:
        client = Groq(api_key=api_key)
        
        # ä»æŠ¥å‘Šä¸­æå–å…³é”®ä¿¡æ¯ï¼ˆæ‘˜è¦éƒ¨åˆ†ï¼‰
        # ä¼˜å…ˆæå– "## æ‘˜è¦" éƒ¨åˆ†ï¼Œè¿™æ˜¯è§†é¢‘çš„æ ¸å¿ƒå†…å®¹æ¦‚æ‹¬
        summary_section = ""
        
        # æ–¹æ³•1: æŸ¥æ‰¾ ## æ‘˜è¦
        if "## æ‘˜è¦" in report_content:
            parts = report_content.split("## æ‘˜è¦")
            if len(parts) > 1:
                summary_part = parts[1].split("\n##")[0]
                summary_section = summary_part.strip()[:800]
        
        # æ–¹æ³•2: å¦‚æœæ²¡æœ‰æ‘˜è¦ï¼ŒæŸ¥æ‰¾ AI æ™ºèƒ½æ€»ç»“åçš„ç¬¬ä¸€æ®µå†…å®¹
        if not summary_section and "## ğŸ¤– AI æ™ºèƒ½æ€»ç»“" in report_content:
            parts = report_content.split("## ğŸ¤– AI æ™ºèƒ½æ€»ç»“")
            if len(parts) > 1:
                # è·³è¿‡ç©ºè¡Œï¼Œè·å–å®é™…å†…å®¹
                lines = parts[1].split('\n')
                content_lines = [line for line in lines if line.strip() and not line.strip().startswith('#')]
                if content_lines:
                    summary_section = '\n'.join(content_lines[:10])[:800]
        
        # æ–¹æ³•3: å¦‚æœè¿˜æ˜¯æ²¡æœ‰ï¼Œä½¿ç”¨æŠ¥å‘Šå‰éƒ¨åˆ†ä½†ç§»é™¤æ ¼å¼åŒ–æ ‡è®°
        if not summary_section:
            import re
            # ç§»é™¤æ‰€æœ‰ Markdown æ ‡é¢˜å’Œæ ¼å¼åŒ–ç¬¦å·
            clean_content = re.sub(r'#+\s+.*?\n', '', report_content)
            clean_content = re.sub(r'\*\*|\*|`', '', clean_content)
            summary_section = clean_content[:800].strip()
        
        prompt = f"""ä½ çš„ä»»åŠ¡æ˜¯ä¸ºä¸€ä¸ªè§†é¢‘å†…å®¹ç”Ÿæˆç®€çŸ­çš„æ–‡ä»¶å¤¹åç§°ã€‚

è¿™æ˜¯è§†é¢‘çš„å†…å®¹æ€»ç»“ï¼ˆè¯·å¿½ç•¥æŠ¥å‘Šæ ¼å¼ï¼Œä¸“æ³¨äºè§†é¢‘è®²äº†ä»€ä¹ˆï¼‰ï¼š
{summary_section}

è¦æ±‚ï¼š
1. åŸºäºè§†é¢‘çš„**æ ¸å¿ƒä¸»é¢˜å’Œå†…å®¹**ç”Ÿæˆåç§°ï¼Œä¸è¦æè¿°æŠ¥å‘Šæœ¬èº«
2. åç§°è¦**å…·ä½“ä¸”æœ‰ç»†èŠ‚**ï¼ŒåŒ…å«å…³é”®ä¿¡æ¯ç‚¹ï¼ˆå¦‚æŠ€æœ¯æ ˆã€åœºæ™¯ã€äººç‰©ç­‰ï¼‰
3. ä½¿ç”¨ä¸‹åˆ’çº¿(_)åˆ†éš”è¯è¯­ï¼Œä¸è¦ç”¨ç©ºæ ¼
4. é•¿åº¦æ§åˆ¶åœ¨30-40ä¸ªå­—ç¬¦ï¼ˆä¸­æ–‡çº¦15-20ä¸ªå­—ï¼‰
5. åªè¿”å›æ–‡ä»¶å¤¹åç§°ï¼Œä¸è¦ä»»ä½•è§£é‡Š

âœ… å¥½çš„ç¤ºä¾‹ï¼ˆè¦æœ‰ç»†èŠ‚ï¼‰ï¼š
- Pythonçˆ¬è™«å®æˆ˜_BeautifulSoupè§£æ
- æ·±åº¦å­¦ä¹ å…¥é—¨_CNNå›¾åƒåˆ†ç±»
- å•åæ‘„å½±æŠ€å·§_äººåƒå¸ƒå…‰æ•™ç¨‹
- Midjourneyç»˜ç”»_æç¤ºè¯æŠ€å·§

âŒ é¿å…è¿™æ ·ï¼ˆæè¿°æŠ¥å‘Šæ ¼å¼ï¼‰ï¼š
- è§†é¢‘åˆ†ææŠ¥å‘Š
- å†…å®¹æ€»ç»“
- çŸ¥è¯†å½’æ¡£

è¯·ç›´æ¥è¿”å›æ–‡ä»¶å¤¹åç§°ï¼š"""

        # å‘½åä»»åŠ¡ä½¿ç”¨è½»é‡çº§æ¨¡å‹ï¼Œä¸å ç”¨ä¸»æ¨¡å‹çš„é…é¢
        # ä¼˜å…ˆä½¿ç”¨ GROQ_NAMING_MODELï¼Œé»˜è®¤ä¸º openai/gpt-oss-20b
        model_name = os.getenv("GROQ_NAMING_MODEL", "openai/gpt-oss-20b")
        
        response = client.chat.completions.create(
            model=model_name,
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å†…å®¹æ ‡æ³¨å‘˜ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®è§†é¢‘å†…å®¹ç”Ÿæˆç®€æ´ã€å‡†ç¡®çš„ä¸»é¢˜æ ‡ç­¾ï¼Œè€Œä¸æ˜¯æè¿°æ–‡æ¡£æ ¼å¼ã€‚"},
                {"role": "user", "content": prompt}
            ],
            max_tokens=100,
            temperature=0.3,
        )
        
        folder_name = response.choices[0].message.content.strip()
        
        # æ¸…ç†æ–‡ä»¶å¤¹åç§°ï¼šç§»é™¤ç‰¹æ®Šå­—ç¬¦ï¼Œé™åˆ¶é•¿åº¦
        import re
        # ç§»é™¤å¼•å·ã€æ¢è¡Œç¬¦ç­‰
        folder_name = re.sub(r'["\'\n\r\t]', '', folder_name)
        # ç§»é™¤è·¯å¾„åˆ†éš”ç¬¦
        folder_name = re.sub(r'[/\\]', '_', folder_name)
        # ç§»é™¤å…¶ä»–ä¸å®‰å…¨çš„æ–‡ä»¶åå­—ç¬¦
        folder_name = re.sub(r'[<>:"|?*]', '', folder_name)
        # é™åˆ¶é•¿åº¦
        if len(folder_name) > 50:
            folder_name = folder_name[:50]
        
        # å¦‚æœç”Ÿæˆå¤±è´¥æˆ–ä¸ºç©ºï¼Œä½¿ç”¨åŸå§‹è§†é¢‘å
        if not folder_name or len(folder_name) < 3:
            print(f"  âš ï¸  LLM ç”Ÿæˆçš„æ–‡ä»¶å¤¹åæ— æ•ˆï¼Œä½¿ç”¨åŸå§‹åç§°")
            print(f"      è°ƒè¯•ä¿¡æ¯ï¼šfolder_name = '{folder_name}', é•¿åº¦ = {len(folder_name) if folder_name else 0}")
            print(f"      åŸå§‹å“åº”ï¼š{response.choices[0].message.content if response else 'N/A'}")
            return video_name
        
        print(f"  âœ… LLM ç”Ÿæˆçš„æ–‡ä»¶å¤¹å: {folder_name}")
        return folder_name
        
    except Exception as e:
        print(f"  âš ï¸  LLM æ–‡ä»¶å¤¹å‘½åå¤±è´¥: {e}")
        print(f"      é”™è¯¯ç±»å‹: {type(e).__name__}")
        import traceback
        print(f"      è¯¦ç»†å †æ ˆ:\n{traceback.format_exc()}")
        return video_name


def generate_timeline_report(timeline: list, output_path: Path):
    """
    ç”ŸæˆéŸ³ç”»æ—¶é—´è½´å¯¹ç…§æŠ¥å‘Š
    
    Args:
        timeline: éŸ³ç”»åŒ¹é…çš„æ—¶é—´è½´æ•°æ®
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    report = []
    report.append("# ğŸ¬ éŸ³ç”»æ—¶é—´è½´å¯¹ç…§\n")
    report.append(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}  \n")
    report.append(f"**æ€»æ—¶é•¿**: {len(timeline)} ç§’  \n")
    report.append("\n---\n")
    
    report.append("## ğŸ“Š é€ç§’å¯¹ç…§è¡¨\n")
    
    for item in timeline:
        second = item['second']
        frame = item['frame']
        text = item['text']
        
        # æ ¼å¼åŒ–æ—¶é—´
        minutes = second // 60
        seconds = second % 60
        time_str = f"{minutes:02d}:{seconds:02d}"
        
        report.append(f"### [{time_str}] ç¬¬ {second} ç§’\n")
        report.append(f"**ç”»é¢**: `{frame}`  \n")
        if text:
            report.append(f"**éŸ³é¢‘**: {text}\n")
        else:
            report.append(f"**éŸ³é¢‘**: *(æ— è¯­éŸ³)*\n")
        report.append("\n")
    
    output_path.write_text('\n'.join(report), encoding='utf-8')


def generate_formatted_report(
    video_name: str,
    timestamp: str,
    transcript_text: str,
    ocr_text: str,
    summary: str,
    with_frames: bool,
    session_dir: Path,
    timeline: list = None,
    video_path: Path = None,
    model_name: str = None,
    detail_model_name: str = None,
    asr_model_name: str = None
) -> str:
    """
    ç”Ÿæˆæ ¼å¼åŒ–çš„æŠ¥å‘Šï¼ŒåŒ…å«å…ƒä¿¡æ¯ã€AIæ€»ç»“å’ŒåŸå§‹æ•°æ®
    """
    # ç»Ÿè®¡ä¿¡æ¯
    transcript_chars = len(transcript_text)
    transcript_lines = transcript_text.count('\n')
    ocr_chars = len(ocr_text) if ocr_text else 0
    ocr_lines = ocr_text.count('\n') if ocr_text else 0
    
    # æ ¼å¼åŒ–æ—¶é—´
    dt = datetime.strptime(timestamp, "%Y%m%d_%H%M%S")
    formatted_time = dt.strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S")
    
    # ä½¿ç”¨ Markdown æ ¼å¼
    report = []
    report.append("# ğŸ“¹ è§†é¢‘åˆ†ææŠ¥å‘Š\n")
    report.append(f"**ğŸ“ è§†é¢‘åç§°**: {video_name}  ")
    report.append(f"**ğŸ•’ å¤„ç†æ—¶é—´**: {formatted_time}  ")
    report.append(f"**ğŸ“ è¾“å‡ºç›®å½•**: `{session_dir.name}`  ")
    if video_path:
        report.append(f"**ğŸ¥ åŸå§‹è§†é¢‘**: [{video_path.name}]({video_path.absolute()})  ")
    report.append(f"**ğŸ”§ å¤„ç†æ¨¡å¼**: {'å®Œæ•´æ¨¡å¼ (OCR + éŸ³é¢‘)' if with_frames else 'éŸ³é¢‘æ¨¡å¼'}  ")
    report.append("\n---\n")
    report.append("## ğŸ“Š æ•°æ®ç»Ÿè®¡\n")
    report.append(f"- **è¯­éŸ³è¯†åˆ«**: {transcript_chars} å­—ç¬¦, {transcript_lines} è¡Œ")
    if asr_model_name:
        report.append(f"- **ASR æ¨¡å‹**: {asr_model_name}")
    if with_frames:
        report.append(f"- **OCRè¯†åˆ«**: {ocr_chars} å­—ç¬¦, {ocr_lines} è¡Œ")
    if model_name:
        # æ˜¾ç¤ºç¬¬ä¸€æ¬¡AIè°ƒç”¨çš„æ¨¡å‹
        report.append(f"- **AI æ¨¡å‹ (æ‘˜è¦)**: {model_name}")
        # å¦‚æœç¬¬äºŒæ¬¡è°ƒç”¨ä½¿ç”¨äº†ä¸åŒçš„æ¨¡å‹ï¼Œä¹Ÿæ˜¾ç¤º
        if detail_model_name and detail_model_name != "N/A" and detail_model_name != model_name:
            report.append(f"- **AI æ¨¡å‹ (è¯¦ç»†)**: {detail_model_name}")
        elif detail_model_name and detail_model_name != "N/A":
            # å¦‚æœä¸¤æ¬¡ä½¿ç”¨ç›¸åŒæ¨¡å‹ï¼Œåªæ˜¾ç¤ºä¸€æ¬¡ä½†æ³¨æ˜
            report[-1] = f"- **AI æ¨¡å‹**: {model_name} (æ‘˜è¦ + è¯¦ç»†)"
    report.append("\n---\n")
    
    # AI æ€»ç»“ï¼ˆå·²ç»æ˜¯ markdown æ ¼å¼ï¼‰
    report.append("## ğŸ¤– AI æ™ºèƒ½æ€»ç»“\n")
    report.append(summary)
    report.append("\n---\n")
    
    # åŸå§‹æ•°æ®å¼•ç”¨
    report.append("## ğŸ“‚ åŸå§‹æ•°æ®æ–‡ä»¶\n")
    report.append(f"- ğŸ“„ [è¯­éŸ³è¯†åˆ«åŸæ–‡](transcript_raw.md) ({transcript_chars} å­—ç¬¦)")
    if with_frames:
        report.append(f"- ğŸ“„ [OCRè¯†åˆ«åŸæ–‡](ocr_raw.md) ({ocr_chars} å­—ç¬¦)")
        report.append(f"- ğŸ“ è§†é¢‘å¸§å›¾ç‰‡: `frames/` ç›®å½•")
        if timeline:
            report.append(f"- ğŸ¬ [éŸ³ç”»æ—¶é—´è½´å¯¹ç…§](timeline.md) (é€ç§’åŒ¹é…)")
    report.append(f"- ğŸ”Š éŸ³é¢‘æ–‡ä»¶: `{video_name}.wav`")
    report.append("\n> ğŸ’¡ **æç¤º**: ç‚¹å‡»é“¾æ¥æŸ¥çœ‹åŸå§‹æ•°æ®æ–‡ä»¶è·å–å®Œæ•´çš„è¯†åˆ«å†…å®¹\n")
    report.append("---\n")
    report.append(f"*ğŸ“Œ æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {formatted_time}*")
    
    return "\n".join(report)


def extract_summary_from_report(summary: str) -> str:
    """ä»AIæŠ¥å‘Šä¸­æå–æ‘˜è¦ï¼ˆä¸è¶…è¿‡50å­—ï¼‰"""
    # æŸ¥æ‰¾æ‘˜è¦éƒ¨åˆ†
    summary_patterns = [
        r'##\s*æ‘˜è¦\s*\n+(.+?)(?:\n\n|\n##)',  # ## æ‘˜è¦ åçš„å†…å®¹
        r'æ‘˜è¦[ï¼š:]\s*(.+?)(?:\n\n|\n##)',     # æ‘˜è¦: åçš„å†…å®¹
    ]
    
    for pattern in summary_patterns:
        matches = re.findall(pattern, summary, re.DOTALL | re.MULTILINE)
        if matches:
            extracted = matches[0].strip()
            # ç§»é™¤Markdownæ ¼å¼
            extracted = re.sub(r'\*\*|\*|`|#|\[|\]|\(.*?\)', '', extracted)
            # é™åˆ¶é•¿åº¦ä¸º50å­—
            if len(extracted) > 50:
                extracted = extracted[:50]
            return extracted
    
    # å¦‚æœæ²¡æ‰¾åˆ°æ‘˜è¦ç« èŠ‚ï¼Œå°è¯•æå–ç¬¬ä¸€æ®µéæ ‡é¢˜å†…å®¹
    lines = summary.split('\n')
    for line in lines:
        line = line.strip()
        if line and not line.startswith('#') and not line.startswith('*') and len(line) > 10:
            # ç§»é™¤Markdownæ ¼å¼
            line = re.sub(r'\*\*|\*|`|#|\[|\]|\(.*?\)', '', line)
            if len(line) > 50:
                return line[:50]
            return line
    
    return "æš‚æ— æ‘˜è¦"


def extract_tags_from_summary(summary: str) -> list:
    """ä»AIæ€»ç»“ä¸­æå–æ ‡ç­¾"""
    tags = []
    
    # æŸ¥æ‰¾æ ‡ç­¾è¡Œï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼‰
    tag_patterns = [
        r'##\s*æ ‡ç­¾\s*\n+(.+?)(?:\n\n|\n##)',  # ## æ ‡ç­¾ åçš„å†…å®¹
        r'æ ‡ç­¾[ï¼š:]\s*(.+)',
        r'Tags[ï¼š:]\s*(.+)',
        r'å…³é”®è¯[ï¼š:]\s*(.+)',
        r'Keywords[ï¼š:]\s*(.+)',
    ]
    
    for pattern in tag_patterns:
        matches = re.findall(pattern, summary, re.IGNORECASE | re.MULTILINE | re.DOTALL)
        for match in matches:
            # ç§»é™¤Markdownæ ¼å¼ï¼ˆç²—ä½“ã€æ–œä½“ç­‰ï¼‰
            clean_match = re.sub(r'\*\*|\*|`|#', '', match)
            # ç§»é™¤å¼•å·
            clean_match = re.sub(r'["""\'\'"]', '', clean_match)
            # ç§»é™¤æ¢è¡Œ
            clean_match = clean_match.replace('\n', ' ')
            # åˆ†å‰²æ ‡ç­¾ï¼ˆæ”¯æŒé€—å·ã€é¡¿å·ã€ç©ºæ ¼ã€åˆ†å·ç­‰åˆ†éš”ç¬¦ï¼‰
            tag_list = re.split(r'[,ï¼Œã€\s;ï¼›]+', clean_match.strip())
            tags.extend([t.strip() for t in tag_list if t.strip()])
    
    # å»é‡å¹¶è¿‡æ»¤
    seen = set()
    unique_tags = []
    for tag in tags:
        # æ¸…ç†æ¯ä¸ªæ ‡ç­¾
        tag = re.sub(r'[^\w\u4e00-\u9fa5\-]', '', tag)  # åªä¿ç•™å­—æ¯ã€æ•°å­—ã€ä¸­æ–‡ã€è¿å­—ç¬¦
        tag_lower = tag.lower()
        if tag_lower not in seen and len(tag) > 1 and len(tag) < 20:
            seen.add(tag_lower)
            unique_tags.append(tag)
    
    return unique_tags[:10]  # æœ€å¤šè¿”å›10ä¸ªæ ‡ç­¾


def extract_topics_from_summary(summary: str, video_duration: float = 0) -> list:
    """ä»AIæ€»ç»“ä¸­æå–ä¸»é¢˜ç« èŠ‚"""
    topics = []
    
    # æŸ¥æ‰¾ç« èŠ‚æ ‡é¢˜ï¼ˆ## å¼€å¤´ï¼‰
    lines = summary.split('\n')
    current_topic = None
    
    for i, line in enumerate(lines):
        line = line.strip()
        
        # æ£€æµ‹ç« èŠ‚æ ‡é¢˜
        if line.startswith('##') and not line.startswith('###'):
            title = line.lstrip('#').strip()
            
            # è¿‡æ»¤æ‰ä¸€äº›éç« èŠ‚çš„æ ‡é¢˜
            skip_titles = ['AI æ™ºèƒ½æ€»ç»“', 'æ•°æ®ç»Ÿè®¡', 'åŸå§‹æ•°æ®', 'æ€»ç»“', 'æ ‡ç­¾', 'Tags', 'å…³é”®è¯']
            if any(skip in title for skip in skip_titles):
                continue
            
            # æå–æ—¶é—´èŒƒå›´ï¼ˆå¦‚æœæœ‰ï¼‰
            time_match = re.search(r'\[?(\d{1,2}):(\d{2})\s*-\s*(\d{1,2}):(\d{2})\]?', line)
            
            if time_match:
                start_min, start_sec, end_min, end_sec = map(int, time_match.groups())
                start_time = start_min * 60 + start_sec
                end_time = end_min * 60 + end_sec
            else:
                # å¦‚æœæ²¡æœ‰æ˜ç¡®æ—¶é—´ï¼ŒæŒ‰é¡ºåºåˆ†é…
                start_time = (len(topics) * video_duration / 5) if video_duration > 0 else 0
                end_time = min(start_time + video_duration / 5, video_duration) if video_duration > 0 else 0
            
            # æ”¶é›†æè¿°ï¼ˆä¸‹é¢å‡ è¡Œéæ ‡é¢˜å†…å®¹ï¼‰
            description_lines = []
            for j in range(i + 1, min(i + 5, len(lines))):
                desc_line = lines[j].strip()
                if desc_line and not desc_line.startswith('#'):
                    description_lines.append(desc_line)
                elif desc_line.startswith('##'):
                    break
            
            description = ' '.join(description_lines)[:200]
            
            topics.append({
                'title': title[:100],
                'start_time': start_time,
                'end_time': end_time,
                'description': description,
                'keywords': []  # å¯ä»¥åç»­ä»æè¿°ä¸­æå–
            })
    
    return topics[:20]  # æœ€å¤šè¿”å›20ä¸ªä¸»é¢˜


def save_to_database(
    video_path: Path,
    video_name: str,
    session_dir: Path,
    transcript_text: str,
    ocr_text: str,
    summary: str,
    transcript_data: dict,
    timeline: list = None,
    with_frames: bool = False,
    video_duration: float = 0,
    source_url: str = None,
    platform_title: str = None,
    ocr_engine: str = None,
) -> int:
    """
    å°†å¤„ç†ç»“æœä¿å­˜åˆ°æ•°æ®åº“
    
    Returns:
        int: è§†é¢‘ID
    """
    try:
        repo = VideoRepository()
        
        # 1. åˆ›å»ºè§†é¢‘è®°å½•
        print("\nğŸ’¾ ä¿å­˜åˆ°æ•°æ®åº“...")
        
        # è®¡ç®—æ–‡ä»¶å“ˆå¸Œ
        content_hash = repo.calculate_content_hash(str(video_path))
        
        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
        existing = repo.get_video_by_hash(content_hash)
        if existing:
            print(f"   âš ï¸  è§†é¢‘å·²å­˜åœ¨ (ID: {existing.id})ï¼Œæ›´æ–°äº§ç‰©...")
            video_id = existing.id
            # æ›´æ–°è§†é¢‘å…ƒæ•°æ®ï¼ˆæ—¶é•¿ã€æ ‡é¢˜ç­‰ï¼‰
            repo.update_video_metadata(
                video_id=video_id,
                duration_seconds=video_duration,
                title=platform_title or video_name,
                platform_title=platform_title
            )
        else:
            # åˆ¤æ–­æ¥æºç±»å‹
            if source_url:
                if 'bilibili.com' in source_url:
                    source_type = SourceType.BILIBILI
                elif 'youtube.com' in source_url or 'youtu.be' in source_url:
                    source_type = SourceType.YOUTUBE
                else:
                    source_type = SourceType.URL
            else:
                source_type = SourceType.LOCAL
            
            video = Video(
                content_hash=content_hash,
                video_id=None,
                source_type=source_type,
                source_url=source_url,
                platform_title=platform_title or video_name,
                title=platform_title or video_name,
                duration_seconds=video_duration,
                file_path=str(video_path),
                file_size_bytes=video_path.stat().st_size,
                processing_config={
                    'with_frames': with_frames,
                    'output_dir': str(session_dir)
                },
                status=ProcessingStatus.COMPLETED
            )
            
            video_id = repo.create_video(video)
            print(f"   âœ… åˆ›å»ºè§†é¢‘è®°å½• (ID: {video_id})")
        
        # 2. ä¿å­˜äº§ç‰©
        # 2.1 è¯­éŸ³è½¬å†™
        if transcript_text.strip():
            transcript_artifact = Artifact(
                video_id=video_id,
                artifact_type=ArtifactType.TRANSCRIPT,
                content_text=transcript_text,
                content_json=transcript_data,
                file_path=str(session_dir / "transcript_raw.md"),
                model_name="groq-whisper-large-v3",
                char_count=len(transcript_text)
            )
            repo.save_artifact(transcript_artifact)
            print(f"   âœ… ä¿å­˜è¯­éŸ³è½¬å†™ ({len(transcript_text)} å­—ç¬¦)")
        
        # 2.2 OCRè¯†åˆ«
        if with_frames and ocr_text.strip():
            model_name = "apple-vision-ocr" if (ocr_engine or OCR_ENGINE) == 'vision' else "paddleocr-v4"
            ocr_artifact = Artifact(
                video_id=video_id,
                artifact_type=ArtifactType.OCR,
                content_text=ocr_text,
                file_path=str(session_dir / "ocr_raw.md"),
                model_name=model_name,
                char_count=len(ocr_text)
            )
            repo.save_artifact(ocr_artifact)
            print(f"   âœ… ä¿å­˜OCRè¯†åˆ« ({len(ocr_text)} å­—ç¬¦)")
        
        # 2.3 AIæŠ¥å‘Š
        if summary.strip():
            report_artifact = Artifact(
                video_id=video_id,
                artifact_type=ArtifactType.REPORT,
                content_text=summary,
                file_path=str(session_dir / "report.md"),
                model_name="groq-llama3-120b",
                char_count=len(summary)
            )
            repo.save_artifact(report_artifact)
            print(f"   âœ… ä¿å­˜AIæŠ¥å‘Š ({len(summary)} å­—ç¬¦)")
        
        # 3. æå–å¹¶ä¿å­˜æ ‡ç­¾
        tags = extract_tags_from_summary(summary)
        if tags:
            repo.save_tags(video_id, tags, source='auto', confidence=0.8)
            print(f"   âœ… ä¿å­˜æ ‡ç­¾: {', '.join(tags)}")
        
        # 4. æå–å¹¶ä¿å­˜ä¸»é¢˜
        topics = extract_topics_from_summary(summary, video_duration)
        if topics:
            topic_objects = []
            for t in topics:
                topic = Topic(
                    video_id=video_id,
                    title=t['title'],
                    start_time=t['start_time'],
                    end_time=t['end_time'],
                    summary=t['description'],
                    keywords=t['keywords']
                )
                topic_objects.append(topic)
            
            repo.save_topics(video_id, topic_objects)
            print(f"   âœ… ä¿å­˜ä¸»é¢˜: {len(topics)} ä¸ªç« èŠ‚")
        
        # 5. ä¿å­˜æ—¶é—´çº¿
        if timeline and len(timeline) > 0:
            timeline_entries = []
            for entry in timeline[:100]:  # é™åˆ¶æ•°é‡
                if entry.get('text'):
                    tl = TimelineEntry(
                        video_id=video_id,
                        timestamp_seconds=entry['second'],
                        transcript_text=entry['text'][:500]
                    )
                    timeline_entries.append(tl)
            
            if timeline_entries:
                repo.save_timeline(video_id, timeline_entries)
                print(f"   âœ… ä¿å­˜æ—¶é—´çº¿: {len(timeline_entries)} ä¸ªæ¡ç›®")
        
        # 6. æ›´æ–°å…¨æ–‡æœç´¢ç´¢å¼•
        print("   ğŸ” æ›´æ–°å…¨æ–‡æœç´¢ç´¢å¼•...")
        repo.update_fts_index(video_id)
        
        print(f"   âœ… æ•°æ®åº“ä¿å­˜å®Œæˆï¼(è§†é¢‘ID: {video_id})")
        print(f"   ğŸ’¡ å¯ä»¥ä½¿ç”¨ `make db-show ID={video_id}` æŸ¥çœ‹è¯¦æƒ…")
        print(f"   ğŸ’¡ å¯ä»¥ä½¿ç”¨ `make search Q=\"å…³é”®è¯\"` æ¥æœç´¢")
        
        return video_id
        
    except Exception as e:
        print(f"   âŒ æ•°æ®åº“ä¿å­˜å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None


# ========== ä¸»æ§åˆ¶æµç¨‹ ==========
def process_video(
    video_path: Path,
    output_dir: Path,
    with_frames: bool = False,
    ocr_lang: str = "ch",
    ocr_det_model: str = "mobile",
    ocr_rec_model: str = "mobile",
    use_gpu: bool = False,
    source_url: str = None,
    platform_title: str = None,
    ocr_engine: str = None,  # æ–°å¢ï¼š'vision' æˆ– 'paddle'ï¼ŒNone=è‡ªåŠ¨é€‰æ‹©
):
    ensure_dir(output_dir)

    # 1. åˆ›å»ºå¸¦æ—¶é—´æˆ³çš„è¾“å‡ºæ–‡ä»¶å¤¹
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    video_name = video_path.stem
    session_dir = output_dir / f"{video_name}_{timestamp}"
    ensure_dir(session_dir)
    
    # 2. å„ç±»æ–‡ä»¶è·¯å¾„
    audio_path = session_dir / f"{video_name}.wav"
    frames_dir = session_dir / "frames"
    ocr_raw_path = session_dir / "ocr_raw.md"
    transcript_raw_path = session_dir / "transcript_raw.md"
    report_path = session_dir / "report.md"
    
    print(f"\nğŸ“ è¾“å‡ºç›®å½•: {session_dir}")
    print(f"   æ—¶é—´æˆ³: {timestamp}\n")

    # è·å–è§†é¢‘æ—¶é•¿
    print(">> è·å–è§†é¢‘æ—¶é•¿...")
    video_duration = get_video_duration(video_path)
    print(f"   â±ï¸  è§†é¢‘æ—¶é•¿: {video_duration:.2f} ç§’ ({int(video_duration // 60)}:{int(video_duration % 60):02d})")

    ocr_text = ""
    transcript_text = ""
    
    # 2. å¦‚æœæ˜¯OCRæ¨¡å¼ï¼Œå…ˆå¤„ç†è§†é¢‘å¸§å’ŒOCR
    if with_frames:
        print("\n" + "="*60)
        print("ğŸ“¹ ç¬¬ä¸€æ­¥ï¼šå¤„ç†è§†é¢‘å¸§ OCR")
        print("="*60)
        
        print(">> æŠ½å¸§ä¸­...")
        extract_frames(video_path, frames_dir, fps=1)

        print("\n>> OCR å¤„ç†ä¸­...")
        
        # å†³å®šä½¿ç”¨å“ªä¸ª OCR å¼•æ“
        selected_engine = ocr_engine or OCR_ENGINE
        
        if selected_engine == 'vision':
            print(f"   ğŸ ä½¿ç”¨ Apple Vision OCR (lang={ocr_lang})")
            try:
                ocr = init_vision_ocr(
                    lang=ocr_lang,
                    recognition_level='accurate',  # 'fast' æˆ– 'accurate'
                )
                ocr_text = ocr_folder_vision(
                    ocr,
                    frames_dir,
                    output_path=ocr_raw_path,
                    debug=False,
                )
            except Exception as e:
                print(f"   âš ï¸  Vision OCR å¤±è´¥ï¼Œå°è¯•é™çº§åˆ° PaddleOCR: {e}")
                selected_engine = 'paddle'
        
        if selected_engine == 'paddle':
            # ä½¿ç”¨å¤šè¿›ç¨‹å¹¶è¡Œå¤„ç†ä»¥æå‡CPUåˆ©ç”¨ç‡
            if PARALLEL_OCR_AVAILABLE:
                import os
                # ä»ç¯å¢ƒå˜é‡è¯»å–å·¥ä½œè¿›ç¨‹æ•°ï¼Œå¦‚æœæœªè®¾ç½®åˆ™ä½¿ç”¨CPUæ ¸å¿ƒæ•°/2
                ocr_workers_env = os.environ.get('OCR_WORKERS', '').strip()
                if ocr_workers_env and ocr_workers_env.lower() != 'auto':
                    try:
                        num_workers = max(1, int(ocr_workers_env))
                    except ValueError:
                        num_workers = max(1, os.cpu_count() // 2)
                else:
                    num_workers = max(1, os.cpu_count() // 2)
                
                print(f"   ğŸ¼ ä½¿ç”¨ PaddleOCR (å¤šè¿›ç¨‹, workers={num_workers})")
                ocr_text = ocr_folder_parallel(
                    str(frames_dir),
                    min_score=0.3,
                    num_workers=num_workers,
                    use_preprocessing=True,
                    hybrid_mode=True,
                )
            else:
                # é™çº§åˆ°å•è¿›ç¨‹æ¨¡å¼
                print(f"   ğŸ¼ ä½¿ç”¨ PaddleOCR (det={ocr_det_model}, rec={ocr_rec_model})")
                ocr = init_ocr(
                    lang=ocr_lang,
                    use_gpu=use_gpu,
                    det_model=ocr_det_model,
                    rec_model=ocr_rec_model
                )
                ocr_text = ocr_folder_to_text(
                    ocr, 
                    str(frames_dir), 
                    min_score=0.3,
                    debug=False,
                    use_preprocessing=True,
                    roi_bottom_only=True,
                    hybrid_mode=True,
                )
        
        if ocr_text.strip():
            char_count = len(ocr_text)
            line_count = ocr_text.count('\n')
            print(f"\nâœ… OCR å®Œæˆï¼è¯†åˆ« {char_count} å­—ç¬¦ï¼Œ{line_count} è¡Œ")
            
            # ä¿å­˜OCRåŸå§‹ç»“æœï¼ˆMarkdown æ ¼å¼ï¼‰
            print(f"   ğŸ’¾ ä¿å­˜OCRåŸå§‹ç»“æœ: {ocr_raw_path.name}")
            ocr_markdown = f"# ğŸ” OCR è¯†åˆ«åŸå§‹æ•°æ®\n\n"
            ocr_markdown += f"**è¯†åˆ«æ—¶é—´**: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}  \n"
            ocr_markdown += f"**æ€»å­—ç¬¦æ•°**: {char_count}  \n"
            ocr_markdown += f"**æ€»è¡Œæ•°**: {line_count}  \n"
            ocr_markdown += f"**å¤„ç†æ¨¡å¼**: æ··åˆæ¨¡å¼ï¼ˆå­—å¹•åŒº + å…¨ç”»é¢ï¼‰\n\n"
            ocr_markdown += "---\n\n"
            ocr_markdown += "## ğŸ“ è¯†åˆ«å†…å®¹\n\n"
            ocr_markdown += "```\n"
            ocr_markdown += ocr_text
            ocr_markdown += "\n```\n"
            ocr_raw_path.write_text(ocr_markdown, encoding="utf-8")
        else:
            print("âš ï¸  è­¦å‘Šï¼šOCR æœªè¯†åˆ«åˆ°ä»»ä½•æ–‡å­—ï¼ˆå¯èƒ½è§†é¢‘ä¸­æ²¡æœ‰æ–‡å­—å†…å®¹ï¼‰")
        
        print("\n" + "="*60)
        print("ğŸ¤ ç¬¬äºŒæ­¥ï¼šå¤„ç†éŸ³é¢‘è½¬å†™")
        print("="*60)
    
    # 3. å¤„ç†éŸ³é¢‘ï¼ˆOCRæ¨¡å¼åœ¨OCRä¹‹åï¼Œæ™®é€šæ¨¡å¼ç›´æ¥å¤„ç†ï¼‰
    print(">> æå–éŸ³é¢‘ä¸­...")
    extract_audio(video_path, audio_path)

    # 4. Groq è¯­éŸ³è½¬æ–‡å­—ï¼ˆå¸¦æ—¶é—´æˆ³ï¼‰
    print(">> è°ƒç”¨ Groq è¯­éŸ³è½¬å†™ï¼ˆå¸¦æ—¶é—´æˆ³ï¼‰...")
    transcript_data = transcribe_audio_with_groq(audio_path)
    transcript_text = transcript_data.get('text', '')
    asr_model_name = transcript_data.get('asr_model', 'Groq Whisper')
    
    # ä¿å­˜è¯­éŸ³è¯†åˆ«åŸå§‹ç»“æœï¼ˆMarkdown æ ¼å¼ï¼ŒåŒ…å«æ—¶é—´æˆ³ï¼‰
    if transcript_text.strip():
        print(f"   ğŸ’¾ ä¿å­˜è¯­éŸ³è¯†åˆ«åŸå§‹ç»“æœ: {transcript_raw_path.name}")
        transcript_markdown = f"# ğŸ¤ è¯­éŸ³è¯†åˆ«åŸå§‹æ•°æ®\n\n"
        transcript_markdown += f"**è¯†åˆ«æ—¶é—´**: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}  \n"
        transcript_markdown += f"**æ€»å­—ç¬¦æ•°**: {len(transcript_text)}  \n"
        transcript_markdown += f"**è¯†åˆ«æ¨¡å‹**: {asr_model_name}  \n"
        transcript_markdown += f"**ç‰‡æ®µæ•°é‡**: {len(transcript_data.get('segments', []))}  \n\n"
        transcript_markdown += "---\n\n"
        transcript_markdown += "## ğŸ“ å®Œæ•´è½¬å†™\n\n"
        transcript_markdown += transcript_text + "\n\n"
        
        # æ·»åŠ å¸¦æ—¶é—´æˆ³çš„ç‰‡æ®µ
        if transcript_data.get('segments'):
            transcript_markdown += "---\n\n"
            transcript_markdown += "## â±ï¸ æ—¶é—´æˆ³ç‰‡æ®µ\n\n"
            for seg in transcript_data['segments']:
                start_time = f"{int(seg['start']//60):02d}:{int(seg['start']%60):02d}"
                end_time = f"{int(seg['end']//60):02d}:{int(seg['end']%60):02d}"
                transcript_markdown += f"**[{start_time} - {end_time}]** {seg['text']}\n\n"
        
        transcript_raw_path.write_text(transcript_markdown, encoding="utf-8")

    # 4.5 ç”ŸæˆéŸ³ç”»åŒ¹é…æ—¶é—´è½´
    timeline = None
    if with_frames and transcript_data.get('segments'):
        print(">> ç”ŸæˆéŸ³ç”»æ—¶é—´è½´åŒ¹é…...")
        timeline = match_audio_with_frames(transcript_data, frames_dir, fps=1)
        timeline_path = session_dir / "timeline.md"
        generate_timeline_report(timeline, timeline_path)
        print(f"   ğŸ’¾ ä¿å­˜éŸ³ç”»æ—¶é—´è½´: {timeline_path.name}")

    # 5. åˆå¹¶æ–‡æœ¬ï¼šæ„å»ºå¸¦æ—¶é—´æˆ³çš„è½¬å†™æ–‡æœ¬ï¼ˆç”¨äºæ‰€æœ‰ AI ä»»åŠ¡ï¼‰
    # ç”¨æˆ·è¦æ±‚ï¼šå¯åŠ¨ç¬¬ä¸€è½®å’Œç¬¬äºŒè½®æ€»ç»“çš„æ—¶å€™ï¼Œåªè¾“å…¥æ—¶é—´æˆ³ç‰‡æ®µï¼Œä¸é¢å¤–é‡å¤åŒ…å«å®Œæ•´è½¬å†™
    combined_text_parts = ["=== Audio Transcript with Timestamps ===\n"]
    if transcript_data.get('segments'):
        for seg in transcript_data['segments']:
            start_time = f"{int(seg['start']//60):02d}:{int(seg['start']%60):02d}"
            end_time = f"{int(seg['end']//60):02d}:{int(seg['end']%60):02d}"
            combined_text_parts.append(f"[{start_time} - {end_time}] {seg['text']}")
    else:
        # å¦‚æœæ²¡æœ‰ segmentsï¼ˆä¾‹å¦‚çº¯éŸ³é¢‘ä¸”æœªæ‹†åˆ†ï¼‰ï¼Œåˆ™ä½¿ç”¨çº¯æ–‡æœ¬
        combined_text_parts.append(transcript_text)

    if with_frames:
        combined_text_parts.append(f"\n\n=== OCR from Frames ===\n{ocr_text}\n")

    combined_text = "\n".join(combined_text_parts)

    # 6. ç¬¬ä¸€æ¬¡AIè°ƒç”¨ï¼šç”Ÿæˆç»“æ„åŒ–æ‘˜è¦æŠ¥å‘Š
    print("\n>> ç¬¬ä¸€æ¬¡AIè°ƒç”¨ï¼šç”Ÿæˆç»“æ„åŒ–æ‘˜è¦...")
    # ä½¿ç”¨å¸¦æ—¶é—´æˆ³çš„æ–‡æœ¬è¿›è¡Œæ‘˜è¦ï¼ˆç¬¦åˆç”¨æˆ·è¦æ±‚ï¼šåªè¾“å…¥æ—¶é—´æˆ³ç‰‡æ®µï¼‰
    summary, model_name = summarize_with_gpt_oss_120b(combined_text)
    
    # 7. ç¬¬äºŒæ¬¡AIè°ƒç”¨ï¼šç”Ÿæˆè¯¦ç»†å†…å®¹æ¦‚æ‹¬
    print(">> ç¬¬äºŒæ¬¡AIè°ƒç”¨ï¼šç”Ÿæˆè¯¦ç»†å†…å®¹æ¦‚æ‹¬...")
    # ä½¿ç”¨åŒä¸€ä»½æ–‡æœ¬
    detailed_content_tuple = generate_detailed_content(combined_text)
    detailed_content, detail_model_name = detailed_content_tuple  # è§£åŒ… tupleï¼Œä¿å­˜ç¬¬äºŒæ¬¡è°ƒç”¨çš„ model_name

    
    # 8. åˆå¹¶æ‘˜è¦å’Œè¯¦ç»†å†…å®¹
    if detailed_content:
        print(">> åˆå¹¶æ‘˜è¦ä¸è¯¦ç»†å†…å®¹...")
        summary = merge_summary_with_details(summary, detailed_content_tuple)
        print(f"   âœ… è¯¦ç»†å†…å®¹å·²æ·»åŠ  ({len(detailed_content)} å­—ç¬¦)")

    # 9. ç”Ÿæˆæ ¼å¼åŒ–æŠ¥å‘Š
    report_content = generate_formatted_report(
        video_name=video_name,
        timestamp=timestamp,
        transcript_text=transcript_text,
        ocr_text=ocr_text,
        summary=summary,
        with_frames=with_frames,
        session_dir=session_dir,
        timeline=timeline,
        video_path=video_path,
        model_name=model_name,
        detail_model_name=detail_model_name,
        asr_model_name=asr_model_name
    )
    
    report_path.write_text(report_content, encoding="utf-8")
    print(f"\nğŸ“„ æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")
    print(f"ğŸ“ å®Œæ•´è¾“å‡ºç›®å½•: {session_dir}")
    
    # 9.5 ä½¿ç”¨ LLM ç”Ÿæˆè¯­ä¹‰åŒ–çš„æ–‡ä»¶å¤¹åç§°å¹¶é‡å‘½å
    print("\n>> ä½¿ç”¨ LLM ç”Ÿæˆè¯­ä¹‰åŒ–æ–‡ä»¶å¤¹å...")
    new_folder_name = generate_folder_name_with_llm(report_content, video_name)
    
    # å¦‚æœç”Ÿæˆçš„åç§°ä¸åŸå§‹åç§°ä¸åŒï¼Œåˆ™é‡å‘½åæ–‡ä»¶å¤¹
    if new_folder_name != video_name:
        new_session_dir = output_dir / f"{new_folder_name}_{timestamp}"
        try:
            session_dir.rename(new_session_dir)
            session_dir = new_session_dir  # æ›´æ–°å¼•ç”¨
            print(f"   âœ… æ–‡ä»¶å¤¹å·²é‡å‘½åä¸º: {session_dir.name}")
            
            # æ›´æ–°è·¯å¾„å¼•ç”¨
            report_path = session_dir / "report.md"
            
        except Exception as e:
            print(f"   âš ï¸  æ–‡ä»¶å¤¹é‡å‘½åå¤±è´¥: {e}")
            print(f"   ä¿æŒåŸæ–‡ä»¶å¤¹å: {session_dir.name}")
    
    # 10. ä¿å­˜åˆ°æ•°æ®åº“
    save_to_database(
        video_path=video_path,
        video_name=video_name,
        session_dir=session_dir,
        transcript_text=transcript_text,
        ocr_text=ocr_text,
        summary=summary,
        transcript_data=transcript_data,
        timeline=timeline,
        with_frames=with_frames,
        video_duration=video_duration,
        source_url=source_url,
        platform_title=platform_title,
        ocr_engine=ocr_engine,
    )



# ========== CLI ==========
def main():
    parser = argparse.ArgumentParser(
        description="Video â†’ Text Report pipeline",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•ï¼š
  # å¤„ç†æœ¬åœ°è§†é¢‘æ–‡ä»¶
  python process_video.py video.mp4
  python process_video.py video.mp4 --with-frames
  
  # ä»URLä¸‹è½½å¹¶å¤„ç†ï¼ˆå¦‚æœå®‰è£…äº† video_downloaderï¼‰
  python process_video.py "https://www.youtube.com/watch?v=xxxxx"
  python process_video.py "https://www.bilibili.com/video/BVxxxxx" --with-frames
        """
    )
    parser.add_argument("video", type=str, help="è¾“å…¥è§†é¢‘è·¯å¾„æˆ–URL")
    parser.add_argument(
        "--with-frames",
        action="store_true",
        help="æ˜¯å¦å¯ç”¨æŠ½å¸§ + OCR åˆ†æ”¯",
    )
    parser.add_argument(
        "--out-dir",
        type=str,
        default="output",
        help="è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤: ./outputï¼‰",
    )
    parser.add_argument(
        "--ocr-lang",
        type=str,
        default="ch",
        help="OCR è¯­è¨€ï¼ˆé»˜è®¤: chï¼‰",
    )
    parser.add_argument(
        "--ocr-engine",
        type=str,
        default=None,
        choices=["vision", "paddle"],
        help="OCR å¼•æ“é€‰æ‹©ï¼ˆé»˜è®¤: è‡ªåŠ¨é€‰æ‹©ï¼‰",
    )
    parser.add_argument(
        "--ocr-det-model",
        type=str,
        default="server",  # æ”¹ä¸º server ä»¥è·å¾—æ›´å¥½çš„æ•ˆæœ
        choices=["server", "mobile"],
        help="PaddleOCR æ£€æµ‹æ¨¡å‹ç±»å‹ï¼ˆé»˜è®¤: serverï¼Œå¤æ‚èƒŒæ™¯å»ºè®®ä½¿ç”¨ï¼‰",
    )
    parser.add_argument(
        "--ocr-rec-model",
        type=str,
        default="server",  # æ”¹ä¸º server ä»¥è·å¾—æ›´å¥½çš„æ•ˆæœ
        choices=["server", "mobile"],
        help="OCR è¯†åˆ«æ¨¡å‹ç±»å‹ï¼ˆé»˜è®¤: serverï¼Œæå‡å‡†ç¡®åº¦ï¼‰",
    )
    parser.add_argument(
        "--use-gpu",
        action="store_true",
        help="æ˜¯å¦ä½¿ç”¨ GPU åŠ é€Ÿ",
    )
    parser.add_argument(
        "--download-dir",
        type=str,
        default="videos",
        help="è§†é¢‘ä¸‹è½½ç›®å½•ï¼ˆé»˜è®¤: videos/ï¼‰",
    )
    
    args = parser.parse_args()

    # æ£€æµ‹è¾“å…¥æ˜¯URLè¿˜æ˜¯æ–‡ä»¶è·¯å¾„
    input_str = args.video
    is_url = input_str.startswith("http://") or input_str.startswith("https://")
    
    source_url = None
    platform_title = None
    
    if is_url:
        # å¦‚æœæ˜¯URLï¼Œå°è¯•ä¸‹è½½
        if not DOWNLOADER_AVAILABLE:
            print("âŒ é”™è¯¯ï¼šæ£€æµ‹åˆ°URLä½†æœªå®‰è£… video_downloader æ¨¡å—")
            print("   è¯·å…ˆå®‰è£…ä¾èµ–: pip install yt-dlp")
            exit(1)
        
        print(f"ğŸ“¥ æ£€æµ‹åˆ°URLï¼Œå¼€å§‹ä¸‹è½½...")
        downloader = VideoDownloader(download_dir=args.download_dir)
        
        try:
            file_info = downloader.download_video(input_str)
            video_path = file_info.file_path
            source_url = input_str
            platform_title = getattr(file_info, 'title', None)
            print(f"âœ… ä¸‹è½½å®Œæˆ: {video_path}")
        except Exception as e:
            print(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
            exit(1)
    else:
        # å¦‚æœæ˜¯æœ¬åœ°æ–‡ä»¶è·¯å¾„
        video_path = Path(input_str).resolve()
        if not video_path.exists():
            print(f"âŒ é”™è¯¯ï¼šè§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
            exit(1)

    output_dir = Path(args.out_dir).resolve()

    process_video(
        video_path=video_path,
        output_dir=output_dir,
        with_frames=args.with_frames,
        ocr_lang=args.ocr_lang,
        ocr_engine=args.ocr_engine,
        ocr_det_model=args.ocr_det_model,
        ocr_rec_model=args.ocr_rec_model,
        use_gpu=args.use_gpu,
        source_url=source_url,
        platform_title=platform_title,
    )


def process_video_cli(args):
    """ç»Ÿä¸€CLIé€‚é…å‡½æ•°"""
    # å°†ç»Ÿä¸€CLIçš„å‚æ•°æ˜ å°„åˆ° process_video å‡½æ•°
    video_path = Path(args.video).resolve()
    if not video_path.exists():
        print(f"âŒ é”™è¯¯ï¼šè§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
        exit(1)
    
    output_dir = Path("output").resolve()
    
    # å‚æ•°æ˜ å°„
    with_frames = args.ocr
    ocr_engine = args.ocr_engine if hasattr(args, 'ocr_engine') else 'vision'
    use_gpu = args.use_gpu if hasattr(args, 'use_gpu') else False
    skip_audio = args.skip_audio if hasattr(args, 'skip_audio') else False
    skip_llm = args.skip_llm if hasattr(args, 'skip_llm') else False
    
    process_video(
        video_path=video_path,
        output_dir=output_dir,
        with_frames=with_frames,
        ocr_lang="ch",
        ocr_engine=ocr_engine,
        ocr_det_model="server",
        ocr_rec_model="server",
        use_gpu=use_gpu,
        source_url=None,
        platform_title=None,
    )


if __name__ == "__main__":
    main()
